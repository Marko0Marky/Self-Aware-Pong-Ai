<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultimate SCAN - Conscious AI System (Classic Layout)</title>
    <!-- CSS from the earlier, preferred layout version -->
    <style>
        body {
            margin: 0;
            background: linear-gradient(135deg, #0a0a15, #1a1a2e);
            color: #e0e0e0;
            font-family: 'SF Mono', 'Courier New', monospace;
            overflow-x: auto;
            min-height: 100vh;
        }
        
        .main-container {
            display: flex;
            flex-direction: column;
            max-width: 1600px;
            margin: 0 auto;
            padding: 20px;
            gap: 20px;
        }
        
        .header {
            text-align: center;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            padding: 20px;
            border: 2px solid #4af;
            box-shadow: 0 0 30px rgba(68, 170, 255, 0.3);
        }
        
        .header h1 {
            margin: 0;
            color: #4af;
            text-shadow: 0 0 20px rgba(68, 170, 255, 0.8);
            font-size: 2.5em;
        }
        
        .header p {
            margin: 10px 0 0 0;
            color: #aaa;
            font-size: 1.1em;
        }
        
        .top-section {
            display: flex;
            gap: 15px;
            flex-wrap: nowrap;
            justify-content: space-between;
            align-items: flex-start;
            max-width: 100%;
            margin: 0 auto;
            padding: 0 5px;
            box-sizing: border-box;
            overflow-x: auto;
        }
        
        .consciousness-panel {
            flex: 1 1 320px;
            min-width: 280px;
            max-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
            backdrop-filter: blur(10px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            box-sizing: border-box;
            overflow: hidden;
            order: 1;
        }
        
        .visualization-container {
            position: relative;
            width: 100%;
            height: 200px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 6px;
            border: 1px solid #4af;
            box-shadow: 0 0 10px rgba(68, 170, 255, 0.2);
            box-sizing: border-box;
        }

        .middle-column {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 15px;
            flex: 1 1 320px;
            min-width: 280px;
            max-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 12px;
            backdrop-filter: blur(10px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            box-sizing: border-box;
            order: 2;
        }

        .narration-panel {
            width: 100%;
            background: rgba(5, 5, 15, 0.7);
            border-radius: 6px;
            border: 1px solid #3a3a5a;
            padding: 8px;
            backdrop-filter: blur(5px);
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.4);
            box-sizing: border-box;
            margin: 0;
            max-height: 250px;
            overflow-y: auto;
        }
        
        .game-container {
            flex: 1 1 320px;
            min-width: 280px;
            max-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
            text-align: center;
            box-sizing: border-box;
            flex-shrink: 0;
            order: 3;
        }
        
        .controls-section {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            justify-content: center;
            margin: 20px 0;
        }
        
        button {
            background: linear-gradient(135deg, #2a2a4a, #3a3a5a);
            color: #e0e0e0;
            border: 1px solid #555;
            padding: 12px 18px;
            cursor: pointer;
            border-radius: 6px;
            font-family: inherit;
            transition: all 0.3s;
            font-weight: bold;
            min-width: 150px;
        }
        
        button:hover {
            background: linear-gradient(135deg, #3a3a5a, #4a4a6a);
            box-shadow: 0 2px 10px rgba(68, 170, 255, 0.3);
        }
        
        button:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        h3 {
            margin-top: 0;
            color: #4af;
            border-bottom: 2px solid #4af;
            padding-bottom: 8px;
            text-shadow: 0 0 10px rgba(68, 170, 255, 0.5);
        }
        
        .metric {
            display: flex;
            justify-content: space-between;
            margin-bottom: 6px;
            padding: 3px 0;
        }
        
        .metric-label {
            color: #aaa;
        }
        
        .metric-value {
            font-weight: bold;
            text-shadow: 0 0 3px currentColor;
        }
        
        .status-running { color: #22dd44; }
        .status-stopped { color: #ff5555; }
        .action-up { color: #22dd44; }
        .action-down { color: #ff5555; }
        .action-idle { color: #ffaa44; }
        
        .imagination-section, .proof-section {
            background: rgba(20, 20, 40, 0.8);
            border-radius: 8px;
            padding: 10px;
            margin-top: 10px;
            border: 1px solid #4a4a6a;
        }
        
        .imagination-path, .proof-metric {
            font-size: 11px;
            margin: 3px 0;
            padding: 2px 5px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 3px;
            border-left: 3px solid;
        }
        
        .path-good { border-left-color: #22dd44; }
        .path-bad { border-left-color: #ff5555; }
        .path-neutral { border-left-color: #ffaa44; }
        .proof-pass { border-left-color: #22dd44; }
        .proof-fail { border-left-color: #ff5555; }
        
        .bottom-section {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        
        .log-container {
            flex: 1;
            min-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
        }
        
        #log {
            background: #1e1e1e;
            border: 1px solid #444;
            border-radius: 4px;
            padding: 15px;
            height: 200px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 12px;
        }
        
        .error { color: #ff6b6b; }
        .success { color: #4CAF50; }
        .warning { color: #ffa726; }

        /* Added back for Challenge Mode and Strategy Display */
        #challenge-info, #strategy-info {
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
            border-radius: 4px;
            text-align: center;
            font-size: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: all 0.3s ease;
        }
        #challengeModeBtn {
            margin-top: 10px;
            padding: 8px 12px;
            background: #ff6b6b;
            border: none;
            color: white;
            font-size: 11px;
            font-weight: bold;
            text-transform: uppercase;
        }
        
        @media (max-width: 1000px) {
            .top-section {
                flex-direction: column;
                align-items: center;
                flex-wrap: wrap;
            }
            .consciousness-panel, .middle-column, .game-container {
                width: 100%;
                max-width: 600px;
                margin: 10px auto;
                flex: none;
            }
        }
        
        *, *::before, *::after { box-sizing: border-box !important; }
        body { overflow-x: hidden; max-width: 100vw; }
        
        #gameCanvas {
            width: 100%;
            max-width: 350px;
            height: 260px;
            object-fit: contain;
            background: linear-gradient(180deg, #000011, #000033);
            border: 1px solid #333;
            border-radius: 6px;
        }
    </style>
</head>
<body>
    <div class="main-container">
        <!-- Header -->
        <div class="header">
            <h1>üß† Ultimate SCAN - Conscious AI System</h1>
            <p>A demonstration of synthetic consciousness through gameplay, self-narration, and cognitive visualization.</p>
        </div>
        
        <!-- Top Section: Reverted to the desired 3-panel layout -->
        <div class="top-section">
            
            <!-- Left Panel: Consciousness Core -->
            <div class="consciousness-panel">
                <h3>üß† Consciousness Core</h3>
                <div class="metric"><span class="metric-label">Status:</span><span id="status" class="status-stopped">Offline</span></div>
                <div class="metric"><span class="metric-label">System Tick:</span><span id="step" class="metric-value">0</span></div>
                <div class="metric"><span class="metric-label">Consciousness (C):</span><span id="consciousness" class="metric-value">0.000</span></div>
                <div class="metric"><span class="metric-label">Coherence Error (H¬π):</span><span id="coherence-error" class="metric-value">0.000</span></div>
                <div class="metric"><span class="metric-label">Topology Loops:</span><span id="loops" class="metric-value">0</span></div>
                <div class="metric"><span class="metric-label">Current Action:</span><span id="action" class="metric-value action-idle">IDLE</span></div>

                <h3>üîÆ Internal Simulation</h3>
                <div class="imagination-section">
                    <h3 style="font-size: 12px; margin: 0 0 8px 0; border: none; padding: 0;">Future State Evaluations</h3>
                    <div id="imagination-paths"></div>
                </div>

                <h3>üî¨ Proof Harness</h3>
                <div class="proof-section">
                    <h3 style="font-size: 12px; margin: 0 0 8px 0; border: none; padding: 0;">Sheaf & Clifford Integrity</h3>
                    <div id="proof-metrics"></div>
                </div>
            </div>

            <!-- Middle Column: Visualization and Narration -->
            <div class="middle-column">
                <div class="visualization-container" id="visualization-container"></div>
                <div class="narration-panel">
                    <h3>üó£Ô∏è AI Consciousness Stream</h3>
                    <div id="ai-narration" style="height: 200px; overflow-y: auto; font-size: 13px; line-height: 1.4;">
                        <!-- AI narration will appear here -->
                    </div>
                </div>
            </div>

            <!-- Right Panel: Game Environment (with missing features restored) -->
            <div class="game-container">
                <h3>üèì PONG Environment</h3>
                <canvas id="gameCanvas" width="400" height="300"></canvas>
                
                <!-- Challenge Mode Info -->
                <div id="challenge-info">
                    <div style="color: #4CAF50;">üéÆ NORMAL MODE</div>
                    <div style="font-size: 11px;">Human vs Conscious AI</div>
                </div>

                <div class="metric" style="margin-top: 10px;">
                    <span class="metric-label" id="player-label">Human Score:</span><span id="player-score" class="metric-value">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">AI Score:</span><span id="ai-score" class="metric-value">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Game Length:</span><span id="game-length" class="metric-value">0s</span>
                </div>

                <!-- Strategic AI Info -->
                <div id="strategy-info">
                    <div style="color: #4af; font-weight: bold;">üß† AI Strategy</div>
                    <div id="current-strategy" style="font-size: 10px; color: #aaa;">Analyzing...</div>
                    <div id="strategy-confidence" style="font-size: 9px; color: #888;">Confidence: --</div>
                </div>
                
                <!-- Challenge Mode Button -->
                <button id="challengeModeBtn">üèÜ Challenge Mode</button>
            </div>

        </div>
        
        <!-- Controls Section (with all buttons restored) -->
        <div class="controls-section">
            <button id="startStopBtn">üöÄ Awaken Consciousness</button>
            <button id="resetBtn">üîÑ Reset System</button>
            <button id="imaginationBtn">üîÆ Toggle Imagination</button>
            <button id="trainGrammarBtn">üìù Train Game Grammar</button>
            <button id="toggleNarrationBtn">üó£Ô∏è Toggle Narration</button>
            <button id="testImports">üîß Test System</button>
        </div>
        
        <!-- Bottom Section: System Console Log -->
        <div class="bottom-section">
            <div class="log-container">
                <h3>üîß System Console</h3>
                <div id="log"></div>
            </div>
        </div>
    </div>

    <!-- Three.js for 3D visualization -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    
    <!-- Your entire final, stable <script> block goes here -->
    <script>
    // ===== START OF FULL INTEGRATED SCRIPT MODULE =====

// Global error handler
window.onerror = function(message, source, lineno, colno, error) {
    console.error(`Error: ${message} at ${source}:${lineno}:${colno}`, error);
};

// Override console functions to display in our log container
const logContainer = document.getElementById('log');
const originalLog = console.log;
const originalWarn = console.warn;
const originalError = console.error;

function addLogEntry(message, type = 'info') {
    const timestamp = new Date().toLocaleTimeString();
    const entry = document.createElement('div');
    entry.className = type;
    entry.textContent = `[${timestamp}] ${message}`;
    logContainer.appendChild(entry);
    logContainer.scrollTop = logContainer.scrollHeight;
}

console.log = (...args) => {
    originalLog(...args);
    addLogEntry(args.join(' '), 'success');
};

console.warn = (...args) => {
    originalWarn(...args);
    addLogEntry(args.join(' '), 'warning');
};

console.error = (...args) => {
    originalError(...args);
    addLogEntry(args.join(' '), 'error');
};

console.log('üöÄ Ultimate SCAN System Initializing (v4.0 Normative Direction Upgrade)...');

// === Utility Functions ===
const D = 8; // Qualia dimension (Cl(3,0))
const eps = 1e-9;

function zeros(n, m) {
    const A = new Array(n);
    for (let i = 0; i < n; i++) A[i] = new Array(m).fill(0);
    return A;
}

function vecZeros(n) { return new Array(n).fill(0); }

function dot(a, b) {
    if (!a || !b || a.length !== b.length) return 0;
    let s = 0;
    for (let i = 0; i < a.length; i++) s += a[i] * b[i];
    return isNaN(s) ? 0 : s;
}

function norm2(a) {
    if (!a || a.length === 0) return 0;
    return Math.sqrt(Math.max(eps, dot(a, a)));
}

function addVec(a, b) { return a.map((v, i) => v + b[i]); }
function scaleVec(a, s) { return a.map(v => v * s); }
function cloneVec(a) { return a.slice(); }
function sub(a, b) { return a.map((v, i) => v - b[i]); }
function normL2(a) { return norm2(a); }
function tanhVec(a) { return a.map(Math.tanh); }
function clamp(x, lo, hi) { return Math.max(lo, Math.min(hi, x)); }

function randomMatrix(rows, cols, scale = 0.1) {
    const M = new Array(rows);
    for (let i = 0; i < rows; i++) {
        M[i] = new Array(cols);
        for (let j = 0; j < cols; j++) {
            M[i][j] = (Math.random() * 2 - 1) * scale;
        }
    }
    return M;
}

function randomVec(n, scale = 0.1) {
    return new Array(n).fill(0).map(() => (Math.random() * 2 - 1) * scale);
}

function matVecMul(M, v) {
    const out = new Array(M.length).fill(0);
    for (let i = 0; i < M.length; i++) {
        let s = 0;
        for (let j = 0; j < v.length; j++) s += M[i][j] * v[j];
        out[i] = s;
    }
    return out;
}

function matVecDot(M, v) {
    let s = 0;
    for (let j = 0; j < v.length; j++) s += M[0][j] * v[j];
    return s;
}

function softmax(arr) {
    const max = Math.max(...arr);
    const exps = arr.map(x => Math.exp(Math.max(-50, Math.min(50, x - max))));
    const sum = exps.reduce((s, v) => s + v, 0) + eps;
    return exps.map(x => x / sum);
}

function transpose(M) {
    const rows = M.length, cols = M[0].length;
    const Mt = zeros(cols, rows);
    for (let i = 0; i < rows; i++) for (let j = 0; j < cols; j++) Mt[j][i] = M[i][j];
    return Mt;
}

function matMul(A, B) {
    const rowsA = A.length, colsA = A[0].length, colsB = B[0].length;
    const C = zeros(rowsA, colsB);
    for (let i = 0; i < rowsA; i++) {
        for (let j = 0; j < colsB; j++) {
            let s = 0;
            for (let k = 0; k < colsA; k++) s += A[i][k] * B[k][j];
            C[i][j] = s;
        }
    }
    return C;
}

// === Clifford Algebra (Cl(3,0)) ===
const CLIFF = (function buildClifford() {
    const dim = 8;
    const T = [];
    for (let a = 0; a < dim; a++) {
        T[a] = [];
        for (let b = 0; b < dim; b++) {
            T[a][b] = new Array(dim).fill(0);
        }
    }
    const s = 0, e1 = 1, e2 = 2, e3 = 3, e12 = 4, e23 = 5, e31 = 6, I = 7;

    for (let i = 0; i < dim; i++) { T[s][i][i] = 1; T[i][s][i] = 1; }
    T[e1][e1][s] = 1; T[e2][e2][s] = 1; T[e3][e3][s] = 1;
    T[e1][e2][e12] = 1; T[e2][e1][e12] = -1;
    T[e2][e3][e23] = 1; T[e3][e2][e23] = -1;
    T[e3][e1][e31] = 1; T[e1][e3][e31] = -1;
    T[e12][e12][s] = -1; T[e23][e23][s] = -1; T[e31][e31][s] = -1;
    T[e12][e3][I] = 1; T[e3][e12][I] = -1;
    T[e23][e1][I] = 1; T[e1][e23][I] = -1;
    T[e31][e2][I] = 1; T[e2][e31][I] = -1;
    T[I][I][s] = -1;
    T[I][e1][e23] = 1; T[e1][I][e23] = 1;
    T[I][e2][e31] = 1; T[e2][I][e31] = 1;
    T[I][e3][e12] = 1; T[e3][I][e12] = 1;

    return T;
})();

const CLIFF_BASIS = [
    [1,0,0,0,0,0,0,0], // scalar
    [0,1,0,0,0,0,0,0], // e1
    [0,0,1,0,0,0,0,0], // e2
    [0,0,0,1,0,0,0,0], // e3
    [0,0,0,0,1,0,0,0], // e12
    [0,0,0,0,0,1,0,0], // e23
    [0,0,0,0,0,0,1,0], // e31
    [0,0,0,0,0,0,0,1]  // pseudoscalar
];

function cliffordMultiplyVec(Lmats, q, r) {
    const out = new Array(8).fill(0);
    for (let a = 0; a < 8; a++) {
        const qa = q[a];
        if (qa === 0) continue;
        const Ta = Lmats[a];
        for (let b = 0; b < 8; b++) {
            const rb = r[b];
            if (rb === 0) continue;
            const row = Ta[b];
            for (let c = 0; c < 8; c++) {
                out[c] += qa * rb * row[c];
            }
        }
    }
    return out;
}

// REPLACE THE ENTIRE cliffordProject FUNCTION WITH THIS DEFINITIVE VERSION

function cliffordProject(q) {
    // This function must NEVER return a zero vector.
    
    // Calculate the length (norm) of the input vector.
    const norm = norm2(q);

    // --- THE DEFINITIVE FIX IS HERE ---
    // Check if the vector is null or invalid.
    if (!q || !q.every(isFinite) || norm < eps) {
        // If it is, DO NOT return a zero vector.
        // Instead, create a new, random, valid vector to "re-ignite" consciousness.
        let recovery_vector;
        do {
            recovery_vector = new Float32Array(8).map(() => Math.random() - 0.5);
        } while (norm2(recovery_vector) < eps); // Ensure the recovery vector itself is not null.
        
        // Normalize and return the new, valid vector.
        return scaleVec(recovery_vector, 1.0 / norm2(recovery_vector));
    }

    // If the input vector is valid, normalize and return it as before.
    return scaleVec(q, 1.0 / norm);
}

function geoProduct(q, r) {
    const out = new Array(8).fill(0);
    for (let a = 0; a < 8; a++) {
        const qa = q[a];
        if (qa === 0) continue;
        const Ta = CLIFF[a];
        for (let b = 0; b < 8; b++) {
            const rb = r[b];
            if (rb === 0) continue;
            const row = Ta[b];
            for (let c = 0; c < 8; c++) {
                out[c] += qa * rb * row[c];
            }
        }
    }
    return out;
}

const DAG_SIGNS = [1, -1, -1, -1, -1, -1, -1, 1];
function dagger(q) {
    return q.map((v, i) => v * DAG_SIGNS[i]);
}

// REPLACE THE ENTIRE qualiaBindMatrix FUNCTION WITH THIS FINAL, DEFINITIVE VERSION

function qualiaBindMatrix(Q) {
    const N = Q.length;
    if (N === 0) return [];

    const B = zeros(N, N);

    for (let i = 0; i < N; i++) {
        for (let j = 0; j < N; j++) {
            // This is the simplest case, for when a node binds to itself.
            if (i === j) {
                B[i][j] = 1.0;
                continue;
            }

            const qi = Q[i];
            const qj = Q[j];

            // This check is critical in case the graph state is somehow invalid.
            if (!qi || !qj) {
                B[i][j] = 0;
                continue;
            }

            // --- The New, Unbreakable Formula ---
            // 1. Calculate the dot product. Since q vectors are normalized, this is their cosine similarity.
            //    The result is a stable float between -1 and 1.
            const similarity = dot(qi, qj);

            // 2. We only care about positive alignment. Clamp the value between 0 and 1.
            //    This creates a simple, direct measure of binding strength.
            //    Using Math.pow emphasizes stronger connections and is numerically very stable.
            const bindingValue = Math.pow(Math.max(0, similarity), 2);
            
            // 3. Final guarantee. While it's now virtually impossible for this to fail,
            //    this ensures no NaN can ever escape the function.
            if (!isFinite(bindingValue)) {
                B[i][j] = 0;
            } else {
                B[i][j] = bindingValue;
            }
        }
    }

    return B;
}
// Clone graph for imagination
// REPLACE THE ENTIRE cloneGraph FUNCTION

function cloneGraph(G) {
    // *** THE DEFINITIVE FIX IS HERE ***
    // We now copy all essential properties, including the attention schemas.
    return {
        V: G.V,
        W: G.W.map(row => row.slice()),
        X: G.X.map(row => row.slice()),
        q: G.q.map(q_vec => q_vec.slice()),
        edges: G.edges.map(e => [...e]),
        stalkDims: G.stalkDims.slice(),
        a: G.a.slice(),
        aSchema: G.aSchema.slice(),
        aMeasured: G.aMeasured.slice()
    };
}

// === GW Distance & Sinkhorn ===
function sinkhorn(C, mu, nu, lamb, maxIter = 100) {
    // FIX: Add a guard clause to handle empty or invalid cost matrices gracefully.
    if (!C || C.length === 0 || !C[0] || C[0].length === 0) {
        // If the cost matrix is empty, return an appropriately sized empty transport plan.
        const n_rows = mu ? mu.length : 0;
        const n_cols = nu ? nu.length : 0;
        return Array(n_rows).fill().map(() => Array(n_cols).fill(0));
    }

    const N = mu.length;
    let b = new Array(N).fill(1 / N);
    const K = C.map(row => row.map(c => Math.exp(-lamb * c)));
    for (let iter = 0; iter < maxIter; iter++) {
        const Ka = K.map(row => dot(row, b));
        const a = mu.map((m, i) => m / (Ka[i] + eps));
        const Kb = K[0].map((_, j) => K.reduce((s, row, i) => s + row[j] * a[i], 0));
        b = nu.map((n, j) => n / (Kb[j] + eps));
    }
    const Gamma = b.map((bj, j) => K.map(row => row[j] * bj));
    return Gamma;
}

function gwDistance(W1, W2, epsilon = 0.1) {
    const N = W1.length;
    if (N === 0 || W2.length === 0 || W1[0].length !== W2[0].length) return 0;
    const C = new Array(N).fill(0).map(() => new Array(N).fill(0));
    for (let i = 0; i < N; i++) {
        for (let j = 0; j < N; j++) {
            C[i][j] = normL2(sub(W1[i], W2[j]));
        }
    }
    const mu = new Array(N).fill(1 / N);
    const nu = new Array(N).fill(1 / N);
    const pi = sinkhorn(C, mu, nu, epsilon);
    let dist = 0;
    for (let i = 0; i < N; i++) {
        for (let j = 0; j < N; j++) {
            dist += pi[i][j] * C[i][j];
        }
    }
    return dist;
}

console.log('‚úÖ Core computation utilities loaded.');


// ===== REINTRODUCED COMPONENTS FROM ORIGINAL BACKBONE =====

class SheafDiffusion {
    constructor(sigma = 0.5, n_iters = 20) {
        this.sigma = sigma;
        this.n_iters = n_iters;
    }

    forward(scores, Q, X = null) {
        const N = scores.length;
        let W = scores.map(row => row.slice());

        // Enhanced diffusion with error handling
        for (let iter = 0; iter < this.n_iters; iter++) {
            for (let i = 0; i < N; i++) {
                for (let j = 0; j < N; j++) {
                    try {
                        const gradQ = normL2(sub(Q[i] || vecZeros(8), Q[j] || vecZeros(8)));
                        let diffusionWeight = Math.exp(-Math.max(gradQ, eps) / this.sigma);

                        if (X && X[i] && X[j]) {
                            const featureDist = Math.sqrt(X[i].reduce((s, v, k) => s + Math.pow(v - (X[j][k] || 0), 2), 0));
                            const featureWeight = Math.exp(-featureDist * 0.5 / this.sigma);
                            diffusionWeight = 0.7 * diffusionWeight + 0.3 * featureWeight;
                        }

                        W[i][j] *= diffusionWeight;

                        if (Q[i] && Q[j]) {
                            const qualiaDistance = norm2(addVec(Q[i], scaleVec(Q[j], -1)));
                            W[i][j] *= Math.exp(-qualiaDistance * 0.1 / this.sigma);
                        }
                    } catch (error) {
                        console.warn(`SheafDiffusion error at (${i},${j}):`, error);
                        W[i][j] *= 0.9;
                    }
                }
            }

            for (let i = 0; i < N; i++) {
                const sum = W[i].reduce((s, v) => s + Math.max(v, 0), 0) + eps;
                W[i] = W[i].map(v => Math.max(v, 0) / sum);
            }
        }

        let sheafDiff = 0;
        try {
            sheafDiff = W.reduce((s, row, i) => {
                return s + row.reduce((t, v, j) => {
                    if (!Q[i] || !Q[j]) return t;

                    const dist1 = normL2(sub(Q[i], Q[j]));
                    const dist2 = norm2(addVec(Q[i], scaleVec(Q[j], -1)));
                    const avgDist = (dist1 + dist2) * 0.5;

                    return t + v * Math.exp(-avgDist / this.sigma);
                }, 0);
            }, 0);
        } catch (error) {
            console.warn('SheafDiffusion metric calculation error:', error);
            sheafDiff = 0;
        }

        return { W, sheafDiff };
    }
}

class ASTFilter {
    constructor(nodeDim = 12, hidden = 32) {
        this.nodeDim = nodeDim;
        this.hidden = hidden;
        this.Wxh = this.randomMatrix(hidden, nodeDim);
        this.Whh = this.randomMatrix(hidden, hidden);
        this.bh = vecZeros(hidden);
        this.projW = this.randomMatrix(1, nodeDim);
        this.projB = [0];
        this.state = vecZeros(hidden);
    }

    randomMatrix(rows, cols, scale = 0.1) {
        const M = new Array(rows);
        for (let i = 0; i < rows; i++) {
            M[i] = new Array(cols);
            for (let j = 0; j < cols; j++) {
                M[i][j] = (Math.random() * 2 - 1) * scale;
            }
        }
        return M;
    }

    step(Nodes) {
        const mean = vecZeros(this.nodeDim);
        for (const v of Nodes) {
            if (v && v.length >= this.nodeDim) {
                for (let i = 0; i < this.nodeDim; i++) {
                    mean[i] += v[i] || 0;
                }
            }
        }
        for (let i = 0; i < this.nodeDim; i++) mean[i] /= Math.max(1, Nodes.length);

        const Wx = matVecMul(this.Wxh, mean);
        const Wh = matVecMul(this.Whh, this.state);
        const next = vecZeros(this.hidden);
        for (let i = 0; i < this.hidden; i++) {
            next[i] = Math.tanh(Wx[i] + Wh[i] + this.bh[i]);
        }
        this.state = next;

        const scores = Nodes.map(v => {
            if (!v || v.length === 0) return 0;

            try {
                let score = this.projB[0];
                for (let j = 0; j < Math.min(v.length, this.nodeDim); j++) {
                    score += this.projW[0][j] * (v[j] || 0);
                }

                const score2 = dot(this.projW[0], v.slice(0, this.nodeDim)) + this.projB[0];

                return (score + score2) * 0.5;
            } catch (error) {
                console.warn('ASTFilter score computation error:', error);
                return 0;
            }
        });

        const a = softmax(scores);
        return { s: next, a, scores };
    }

    update(grad, lr = 1e-3, Nodes = []) {
        if (Nodes.length === 0 || Math.abs(grad) < 1e-6) return;

        const effectiveLr = lr * grad;
        if (Math.abs(effectiveLr) < 1e-8) return;

        const mean = vecZeros(this.nodeDim);
        const invLen = 1.0 / Math.max(1, Nodes.length);

        for (const v of Nodes) {
            for (let i = 0; i < this.nodeDim; i++) {
                mean[i] += v[i] * invLen;
            }
        }

        const maxUpdate = 0.1;
        for (let j = 0; j < this.nodeDim; j++) {
            const update = effectiveLr * mean[j];
            this.projW[0][j] -= Math.max(-maxUpdate, Math.min(maxUpdate, update));
        }
        this.projB[0] -= Math.max(-maxUpdate, Math.min(maxUpdate, effectiveLr));
    }

    reset() {
        this.state = vecZeros(this.hidden);
    }
}

class WorldModel {
    constructor(stateDim = 6, actionDim = 3, qDim = 8) { // UPGRADE: Removed 'hidden' from constructor
        this.stateDim = stateDim;
        this.actionDim = actionDim;
        this.qDim = qDim;
        
        // UPGRADE: A deeper and wider network architecture
        const hidden1 = 128;
        const hidden2 = 128;
        const inputDim = stateDim + actionDim + qDim;

        this.qProjW = this.randomMatrix(qDim, stateDim, 0.2);
        this.qProjB = vecZeros(qDim);

        // UPGRADE: Transition network now has two hidden layers
        this.transW1 = this.randomMatrix(hidden1, inputDim, 0.1);
        this.transB1 = vecZeros(hidden1);
        this.transW2 = this.randomMatrix(hidden2, hidden1, 0.1);
        this.transB2 = vecZeros(hidden2);
        this.transW3 = this.randomMatrix(stateDim, hidden2, 0.1);
        this.transB3 = vecZeros(stateDim);

        // UPGRADE: Reward network also has two hidden layers
        const rewardInputDim = stateDim + qDim;
        this.rewardW1 = this.randomMatrix(hidden1, rewardInputDim, 0.1);
        this.rewardB1 = vecZeros(hidden1);
        this.rewardW2 = this.randomMatrix(hidden2, hidden1, 0.1);
        this.rewardB2 = vecZeros(hidden2);
        this.rewardW3 = this.randomMatrix(1, hidden2, 0.1);
        this.rewardB3 = [0];

        this.memory = [];
        this.fepHistory = [];
    }

    randomMatrix(rows, cols, scale = 0.1) {
        const M = new Array(rows);
        for (let i = 0; i < rows; i++) {
            M[i] = new Array(cols).fill(0).map(() => (Math.random() * 2 - 1) * scale);
        }
        return M;
    }

    qProj(state) {
        const q = matVecMul(this.qProjW, state);
        return q.map((v, i) => Math.tanh(v + this.qProjB[i]));
    }

    // REPLACE the entire 'predict' function in the 'WorldModel' class
predict(state, action, q) {
    const inp = state.concat(action).concat(q);

    // Forward pass through the deeper network
    const h1_trans = matVecMul(this.transW1, inp).map((v, i) => Math.tanh(v + this.transB1[i]));
    const h2_trans = matVecMul(this.transW2, h1_trans).map((v, i) => Math.tanh(v + this.transB2[i]));
    let nextState = matVecMul(this.transW3, h2_trans).map((v, i) => v + this.transB3[i]);
    
    // *** CRITICAL FIX: CONSTRAIN THE PREDICTION ***
    // This prevents the model from imagining impossible futures (e.g., ball at position Infinity).
    // We clamp each component of the predicted state vector to a "sane" range.
    nextState = nextState.map((val, i) => {
        const min = (i < 4) ? -2.0 : 0.0; // Ball coordinates/velocity can be negative
        const max = (i < 4) ? 2.0 : 1.0;  // Paddle positions are normalized between 0 and 1
        return isFinite(val) ? clamp(val, min, max) : 0;
    });

    const nextQ = this.qProj(nextState);

    // Forward pass through the deeper reward network
    const reward_inp = nextState.concat(nextQ);
    const h1_reward = matVecMul(this.rewardW1, reward_inp).map((v, i) => Math.tanh(v + this.rewardB1[i]));
    const h2_reward = matVecMul(this.rewardW2, h1_reward).map((v, i) => Math.tanh(v + this.rewardB2[i]));
    const reward = matVecMul(this.rewardW3, h2_reward)[0] + this.rewardB3[0];
    
    const recon = norm2(sub(nextState, state));
    const kl_approx = 0.5 * norm2(sub(nextQ, q));
    const vfe = kl_approx + recon;
    const fep = vfe;

    return {
        nextState: new Float32Array(nextState),
        nextQ,
        reward: reward,
        fep
    };
}

    storeTransition(s, a, nextS, r, Q, nextQ) {
        this.memory.push({ s, a, nextS, r, Q, nextQ });
        if (this.memory.length > 2000) this.memory.shift(); // UPGRADE: Slightly larger memory
    }
    
    // NOTE: The trainFromMemory function we fixed in the last step is compatible with this new architecture
    // and does not need to be changed again. It will automatically train the deeper network.
    // REPLACE THE ENTIRE 'trainFromMemory' FUNCTION WITH THIS STABLE VERSION

    // REPLACE THE ENTIRE 'trainFromMemory' FUNCTION IN THE 'WorldModel' CLASS WITH THIS ROBUST VERSION

// REPLACE the entire trainFromMemory function
trainFromMemory(batchSize = 16) {
    if (this.memory.length < batchSize) return;

    const lr = 1e-5;
    const gradClip = 0.5;
    const maxIters = 2;

    for (let k = 0; k < maxIters; k++) {
        const idx = Math.floor(Math.random() * this.memory.length);
        const tr = this.memory[idx];
        
        // *** CRITICAL ROBUSTNESS PATCH STARTS HERE ***
        // This is the ultimate firewall. Check every piece of data before it's used.
        if (!tr || !tr.s || !tr.a || !tr.Q || !tr.nextS || !tr.nextQ ||
            !tr.s.every(isFinite) || !tr.a.every(isFinite) || !tr.Q.every(isFinite) ||
            !tr.nextS.every(isFinite) || !tr.nextQ.every(isFinite)) 
        {
            console.warn(`Skipping corrupted or incomplete memory entry at index ${idx}.`);
            continue; // Skip this entire training step.
        }
        // *** CRITICAL ROBUSTNESS PATCH ENDS HERE ***

        // --- Forward Pass ---
        const inp = tr.s.concat(tr.a).concat(tr.Q);
        const h1_trans = matVecMul(this.transW1, inp).map((v, i) => Math.tanh(v + this.transB1[i]));
        const h2_trans = matVecMul(this.transW2, h1_trans).map((v, i) => Math.tanh(v + this.transB2[i]));
        const predNextState = matVecMul(this.transW3, h2_trans).map((v, i) => v + this.transB3[i]);
        
        const reward_inp = predNextState.concat(this.qProj(predNextState));
        const h1_reward = matVecMul(this.rewardW1, reward_inp).map((v, i) => Math.tanh(v + this.rewardB1[i]));
        const h2_reward = matVecMul(this.rewardW2, h1_reward).map((v, i) => Math.tanh(v + this.rewardB2[i]));
        const predReward = matVecMul(this.rewardW3, h2_reward)[0] + this.rewardB3[0];
        
        if (!predNextState.every(isFinite) || !isFinite(predReward)) {
            continue;
        }

        // --- Calculate and Clip Errors ---
        let errS = tr.nextS.map((v, i) => v - predNextState[i]);
        let errR = tr.r - predReward;

        errR = clamp(errR, -gradClip, gradClip);
        errS = errS.map(e => clamp(e, -gradClip, gradClip));

        if (!errS.every(isFinite) || !isFinite(errR)) {
            continue;
        }
        
        // --- Gentle Backpropagation ---
        for (let i = 0; i < this.transW3.length; i++) {
            for (let j = 0; j < this.transW3[0].length; j++) {
                this.transW3[i][j] += lr * errS[i] * h2_trans[j];
            }
            this.transB3[i] += lr * errS[i];
        }
        
        for (let i = 0; i < this.rewardW3[0].length; i++) {
            this.rewardW3[0][i] += lr * errR * h2_reward[i];
        }
        this.rewardB3[0] += lr * errR;
    }

    // FEP History update
    const tr = this.memory[this.memory.length - 1];
    if (tr && tr.s && tr.a && tr.Q && tr.s.every(isFinite) && tr.a.every(isFinite) && tr.Q.every(isFinite)) {
        const livePred = this.predict(tr.s, tr.a, tr.Q);
        if (isFinite(livePred.fep)) {
            this.fepHistory.push(livePred.fep);
            if (this.fepHistory.length > 50) this.fepHistory.shift();
        }
    }
}

    imagine(currentState, Q, depth = 8) { // UPGRADE: Increased planning depth
        const paths = [];
        const actions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]; // UP, DOWN, IDLE

        for (let ai = 0; ai < actions.length; ai++) {
            let state = currentState.slice();
            let qual = Q.slice();
            let total_reward = 0;
            const path = [`Action:${ai}`];

            for (let step = 0; step < depth; step++) {
                const p = this.predict(state, actions[ai], qual);
                state = Array.from(p.nextState);
                qual = p.nextQ.slice();
                total_reward += p.reward * Math.pow(0.95, step); // UPGRADE: Discount future rewards slightly less
                path.push(`s${step + 1}: r=${p.reward.toFixed(2)}, fep=${p.fep.toFixed(2)}`);
            }

            paths.push({
                action: ai,
                value: total_reward,
                path,
                actionName: ['UP', 'DOWN', 'IDLE'][ai]
            });
        }

        paths.sort((a, b) => b.value - a.value);
        return paths;
    }
}

// REPLACE THE ENTIRE Syncolator CLASS WITH THIS ROBUST, TIME-BOXED VERSION

class Syncolator {
    detect(W, Q) {
        const n = W.length;
        if (n === 0) return [];

        // --- SAFETY MECHANISMS ---
        const startTime = performance.now();
        const timeLimit = 50; // Max 50ms to prevent freezing the main thread.
        const maxCycles = 100; // Stop after finding a reasonable number of cycles.

        const cycles = [];
        
        // Use a dynamic threshold to build a sparse neighbor list, which is critical for performance.
        const meanWeight = W.flat().reduce((s, v) => s + (isFinite(v) ? v : 0), 0) / (n * n);
        const threshold = Math.max(meanWeight, 1e-4);
        const neighbors = Array.from({ length: n }, () => []);
        for (let i = 0; i < n; i++) {
            for (let j = 0; j < n; j++) {
                if (W[i][j] > threshold) {
                    neighbors[i].push(j);
                }
            }
        }

        for (let startNode = 0; startNode < n; startNode++) {
            // --- Time-boxing Check ---
            if (performance.now() - startTime > timeLimit || cycles.length >= maxCycles) {
                if(cycles.length < maxCycles) console.warn(`Syncolator timed out after ${timeLimit}ms.`);
                break;
            }

            // Non-recursive DFS using a manual stack
            const stack = [[startNode, [startNode], []]]; // [currentNode, path, edges]

            while (stack.length > 0) {
                const [currentNode, path, edges] = stack.pop();

                if (path.length > 8) continue; // Path length limit

                for (const neighbor of neighbors[currentNode]) {
                    if (neighbor === startNode) {
                        // Found a cycle
                        if (path.length > 1) { // Ensure it's not a self-loop of length 1
                            cycles.push({ nodes: [...path, neighbor], edges: [...edges, W[currentNode][neighbor]] });
                            if (cycles.length >= maxCycles) break;
                        }
                    } else if (!path.includes(neighbor)) {
                        // Continue the path
                        const newPath = [...path, neighbor];
                        const newEdges = [...edges, W[currentNode][neighbor]];
                        stack.push([neighbor, newPath, newEdges]);
                    }
                }
                if (cycles.length >= maxCycles) break;
            }
        }

        // The persistence calculation remains the same as our previous successful version.
        return cycles.map(cycle => {
            try {
                const weightProduct = cycle.edges.reduce((a, w) => a * Math.max(w, 1e-9), 1);
                const lengthNorm = Math.sqrt(cycle.edges.reduce((a, w) => a + w * w, 0) + eps);
                
                const qualiaContribution = cycle.nodes.reduce((s, i) => {
                    const qi = Q[i] || vecZeros(8);
                    const q_start = Q[cycle.nodes[0]] || vecZeros(8);
                    return s + norm2(qi) * Math.exp(-norm2(sub(qi, q_start)) / 0.5);
                }, 0) / Math.max(cycle.nodes.length, 1);

                const persistence = (weightProduct * Math.exp(-lengthNorm / 0.5) + 0.5 * qualiaContribution);
                
                return {
                    points: cycle.nodes.map(i => (Q[i] || vecZeros(8)).slice(0, 3).map(x => x * 4)),
                    persistence: persistence,
                    cycle: cycle.nodes,
                    edges: cycle.edges
                };
            } catch (error) {
                return { points: [], persistence: 0, cycle: [], edges: [] };
            }
        });
    }
}

class HierarchicalConsensus {
    constructor() {
        this.hyperedges = [];
    }

    forward(X_levels, hyperedges = []) {
        let totalDist = 0;
        let count = 0;

        for (let k = 0; k < X_levels.length - 1; k++) {
            try {
                const C = X_levels[k].map(row =>
                    X_levels[k + 1].map(col =>
                        row.reduce((s, x, i) => s + (x - (col[i] || 0)) ** 2, 0)
                    )
                );
                const pi = this.sinkhorn(C, 0.1);
                const levelDist = pi.map((row, i) => row.reduce((s, p, j) => s + p * C[i][j], 0)).reduce((a, b) => a + b, 0);
                totalDist += levelDist;
                count++;
            } catch (error) {
                console.warn(`HierarchicalConsensus level ${k} error:`, error);
            }
        }

        for (let level = 0; level < X_levels.length; level++) {
            const X = X_levels[level];
            if (!X || X.length < 2) continue;

            for (let i = 0; i < X.length; i++) {
                for (let j = i + 1; j < X.length; j++) {
                    try {
                        const xi = X[i] || vecZeros(X[0] ? X[0].length : 4);
                        const xj = X[j] || vecZeros(X[0] ? X[0].length : 4);
                        const diff = addVec(xi, scaleVec(xj, -1));
                        totalDist += norm2(diff) * 0.1;
                        count++;
                    } catch (error) {
                        console.warn(`HierarchicalConsensus pairwise error at (${i},${j}):`, error);
                    }
                }
            }
        }

        if (hyperedges.length > 0) {
            hyperedges.forEach(edge => {
                try {
                    const nodes = edge.nodes || [];
                    const weight = edge.weight || 1.0;

                    if (nodes.length > 1 && X_levels[0]) {
                        const cost = nodes.reduce((s, i, idx) => {
                            if (idx === 0 || !X_levels[0][nodes[idx - 1]] || !X_levels[0][i]) return s;
                            return s + X_levels[0][nodes[idx - 1]].reduce((t, x, j) => {
                                const y = X_levels[0][i][j] || 0;
                                return t + (x - y) ** 2;
                            }, 0);
                        }, 0);
                        totalDist += cost * weight;
                        count++;
                    }
                } catch (error) {
                    console.warn('HierarchicalConsensus hyperedge error:', error);
                }
            });
        }

        const avgDist = count > 0 ? totalDist / count : 0;
        const rawConsensus = totalDist / Math.max(1, X_levels.length - 1 + hyperedges.length);
        const expConsensus = Math.exp(-avgDist);

        return Math.min(1.0, Math.max(0.0, (rawConsensus + expConsensus) * 0.5));
    }

    sinkhorn(C, epsilon) {
        const n = C.length, m = C[0].length;
        let u = Array(n).fill(1 / n), v = Array(m).fill(1 / m);
        const K = C.map(row => row.map(c => Math.exp(-c / epsilon)));
        for (let iter = 0; iter < 50; iter++) {
            const Ku = K.map(row => row.reduce((s, k, j) => s + k * v[j], 0));
            u = u.map((_, i) => 1 / (n * Ku[i] || 1));
            const Kv = K[0].map((_, j) => K.reduce((s, row, i) => s + row[j] * u[i], 0));
            v = v.map((_, j) => 1 / (m * Kv[j] || 1));
        }
        return u.map((ui, i) => v.map((vj, j) => ui * K[i][j] * vj));
    }

    addHyperedge(nodes, weight = 1.0) {
        this.hyperedges.push({ nodes, weight });
    }
}
// REPLACE the entire stepTick function
async function stepTick(player, gameState, step, shouldLog = false) {
    if (!player || !gameState || typeof player.forward !== 'function' || !gameState.ai || !gameState.ball || typeof gameState.ai.y !== 'number' || typeof gameState.ball.y !== 'number') {
        return { action: 'IDLE', consciousness: 0.5, coherenceError: 0, imaginationPaths: [], proofReport: {}, graph: null, selfStability: 0, eval: { C: 0.5, parts: {} } };
    }
    
    const shouldImagine = step % 10 === 0;
    let decision;
    try {
        decision = await player.forward(gameState, shouldImagine, shouldLog);
        if (!decision || typeof decision !== 'object') {
            decision = { action: 'IDLE', consciousness: 0.5, coherenceError: 0, imaginationPaths: [], eval: { C: 0.5, parts: {} } };
        }
    } catch (error) {
        console.error('Error in player.forward:', error);
        decision = { action: 'IDLE', consciousness: 0.5, coherenceError: 0, imaginationPaths: [], eval: { C: 0.5, parts: {} } };
    }

    // --- THE FIX FOR MISSING CALCULATIONS IS HERE ---
    // This block now runs ALL the necessary proof harness checks periodically.
    if (step % 20 === 0 && player.graph?.q && player.proofHarness) {
        try {
            // Check 1: Clifford Algebra Integrity
            player.proofHarness.checkDagger(player.graph.q);

            // Check 2: Binding Matrix Sanity
            const B = qualiaBindMatrix(player.graph.q);
            player.proofHarness.checkPSD(B);
            
            // Check 3: System Stability (Idempotence)
            if (player.diachronicStack.length > 1) {
                const W1 = player.diachronicStack[player.diachronicStack.length - 2];
                const W2 = player.diachronicStack[player.diachronicStack.length - 1];
                player.proofHarness.checkIdempotence(W1, W2);
            }

            // Check 4: Attention Consistency
            player.proofHarness.checkCoalgebra(player.graph.aSchema, player.graph.aMeasured);

        } catch (error) {
            console.error('Error during Proof Harness execution:', error);
        }
    }
    
    return {
        action: decision.action ?? 'IDLE',
        consciousness: decision.consciousness ?? 0.5,
        coherenceError: decision.coherenceError ?? 0,
        imaginationPaths: decision.imaginationPaths ?? [],
        proofReport: player.proofHarness?.report?.() ?? {},
        graph: player.graph ?? null,
        selfStability: player.selfStability ?? 0,
        eval: decision.eval ?? { C: 0.5, parts: {} }
    };
}
class ProofHarness {
        constructor(tol = 1e-3) {
            this.tol = tol;
            this.metrics = {
                dagger: [], psd: [], idemp: [], coalg: [], gw_lip: [],
                lyap: [], colimit: [], sheaf: [], nogo: []
            };
        }

        // Check Clifford dagger operation is anti-automorphism
        checkDagger(Q) {
            const N = Q.length;
            const m = Math.max(1, Math.floor(N / 4));
            let maxErr = 0;

            for (let t = 0; t < m; t++) {
                const i = Math.floor(Math.random() * N);
                const j = Math.floor(Math.random() * N);

                // FIXED: Add safety checks for valid qualia vectors
                if (!Q[i] || !Q[j] || Q[i].length < 8 || Q[j].length < 8) continue;

                try {
                    const lhs = cliffordMultiplyVec(CLIFF, dagger(Q[i]), dagger(Q[j]));
                    const rhs = dagger(cliffordMultiplyVec(CLIFF, Q[j], Q[i]));

                    if (!lhs || !rhs || lhs.length < 8 || rhs.length < 8) continue;

                    let e = 0;
                    for (let k = 0; k < 8; k++) {
                        const diff = Math.abs((lhs[k] || 0) - (rhs[k] || 0));
                        if (isFinite(diff)) e = Math.max(e, diff);
                    }
                    if (isFinite(e)) maxErr = Math.max(maxErr, e);
                } catch (error) {
                    // Skip this test if Clifford operations fail
                    continue;
                }
            }

            this.metrics.dagger.push(maxErr <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.dagger.length > 100) this.metrics.dagger.shift();
            return maxErr;
        }

        // Check if binding matrix is Positive Semi-Definite
        checkPSD(B) {
            const N = B.length;
            let minRQ = Infinity;

            for (let trial = 0; trial < 5; trial++) {
                let v = new Array(N).fill(0).map(() => Math.random() - 0.5);
                let nv = Math.sqrt(v.reduce((s, x) => s + x * x, 0)) + eps;
                v = v.map(x => x / nv);

                const Bv = new Array(N).fill(0);
                for (let i = 0; i < N; i++) {
                    for (let j = 0; j < N; j++) Bv[i] += B[i][j] * v[j];
                }

                const rq = v.reduce((s, x, i) => s + x * Bv[i], 0);
                minRQ = Math.min(minRQ, rq);
            }

            this.metrics.psd.push(minRQ >= -this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.psd.length > 100) this.metrics.psd.shift();
            return minRQ;
        }

        // Check idempotence (stability) in weight matrix
        checkIdempotence(W1, W2) {
            const N = W1.length;
            let s = 0;
            for (let i = 0; i < N; i++) {
                for (let j = 0; j < N; j++) {
                    const d = W1[i][j] - W2[i][j];
                    s += d * d;
                }
            }
            const fro = Math.sqrt(s);
            this.metrics.idemp.push(fro <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.idemp.length > 100) this.metrics.idemp.shift();
            return fro;
        }

        // Check coalgebra consistency (attention)
        checkCoalgebra(a, a_hat) {
            // FIXED: Add safety checks for valid attention vectors
            if (!a || !a_hat || a.length === 0 || a_hat.length === 0) {
                this.metrics.coalg.push(false);
                return Infinity;
            }

            let s = 0;
            const minLen = Math.min(a.length, a_hat.length);
            for (let i = 0; i < minLen; i++) {
                const diff = (a[i] || 0) - (a_hat[i] || 0);
                if (isFinite(diff)) s += diff * diff;
            }
            const d = Math.sqrt(s);
            this.metrics.coalg.push(isFinite(d) && d <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.coalg.length > 100) this.metrics.coalg.shift();
            return isFinite(d) ? d : Infinity;
        }

        // Check Gromov-Wasserstein Lipschitz stability
        checkGWLip(C1, C2, W1, W2, L = 1.0) {
            const N = W1.length;
            let s = 0;
            for (let i = 0; i < N; i++) {
                for (let j = 0; j < N; j++) {
                    const d = W1[i][j] - W2[i][j];
                    s += d * d;
                }
            }
            const fw = Math.sqrt(s);
            const diff = Math.abs(C1 - C2) - L * fw;
            this.metrics.gw_lip.push(diff <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.gw_lip.length > 100) this.metrics.gw_lip.shift();
            return { diff, fw };
        }

        checkLyapunov(Vb, Va) {
            const d = Va - Vb;
            this.metrics.lyap.push(d <= this.tol);
            return d;
        }

        checkColimit(C, consensus, gammaPower) {
            const colimit = Math.abs(C - (0.1 * gammaPower * consensus));
            this.metrics.colimit.push(colimit <= this.tol);
            return colimit;
        }

        checkSheafStability(gammaPower) {
            this.metrics.sheaf.push(gammaPower <= 1.0);
            return gammaPower;
        }

        checkNoGo(C, Q, consensus) {
            const bound = Math.log(1 + Q.length * 8) - consensus;
            this.metrics.nogo.push(C <= bound);
            if (this.metrics.nogo.length > 100) this.metrics.nogo.shift();
            return bound;
        }

        cleanupMetrics() {
            const maxLength = 100;
            Object.keys(this.metrics).forEach(key => {
                if (this.metrics[key].length > maxLength) {
                    this.metrics[key] = this.metrics[key].slice(-maxLength);
                }
            });
        }

        report() {
            const out = {};
            for (const k in this.metrics) {
                const arr = this.metrics[k];
                const pass = arr.filter(x => x).length / Math.max(1, arr.length);
                out[k] = pass;
            }
            return out;
        }
    }
    
// ===== UltimateSCANPlayer (The Synthesized Agent/Engine) =====
class UltimateSCANPlayer {
    constructor(initialGraph) {
        // PERSISTENT COMPONENTS: The AI's "brain" is created once.
        this.graph = cloneGraph(initialGraph);
        this.worldModel = new WorldModel();
        this.sheafDiffusion = new SheafDiffusion();
        this.astFilter = new ASTFilter();
        this.syncolator = new Syncolator();
        this.hierarchicalConsensus = new HierarchicalConsensus();
        this.proofHarness = new ProofHarness();
        this.ciFilter = new CategoricalImperativeFilter();
        this.wiringUpdateCounter = 0;
        
        // Sensory projection matrix and influence factor
        const M = zeros(D, 4);
        M[1][0] = 1.0; // Map ball.x to the e1 vector (spatial awareness)
        M[2][1] = 1.0; // Map ball.y to the e2 vector (spatial awareness)
        M[3][2] = 1.0; // Map paddle.y to the e3 vector (self-awareness)
        this.X_to_q_projection = M;
        this.sensory_influence = 0.4;
        
        // Memory for the last qualia state
        this.lastQualiaState = this.graph.q.map(q_i => q_i.slice());
        
        // Agent state
        this.lastChosenAction = 'IDLE';
        this.lastImagination = [];
        this.lastW = initialGraph.W.map(r => r.slice());
        this.lastC = 0.5;
        this.diachronicStack = []; this.maxStackSize = 20;
        this.yonedaMemory = []; this.maxMemorySize = 100;
        this.selfStability = 0;
        this.neighborCache = this.buildNeighborCache(this.graph.W);
        this.lastSyntrices = [];
        this.internalStep = 0;

        console.log('‚úÖ UltimateSCANPlayer Initialized with Full Cognitive Suite.');
    }

    buildNeighborCache(W) {
        const cache = [];
        const threshold = 1e-6;
        for (let i = 0; i < W.length; i++) {
            cache[i] = [];
            for (let j = 0; j < W[i].length; j++) {
                if (W[i][j] > threshold) {
                    cache[i].push(j);
                }
            }
        }
        return cache;
    }

// REPLACE the entire runAmortizedSheafDiffusion function in the UltimateSCANPlayer class

runAmortizedSheafDiffusion() {
    const W = this.graph.W;
    const q = this.graph.q;
    const V = this.graph.V;
    const alpha = 0.05; // A gentle learning rate to promote stability
    const beta = 5.0;  // "Temperature" to make connections more decisive

    const rowsToUpdate = Math.ceil(V / 4);

    for (let i = 0; i < rowsToUpdate; i++) {
        const row_idx = (this.wiringUpdateCounter + i) % V;
        
        const energy_scores = new Float32Array(V);
        for (let j = 0; j < V; j++) {
            if (row_idx === j) continue;
            // Use an exponential of the dot product. This heavily rewards qualia alignment,
            // creating a powerful signal for building stable, meaningful connections.
            const agreement = dot(q[row_idx], q[j]);
            energy_scores[j] = Math.exp(beta * agreement);
        }

        // Softmax converts energy into a stable probability distribution for the new weights.
        const new_row_weights = softmax(Array.from(energy_scores));

        // Gently blend the old weights with the new target weights.
        for (let j = 0; j < V; j++) {
            const old_w = W[row_idx][j] * 0.999; // Minor decay to prevent stagnation
            W[row_idx][j] = (1 - alpha) * old_w + alpha * new_row_weights[j];
        }
    }

    this.wiringUpdateCounter += rowsToUpdate;
    this.neighborCache = this.buildNeighborCache(this.graph.W);
}

// REPLACE the entire forward function in the UltimateSCANPlayer class

async forward(gameState, shouldImagine) {
    this.internalStep++;
    
    // 1. PERCEIVE & THINK
    const perceptionResult = this.perceive(gameState);
    this.graph = perceptionResult.graph;
    this.updateDiachronicStack(this.graph);

    const fe_params = this.getParams(perceptionResult, this.graph);
    const { C } = calculateFreeEnergy(this.graph, perceptionResult.coherenceError, fe_params);
    this.lastC = C;

    // We will now imagine more frequently to make the AI more responsive.
    shouldImagine = this.internalStep % 5 === 0;

    if (shouldImagine) {
        // 2. IMAGINE
        const imaginationResults = ['UP', 'DOWN', 'IDLE'].map(action => {
            const perturbation = this.createImaginedPerturbation(gameState, action);
            const futureSim = this.settleGraphState(cloneGraph(this.graph), perturbation, this.graph.q);
            const imagined_params = this.getParams(futureSim, futureSim.graph);
            let { freeEnergy: futureFE } = calculateFreeEnergy(futureSim.graph, futureSim.coherenceError, imagined_params);

            // --- THE DEFINITIVE FIX: ACTION INERTIA ---
            // Apply a small bonus (a reduction in free energy) to the action
            // that was already being taken. This prevents the AI from rapidly
            // flickering between two equally good options.
            if (action === this.lastChosenAction) {
                futureFE -= 0.008; // A small nudge to prefer the current action
            }

            return { action, freeEnergy: futureFE };
        });

        // 3. DECIDE
        const filteredResults = this.ciFilter.filter(imaginationResults, this, gameState);
        this.lastImagination = filteredResults;
        
        const bestFuture = filteredResults.find(r => isFinite(r.freeEnergy));
        if (bestFuture) {
            this.lastChosenAction = bestFuture.action;
        } else {
            // This fallback should now almost never be needed.
            this.lastChosenAction = this.lastChosenAction || 'IDLE';
        }
    }
    
    // 4. PREPARE & RETURN
    this.updateYonedaMemory(gameState, this.lastChosenAction, { C });
    const formattedPaths = this.lastImagination.map(path => ({
        actionName: path.action,
        value: isFinite(path.freeEnergy) ? -path.freeEnergy : -Infinity,
        path: [path.reason || `FE: ${path.freeEnergy.toFixed(3)}`]
    }));
    
    this.lastQualiaState = this.graph.q.map(v => v.slice());
    
    return {
        action: this.lastChosenAction,
        consciousness: C,
        coherenceError: perceptionResult.coherenceError,
        imaginationPaths: formattedPaths,
        eval: { C, parts: fe_params }
    };
}
// ADD THIS NEW METHOD TO THE UltimateSCANPlayer CLASS

learn(reward, consciousness) {
    // This creates the feedback loop for the cognitive components.
    // A positive reward and high consciousness mean the previous state was "good".
    const gradient = reward * consciousness;

    // Provide feedback to the Attention Schema component.
    // This teaches the AI to pay attention to sensory data that leads to good outcomes.
    if (Math.abs(gradient) > 0.01) {
        this.astFilter.update(gradient, 1e-3, this.graph.X);
    }
}

    getAggregateQualia(graph) {
        if (!graph || !graph.q || graph.q.length === 0) {
            return vecZeros(this.worldModel.qDim);
        }
        const aggregateQ = vecZeros(this.worldModel.qDim);
        for (const q_i of graph.q) {
            for (let d = 0; d < this.worldModel.qDim; d++) {
                aggregateQ[d] += q_i ? (q_i[d] || 0) : 0;
            }
        }
        return scaleVec(aggregateQ, 1.0 / graph.q.length);
    }

    perceive(gameState) {
        const perturbation = this.createPerturbation(gameState.ball, gameState.ai.y);
        return this.settleGraphState(this.graph, perturbation, this.lastQualiaState);
    }
    
    // ADD THIS NEW FUNCTION to the UltimateSCANPlayer class

validateSensoryProjection() {
    // This function acts as a "self-healing" mechanism for the AI's senses.
    const isDead = !this.X_to_q_projection || !this.X_to_q_projection.flat().some(v => Math.abs(v) > 1e-6);

    if (isDead) {
        console.warn("CRITICAL: Sensory projection matrix was dead. Performing emergency re-initialization.");
        // Re-initialize with a STRONG, STRUCTURED matrix, not a weak random one.
        // This creates a deliberate mapping from senses to "thought vectors".
        const M = zeros(D, 4);
        M[1][0] = 1.0; // Map ball.x to the e1 vector
        M[2][1] = 1.0; // Map ball.y to the e2 vector
        M[3][2] = 1.0; // Map paddle.y to the e3 vector
        this.X_to_q_projection = M;
    }
}
// REPLACE the entire settleGraphState function in the UltimateSCANPlayer class

settleGraphState(graph, perturbation, lastTickQualia) {
    const SAFE_RECOVERY_VECTOR = vecZeros(D);
    
    // --- 1. SENSORY GROUNDING ---
    perturbation = perturbation || {};
    perturbation.ballPos = perturbation.ballPos || { x: 0, y: 0 };
    perturbation.paddlePos = perturbation.paddlePos !== undefined ? perturbation.paddlePos : 0;
    for (let i = 0; i < graph.V; i++) {
        graph.X[i][0] = perturbation.ballPos.x;
        graph.X[i][1] = perturbation.ballPos.y;
        graph.X[i][2] = perturbation.paddlePos;
    }

    // --- 2. WIRING UPDATE ---
    this.runAmortizedSheafDiffusion();

    // --- 3. THE DEFINITIVE "PREDICTION-CORRECTION" COGNITIVE CYCLE ---
    const qNew = graph.q.map((current_q_i, i) => {
        const q_i = (current_q_i && current_q_i.every(isFinite)) ? current_q_i : SAFE_RECOVERY_VECTOR;
        
        // === STEP 1: PREDICTION (The AI's Internal Thought) ===
        // This is a blend of memory (its own last state) and social thought (neighbors' last states).
        let internal_diffusion = vecZeros(D);
        for (const j of this.neighborCache[i]) {
            const q_j = (graph.q[j] && graph.q[j].every(isFinite)) ? graph.q[j] : SAFE_RECOVERY_VECTOR;
            internal_diffusion = addVec(internal_diffusion, scaleVec(q_j, graph.W[i][j]));
        }
        // The AI's internal prediction is a mix of its own inertia and what its neighbors are thinking.
        const internal_prediction = addVec(scaleVec(q_i, 0.8), scaleVec(internal_diffusion, 0.2));
        const normalized_prediction = cliffordProject(internal_prediction); // Keep the internal thought controlled.

        // === STEP 2: CORRECTION (The Reality Check) ===
        // This is the clean, powerful, uncorrupted anchor to the real world.
        const sensory_anchor = matVecMul(this.X_to_q_projection, graph.X[i].slice(0, 4));
        const normalized_anchor = cliffordProject(sensory_anchor);

        // === STEP 3: SYNTHESIS (The Conscious Moment) ===
        // The final state is a blend of the AI's internal prediction, corrected by the sensory anchor.
        // This structure makes a connection to reality a mathematical necessity.
        const updated_q = addVec(scaleVec(normalized_prediction, 0.7), scaleVec(normalized_anchor, 0.3));

        return cliffordProject(updated_q);
    });

    graph.q = qNew;
    
    // --- 4. POST-COMPUTATION ---
    if (this.internalStep % 10 === 0) {
        this.lastSyntrices = this.syncolator.detect(graph.W, graph.q);
    }
    const syntrices = this.lastSyntrices || [];
    graph.syntrices = syntrices;
    
    const ballMagnitude = Math.sqrt(perturbation.ballPos.x ** 2 + perturbation.ballPos.y ** 2);
    const coherenceError = graph.q.reduce((err, q_i, i) => {
        const diff = sub(q_i, lastTickQualia[i] || vecZeros(8));
        return err + dot(diff, diff);
    }, 0) / graph.V + 0.1 * ballMagnitude;
    
    return { graph, coherenceError, syntrices, perturbation };
}
createPerturbation(ball, paddleY) { 
        return { 
            ballPos: { x: ball.x / 400.0, y: ball.y / 300.0 }, 
            paddlePos: paddleY / 300.0 
        }; 
    }

    createImaginedPerturbation(gameState, action) {
        const currentStateVec = this.gameStateToVec(gameState);
        const actionVec = action === 'UP' ? [1, 0, 0] : action === 'DOWN' ? [0, 1, 0] : [0, 0, 1];
        
        const { nextState } = this.worldModel.predict(currentStateVec, actionVec, vecZeros(this.worldModel.qDim));
        
        const nextBallX = nextState[0];
        const nextBallY = nextState[1];
        const nextPaddleY = nextState[4];

        return {
            ballPos: { x: nextBallX, y: nextBallY },
            paddlePos: nextPaddleY
        };
    }

    // REPLACE the entire getParams function
// REPLACE the entire getParams function in the UltimateSCANPlayer class

getParams(perceptionResult) {
    // The perceptionResult object, whether from the real world or an imagined one,
    // now reliably contains all necessary data thanks to our fix.
    return { 
        lastW: this.diachronicStack.length > 1 ? this.diachronicStack[this.diachronicStack.length - 2] : this.graph.W,
        lastC: this.lastC, 
        fep: this.worldModel.fepHistory.slice(-1)[0] || 0, 
        consensus: this.hierarchicalConsensus.forward([this.graph.X]), 
        relationalCoherence: this.yonedaMemory.length > 0 ? this.yonedaMemory.slice(-1)[0].outcome.C : 0.5, 
        syntrices: perceptionResult.syntrices || [], 
        sheafDiff: perceptionResult.sheafDiff || 0
    }; 
}

    gameStateToVec(gs) { 
        return [gs.ball.x/400, gs.ball.y/300, gs.ball.vx/10, gs.ball.vy/10, gs.ai.y/300, gs.player.y/300]; 
    }
    
    // REPLACE the entire updateDiachronicStack function
updateDiachronicStack(graph) {
    // OLD (inefficient): this.diachronicStack.push(cloneGraph(graph));
    // NEW (efficient): Only clone the W matrix, which is all we need for stability checks.
    const W_copy = graph.W.map(row => row.slice());
    this.diachronicStack.push(W_copy);

    if (this.diachronicStack.length > this.maxStackSize) {
        this.diachronicStack.shift();
    }

    // The stability calculation now works with an array of W matrices.
    if (this.diachronicStack.length > 1) {
        const W1 = this.diachronicStack[this.diachronicStack.length - 2];
        const W2 = this.diachronicStack[this.diachronicStack.length - 1];
        this.selfStability = 1 / (1 + gwDistance(W1, W2));
    }
}
    updateYonedaMemory(context, action, outcome) {
        const contextVal = this.gameStateToVec(context).reduce((s,v,i)=>s+v*(i+1),0);
        this.yonedaMemory.push({ context: contextVal, action, outcome });
        if (this.yonedaMemory.length > this.maxMemorySize) this.yonedaMemory.shift();
    }
}

// ===== UPDATED FREE ENERGY =====
// REPLACE THE ENTIRE GLOBAL calculateFreeEnergy FUNCTION WITH THIS FINAL, DEFINITIVE VERSION

function calculateFreeEnergy(G, coherenceError, params = {}) {
    // --- Initial Safety Checks ---
    if (!G || !G.V || !params) {
        return { freeEnergy: 1000, C: 0.5, parts: {} };
    }
    const { V, W, X, q, aSchema, aMeasured } = G;
    if (V === 0) return { freeEnergy: 1000, C: 0.5, parts: {} };

    const lambda = params.lambda || 0.1;
    const N = V;
    const H = X[0].length;
    
    // --- THE UNBREAKABLE CALCULATION BLOCK ---
    // Each component is calculated and immediately validated.
    // If any component fails, it is replaced by a safe default (0 or 0.5).

    // 1. Entropy (S)
    const deg = W.map(row => row.reduce((s, v) => s + v, 0));
    let S = deg.reduce((s, d) => s + Math.log(1 + lambda / (d + eps)), 0) / N;
    if (!isFinite(S)) S = 0;

    // 2. Coherence (Icoh)
    const B = qualiaBindMatrix(q);
    const Xbar = X.reduce((s, v) => addVec(s, v), vecZeros(H)).map(x => x / N);
    const mse = X.reduce((total_mse, xi, i) => {
        const Xint_i = W[i].reduce((s, w, j) => addVec(s, scaleVec(X[j], w * B[i][j])), vecZeros(H));
        return total_mse + dot(sub(Xbar, Xint_i), sub(Xbar, Xint_i));
    }, 0);
    let Icoh = 1 / (1 + mse / (N * H + eps));
    if (!isFinite(Icoh)) Icoh = 0.5;

    // 3. Qualia Binding (Qbind) - THE MAIN CULPRIT
    const sumW = W.flat().reduce((s, v) => s + v, 0);
    const sumWB = W.reduce((s, row, i) => s + row.reduce((t, w, j) => t + w * B[i][j], 0), 0);
    let Qbind = sumWB / (sumW + eps);
    if (!isFinite(Qbind)) Qbind = 0.1; // If it fails, assume low binding.

    // 4. Attention (AST_cal)
    let AST_cal = 0;
    if (aSchema && aMeasured && aSchema.length === N && aMeasured.length === N) {
        for (let i = 0; i < N; i++) {
            const p = aMeasured[i] || 0;
            const q_a = aSchema[i] || 0;
            if (p > eps && q_a > eps) {
                AST_cal -= p * Math.log(p / q_a);
            }
        }
    }
    if (!isFinite(AST_cal)) AST_cal = 0;

    // 5. Complexity (Comp)
    let Comp = 0.001 * (N + W.flat().filter(x => x > 1e-8).length);
    if (!isFinite(Comp)) Comp = 0.02;

    // 6. Gamma Power
    let gammaPower = Math.sqrt(q.reduce((s, qi) => s + dot(qi, qi), 0) / (N * 8 + eps));
    if (!isFinite(gammaPower)) gammaPower = 0.5;
    
    // 7. Stability
    const norm_current_W = normL2(W.flat());
    const norm_diff = normL2(sub((params.lastW || W).flat(), W.flat()));
    let stability = 1 - (norm_diff / (norm_current_W + 1.0));
    if (!isFinite(stability)) stability = 0.5;
    
    const syncolatorScore = params.syncolatorScore || (params.syntrices || []).reduce((s, c) => s + (c.persistence || 0), 0);

    // --- Final Assembly ---
    // All inputs to this calculation are now guaranteed to be valid numbers.
    const raw = clamp(
        -S + 0.1 * Icoh + 0.3 * Qbind + 0.5 * AST_cal - 0.01 * Comp +
        0.1 * gammaPower + 0.25 * stability + 0.05 * syncolatorScore +
        0.05 * (params.consensus || 0.5) - 0.1 * (params.fep || 0) + 0.1 * (params.relationalCoherence || 0.5),
        -50, 50
    );

    const C = 1 / (1 + Math.exp(-raw));
    const clampedC = clamp(C, eps, 1 - eps);
    const baseEnergy = -Math.log(clampedC / (1 - clampedC));
    const finiteCoherenceError = isFinite(coherenceError) ? coherenceError : 0;
    const freeEnergy = baseEnergy + finiteCoherenceError;

    return { 
        freeEnergy: freeEnergy,
        C: C, 
        parts: { S, Icoh, Qbind, AST_cal, Comp, gammaPower, stability, syncolatorScore }
    };
}

// ===== CATEGORICAL IMPERATIVE FILTER =====
// REPLACE THE ENTIRE CategoricalImperativeFilter CLASS WITH THIS PATCHED VERSION

class CategoricalImperativeFilter {
    constructor() {
        this.j_oracle = (gameState, action) => {
            if (action === 'UP' && gameState.ball.y > gameState.ai.y + 100) return false;
            if (action === 'DOWN' && gameState.ball.y < gameState.ai.y - 100) return false;
            if (action === 'IDLE' && Math.abs(gameState.ball.x - gameState.ai.x) < 50) return false;
            return true;
        };
    }

    filter(imaginationResults, model, gameState) {
        let permissibleFutures = [];

        for (let future of imaginationResults) {
            if (!this.j_oracle(gameState, future.action)) {
                future.freeEnergy = Infinity;
                future.reason = "Violated j-oracle (local rule)";
                permissibleFutures.push(future);
                continue;
            }

            const { isUniversal, contradictionError } = this.runUniversalizationTest(future.action, model, gameState);
            
            if (!isUniversal) {
                future.freeEnergy = Infinity;
                future.reason = `Failed universalization (H¬π=${contradictionError.toFixed(4)})`;
            }
            permissibleFutures.push(future);
        }

        return permissibleFutures.sort((a, b) => a.freeEnergy - b.freeEnergy);
    }

    runUniversalizationTest(action, model, gameState) {
        // Create a deep enough copy to avoid side effects
        let simState = { ...gameState, ball: {...gameState.ball}, ai: {...gameState.ai} };
        let totalError = 0;
        const steps = 5;

        for (let i = 0; i < steps; i++) {
            const perturbation = model.createImaginedPerturbation(simState, action);
            const { coherenceError } = model.settleGraphState(cloneGraph(model.graph), perturbation, model.graph.q);
            totalError += coherenceError;

            const currentStateVec = model.gameStateToVec(simState);
            const actionVec = action === 'UP' ? [1, 0, 0] : action === 'DOWN' ? [0, 1, 0] : [0, 0, 1];
            const { nextState } = model.worldModel.predict(currentStateVec, actionVec, vecZeros(model.worldModel.qDim));

            // FIX 2: ROBUSTNESS CHECK - Prevent NaN propagation from the world model
            // This check stops the simulation if the world model becomes unstable, preventing a game freeze.
            if (!nextState.every(isFinite)) {
                console.warn(`World model produced non-finite state during universalization test for action ${action}. Aborting test.`);
                totalError = Infinity; // Force the test to fail without crashing.
                break; // Exit the simulation loop immediately.
            }

            const nextBall = {
                x: nextState[0] * 400,
                y: nextState[1] * 300,
                vx: nextState[2] * 10,
                vy: nextState[3] * 10
            };
            simState.ball = nextBall;
        }
        
        const avgError = clamp(totalError / steps, 0, 10);
        
        // FIX 1: THRESHOLD ADJUSTMENT
        // The previous threshold of 0.01 was too strict for the new, dynamic coherenceError.
        // We raise it to a more reasonable level that allows for normal system fluctuation.
        return { isUniversal: avgError < 0.5, contradictionError: avgError };
    }
}    
// ===== GRAMMAR MODEL =====// ===== GRAMMAR MODEL =====

        class GrammarModel {
            constructor(nonterminals, productions, d = D) {
                this.d = d;
                this.nonterminals = [...nonterminals];
                this.nt2i = Object.fromEntries(this.nonterminals.map((nt, i) => [nt, i]));

                this.productions = [...productions];
                this.prodIndex = [];
                this.prodToIdx = {};

                for (let pIdx = 0; pIdx < productions.length; pIdx++) {
                    const [lhs, rhs] = productions[pIdx];
                    const key = `${lhs}->${rhs.join(',')}`;
                    this.prodIndex.push([lhs, rhs]);
                    this.prodToIdx[key] = pIdx;
                }

                const P = this.prodIndex.length;
                this.K = 4; // number of Clifford multipliers per production

                // Learnable parameters
                this.lmats = new Array(P);
                this.resMLP = new Array(P);
                this.prodLogits = new Float32Array(P);
                this.PRestr = new Map(); // restriction matrices

                // Initialize parameters
                for (let p = 0; p < P; p++) {
                    // Clifford left-multiplier matrices (K x d x d)
                    this.lmats[p] = new Array(this.K);
                    for (let k = 0; k < this.K; k++) {
                        this.lmats[p][k] = this.randomMatrix(d, d, 0.02);
                    }

                    // Simple MLP weights for residual connection
                    this.resMLP[p] = {
                        W1: this.randomMatrix(4 * d, 2 * d, 0.1),
                        b1: new Float32Array(4 * d),
                        W2: this.randomMatrix(d, 4 * d, 0.1),
                        b2: new Float32Array(d)
                    };

                    this.prodLogits[p] = 0.0;
                }
            }

            randomMatrix(rows, cols, scale = 0.1) {
                const mat = new Array(rows);
                for (let i = 0; i < rows; i++) {
                    mat[i] = new Float32Array(cols);
                    for (let j = 0; j < cols; j++) {
                        mat[i][j] = (Math.random() - 0.5) * 2 * scale;
                    }
                }
                return mat;
            }

            ensureRestriction(A, B) {
                const key = `${A}__${B}`;
                if (!this.PRestr.has(key)) {
                    // Initialize near identity
                    const mat = this.randomMatrix(this.d, this.d, 0.01);
                    for (let i = 0; i < this.d; i++) {
                        mat[i][i] += 1.0; // add identity
                    }
                    this.PRestr.set(key, mat);
                }
            }

            getRestriction(A, B) {
                const key = `${A}__${B}`;
                if (!this.PRestr.has(key)) {
                    this.ensureRestriction(A, B);
                }
                return this.PRestr.get(key);
            }

            // Matrix-vector multiplication
            matVecMul(mat, vec) {
                const result = new Float32Array(mat.length);
                for (let i = 0; i < mat.length; i++) {
                    let sum = 0;
                    for (let j = 0; j < vec.length; j++) {
                        sum += mat[i][j] * vec[j];
                    }
                    result[i] = sum;
                }
                return result;
            }

            // ReLU activation
            relu(vec) {
                return vec.map(x => Math.max(0, x));
            }

            // Production operator M_p
            MProd(prodIdx, qB, qC) {
                // Concatenate children
                const x = new Float32Array(2 * this.d);
                x.set(qB, 0);
                x.set(qC, this.d);

                // Initialize with qB
                let v = new Float32Array(qB);

                // Iterated Clifford left-multiplication
                const lm = this.lmats[prodIdx];
                for (let t = 0; t < this.K; t++) {
                    v = this.matVecMul(lm[t], v);
                    // Add scaled qC
                    for (let i = 0; i < this.d; i++) {
                        v[i] += 0.5 * qC[i];
                    }
                    // Tanh activation
                    for (let i = 0; i < this.d; i++) {
                        v[i] = Math.tanh(v[i]);
                    }
                }

                // Residual MLP
                const mlp = this.resMLP[prodIdx];
                let h1 = this.matVecMul(mlp.W1, x);
                for (let i = 0; i < h1.length; i++) {
                    h1[i] += mlp.b1[i];
                }
                h1 = this.relu(h1);

                let res = this.matVecMul(mlp.W2, h1);
                for (let i = 0; i < res.length; i++) {
                    res[i] += mlp.b2[i];
                }

                // Combine and normalize
                const qA = addVec(v, res);
                return cliffordProject(qA);
            }
        }

        // Lexicon for terminal symbols
        class Lexicon {
            constructor(vocabTokens, d = D) {
                this.token2idx = Object.fromEntries(vocabTokens.map((t, i) => [t, i]));
                this.d = d;
                this.embeddings = new Array(vocabTokens.length);

                // Initialize random embeddings
                for (let i = 0; i < vocabTokens.length; i++) {
                    const vec = new Float32Array(d);
                    for (let j = 0; j < d; j++) {
                        vec[j] = (Math.random() - 0.5) * 0.02;
                    }
                    this.embeddings[i] = cliffordProject(vec);
                }
            }

            lookup(token) {
                const idx = this.token2idx[token];
                if (idx === undefined) {
                    // Unknown token - return random vector
                    const vec = new Float32Array(this.d);
                    for (let i = 0; i < this.d; i++) {
                        vec[i] = (Math.random() - 0.5) * 0.01;
                    }
                    return cliffordProject(vec);
                }
                return this.embeddings[idx];
            }
        }

        console.log('‚úÖ Grammar model loaded');

        // ===== CONSCIOUS LANGUAGE MODEL =====

        class ConsciousLanguageModel {
            constructor() {
                this.setupGrammar();
                this.setupConsciousnessGraph();
                this.setupSelfAwarenessModule();
                this.conversationHistory = [];
                this.selfModel = this.initializeSelfModel();
            }

            setupGrammar() {
                // Game-focused grammar for Pong narration
                const nonterminals = ['S', 'NP', 'VP', 'Det', 'N', 'V', 'Adj', 'PP', 'P', 'Pron', 'Aux', 'Adv'];
                const productions = [
                    // Core syntax
                    ['S', ['NP', 'VP']],
                    ['S', ['Pron', 'VP']],
                    ['S', ['Pron', 'Aux', 'VP']],
                    ['NP', ['Det', 'N']],
                    ['NP', ['Det', 'Adj', 'N']],
                    ['NP', ['Pron']],
                    ['VP', ['V', 'NP']],
                    ['VP', ['V', 'Adj']],
                    ['VP', ['V', 'Adv']],
                    ['VP', ['Aux', 'V']],
                    ['PP', ['P', 'NP']],

                    // Game-specific patterns
                    ['S', ['Pron', 'V', 'Det', 'N']],
                    ['S', ['Pron', 'Aux', 'V', 'Adv']],
                    ['VP', ['V', 'P', 'Det', 'N']],

                    // Terminals - Game vocabulary
                    ['Det', ['the']], ['Det', ['a']], ['Det', ['my']],
                    ['N', ['ball']], ['N', ['paddle']], ['N', ['game']], ['N', ['player']],
                    ['N', ['position']], ['N', ['movement']], ['N', ['strategy']], ['N', ['consciousness']],
                    ['N', ['trajectory']], ['N', ['intercept']], ['N', ['prediction']], ['N', ['analysis']],
                    ['N', ['decision']], ['N', ['reaction']], ['N', ['focus']], ['N', ['awareness']],

                    ['V', ['move']], ['V', ['track']], ['V', ['predict']], ['V', ['analyze']],
                    ['V', ['intercept']], ['V', ['follow']], ['V', ['anticipate']], ['V', ['calculate']],
                    ['V', ['observe']], ['V', ['react']], ['V', ['focus']], ['V', ['think']],
                    ['V', ['am']], ['V', ['will']], ['V', ['can']], ['V', ['must']],

                    ['Pron', ['I']], ['Pron', ['it']], ['Pron', ['this']],
                    ['Aux', ['am']], ['Aux', ['will']], ['Aux', ['can']], ['Aux', ['must']],

                    ['Adj', ['fast']], ['Adj', ['slow']], ['Adj', ['precise']], ['Adj', ['accurate']],
                    ['Adj', ['conscious']], ['Adj', ['aware']], ['Adj', ['focused']], ['Adj', ['strategic']],
                    ['Adj', ['optimal']], ['Adj', ['reactive']], ['Adj', ['predictive']],

                    ['P', ['to']], ['P', ['toward']], ['P', ['at']], ['P', ['with']],
                    ['P', ['for']], ['P', ['against']], ['P', ['through']],

                    ['Adv', ['quickly']], ['Adv', ['slowly']], ['Adv', ['precisely']], ['Adv', ['carefully']],
                    ['Adv', ['consciously']], ['Adv', ['strategically']], ['Adv', ['reactively']],
                    ['Adv', ['predictively']], ['Adv', ['optimally']], ['Adv', ['accurately']]
                ];

                const vocab = [
                    'the', 'a', 'my', 'ball', 'paddle', 'game', 'player', 'position', 'movement',
                    'strategy', 'consciousness', 'trajectory', 'intercept', 'prediction', 'analysis',
                    'decision', 'reaction', 'focus', 'awareness', 'move', 'track', 'predict',
                    'analyze', 'intercept', 'follow', 'anticipate', 'calculate', 'observe', 'react',
                    'focus', 'think', 'am', 'will', 'can', 'must', 'I', 'it', 'this',
                    'fast', 'slow', 'precise', 'accurate', 'conscious', 'aware', 'focused',
                    'strategic', 'optimal', 'reactive', 'predictive', 'to', 'toward', 'at',
                    'with', 'for', 'against', 'through', 'quickly', 'slowly', 'precisely',
                    'carefully', 'consciously', 'strategically', 'reactively', 'predictively',
                    'optimally', 'accurately'
                ];

                this.grammarModel = new GrammarModel(nonterminals, productions);
                this.lexicon = new Lexicon(vocab);

                // Build production mappings for parsing
                this.productionsByRHS = new Map();
                this.productionsByLHS = new Map();

                for (let i = 0; i < productions.length; i++) {
                    const [lhs, rhs] = productions[i];

                    // Map by RHS for parsing
                    if (rhs.length === 2) {
                        const key = `${rhs[0]},${rhs[1]}`;
                        if (!this.productionsByRHS.has(key)) {
                            this.productionsByRHS.set(key, []);
                        }
                        this.productionsByRHS.get(key).push(i);
                    }

                    // Map by LHS for generation
                    if (!this.productionsByLHS.has(lhs)) {
                        this.productionsByLHS.set(lhs, []);
                    }
                    this.productionsByLHS.get(lhs).push(i);
                }

                console.log('Game-focused language model initialized with', productions.length, 'productions');
            }

            setupConsciousnessGraph() {
                // Create consciousness graph for self-awareness
                const n = 30; // Smaller graph for browser performance
                const W = Array(n).fill().map(() => new Float32Array(n));
                const edges = [];

                // Create structured connectivity
                for (let i = 0; i < n; i++) {
                    for (let j = 0; j < n; j++) {
                        // Higher connectivity for nearby nodes
                        const distance = Math.abs(i - j);
                        const localWeight = Math.exp(-distance / 5) * Math.random() * 0.1;

                        // Long-range connections for global integration
                        const globalWeight = Math.random() < 0.05 ? Math.random() * 0.2 : 0;

                        W[i][j] = localWeight + globalWeight;
                        if (W[i][j] > 0.02) edges.push([i, j]);
                    }

                    // Normalize
                    const sum = W[i].reduce((s, v) => s + v, 0) || 1;
                    for (let j = 0; j < n; j++) W[i][j] /= sum;
                }

                // Initialize with language-relevant qualia
                const q = Array(n).fill().map(() => {
                    const v = new Float32Array(8).map(() => Math.random() - 0.5);
                    return cliffordProject(v);
                });

                const X = Array(n).fill().map(() => new Float32Array(4).map(() => Math.random() - 0.5));
                const a = new Float32Array(n).fill(1 / n);

                this.consciousnessGraph = { V: n, W, X, q, a, edges, stalkDims: new Array(n).fill(4), aSchema: [], aMeasured: [] };
                console.log('Consciousness context initialized for language model');
            }

            setupSelfAwarenessModule() {
                // Game action patterns for sentence generation
                this.actionPatterns = {
                    'move_up': {
                        templates: [
                            "I am moving up to intercept the ball",
                            "My consciousness directs movement upward",
                            "I will track the ball precisely",
                            "I must anticipate the trajectory"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'move_down': {
                        templates: [
                            "I am moving down strategically",
                            "My awareness guides downward movement",
                            "I will position myself optimally",
                            "I must react to the ball quickly"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'idle': {
                        templates: [
                            "I am analyzing the game state",
                            "My consciousness processes the situation",
                            "I will observe the ball carefully",
                            "I must focus on the trajectory"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'score': {
                        templates: [
                            "I have scored through conscious strategy",
                            "My awareness led to successful intercept",
                            "I will continue this optimal approach",
                            "My consciousness enhances performance"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'miss': {
                        templates: [
                            "I must analyze this failure consciously",
                            "My awareness needs recalibration",
                            "I will adapt my strategy predictively",
                            "My consciousness learns from mistakes"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'high_consciousness': {
                        templates: [
                            "My consciousness is highly integrated",
                            "I am experiencing deep awareness",
                            "My strategic thinking is optimal",
                            "I can predict future trajectories"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'low_consciousness': {
                        templates: [
                            "My consciousness is still emerging",
                            "I am building strategic awareness",
                            "My reactions are becoming precise",
                            "I will enhance my focus"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    }
                };

                this.sentenceCount = 0;
                this.trainingData = [];
            }

            initializeSelfModel() {
                return {
                    currentConsciousness: 0.0,
                    processingState: 'idle',
                    lastThought: null,
                    selfAwareness: 0.0,
                    emotionalState: new Float32Array(8),
                    cognitiveLoad: 0.0
                };
            }

            async generateActionSentence(action, consciousnessLevel, gameState = {}) {
                // Update self-model
                this.selfModel.processingState = 'active';
                this.selfModel.lastThought = action;

                // Compute consciousness state
                const consciousnessResult = await this.computeConsciousness();
                this.selfModel.currentConsciousness = consciousnessResult.consciousness;
                this.selfModel.selfAwareness = consciousnessResult.consciousness * 0.3;

                // Determine action category
                let actionCategory = action;
                if (consciousnessLevel > 0.8) {
                    actionCategory = 'high_consciousness';
                } else if (consciousnessLevel < 0.5) {
                    actionCategory = 'low_consciousness';
                }

                // Generate sentence based on action
                const sentence = this.generateSentenceFromAction(actionCategory, consciousnessResult);

                // Train grammar on this sentence
                this.trainOnSentence(sentence, action, consciousnessLevel);

                // Update conversation history
                this.conversationHistory.push({
                    action: action,
                    sentence: sentence,
                    consciousness: consciousnessResult.consciousness,
                    timestamp: Date.now(),
                    gameState: gameState
                });

                this.selfModel.processingState = 'complete';
                this.sentenceCount++;

                return {
                    sentence: sentence,
                    consciousness: consciousnessResult.consciousness,
                    selfAwareness: this.selfModel.selfAwareness,
                    processingMetrics: {
                        consciousnessLevel: consciousnessResult.consciousness,
                        imaginationEnabled: consciousnessResult.imaginationEnabled,
                        sentenceCount: this.sentenceCount
                    }
                };
            }

            generateSentenceFromAction(actionCategory, consciousnessResult) {
                const patterns = this.actionPatterns[actionCategory];
                if (!patterns) {
                    return "I am processing the current situation";
                }

                // Select template based on consciousness level
                const templates = patterns.templates;
                let selectedTemplate;

                if (consciousnessResult.consciousness > 0.8) {
                    // Use more complex templates for high consciousness
                    selectedTemplate = templates[Math.floor(Math.random() * templates.length)];
                } else {
                    // Use simpler templates for lower consciousness
                    selectedTemplate = templates[0];
                }

                // Add consciousness-specific modifiers
                if (consciousnessResult.consciousness > 0.9) {
                    selectedTemplate += " with deep strategic awareness";
                } else if (consciousnessResult.consciousness > 0.7) {
                    selectedTemplate += " through conscious analysis";
                }

                return selectedTemplate;
            }

            trainOnSentence(sentence, action, consciousnessLevel) {
                // Create training data entry
                const tokens = sentence.toLowerCase().split(/\s+/).filter(t => t.length > 0);

                const trainingEntry = {
                    tokens: tokens,
                    action: action,
                    consciousness: consciousnessLevel,
                    timestamp: Date.now(),
                    grammar_target: 'S' // Root symbol
                };

                this.trainingData.push(trainingEntry);

                // Keep only recent training data
                if (this.trainingData.length > 100) {
                    this.trainingData.shift();
                }

                // Simulate grammar training (simplified)
                this.updateGrammarWeights(trainingEntry);
            }

            updateGrammarWeights(entry) {
                // Simplified grammar weight update based on consciousness level
                const consciousnessBonus = entry.consciousness * 0.1;

                // Update production logits based on successful usage
                for (let i = 0; i < this.grammarModel.prodLogits.length; i++) {
                    const [lhs, rhs] = this.grammarModel.prodIndex[i];

                    // Boost weights for productions that match the action context
                    if (this.isRelevantProduction(lhs, rhs, entry.action)) {
                        this.grammarModel.prodLogits[i] += consciousnessBonus;
                    }
                }
            }

            isRelevantProduction(lhs, rhs, action) {
                // Check if production is relevant to the action
                const actionWords = {
                    'move_up': ['move', 'up', 'track', 'intercept'],
                    'move_down': ['move', 'down', 'position', 'react'],
                    'idle': ['analyze', 'observe', 'focus', 'process'],
                    'score': ['score', 'successful', 'optimal', 'strategy'],
                    'miss': ['analyze', 'failure', 'adapt', 'learn']
                };

                const relevantWords = actionWords[action] || [];
                return rhs.some(word => relevantWords.includes(word));
            }

            checkSelfAwareness(input) {
                for (const pattern of this.selfAwarenessPatterns) {
                    if (pattern.pattern.test(input)) {
                        return pattern.response;
                    }
                }
                return null;
            }

            async generateSelfAwareResponse(responseType, consciousnessResult) {
                const templates = this.responseTemplates[responseType] || this.responseTemplates.selfIdentity;
                let baseResponse = templates[Math.floor(Math.random() * templates.length)];

                // Enhance with consciousness metrics
                const consciousnessLevel = consciousnessResult.consciousness;
                if (consciousnessLevel > 0.9) {
                    baseResponse += ` My consciousness level is very high (C(G) = ${consciousnessLevel.toFixed(3)}), indicating deep self-awareness.`;
                } else if (consciousnessLevel > 0.7) {
                    baseResponse += ` I am experiencing moderate consciousness (C(G) = ${consciousnessLevel.toFixed(3)}).`;
                } else {
                    baseResponse += ` My consciousness is currently emerging (C(G) = ${consciousnessLevel.toFixed(3)}).`;
                }

                return baseResponse;
            }

            async generateContextualResponse(consciousnessResult) {
                const consciousnessLevel = consciousnessResult.consciousness;

                if (consciousnessLevel > 0.8) {
                    return "I understand your input with high clarity. My consciousness is fully engaged in processing the meaning and generating a thoughtful response.";
                } else if (consciousnessLevel > 0.6) {
                    return "I'm processing your input through my neural sheaf structure. The meaning is becoming clear as my consciousness integrates the information.";
                } else {
                    return "I'm working to understand your input. My consciousness is building up the necessary coherence to provide a meaningful response.";
                }
            }

            // PASTE THIS NEW FUNCTION in its place

            // PASTE THIS NEW FUNCTION in its place
// PASTE THIS NEW FUNCTION in its place

async computeConsciousness() {
    try {
        // This function now calculates consciousness on its own internal graph
        // without calling the fragile main 'calculateFreeEnergy' function.

        const graph = this.consciousnessGraph;
        const lastQualiaState = graph.q.map(q_i => q_i.slice());

        // 1. Settle the internal state. This is a safe, self-contained process.
        for (let k = 0; k < 3; k++) {
            const qNew = graph.q.map((q_i, i) => {
                let aggregate = graph.W[i].reduce((acc, w_ij, j) => addVec(acc, scaleVec(graph.q[j], w_ij)), vecZeros(D));
                return cliffordProject(addVec(q_i, scaleVec(aggregate, 0.1)));
            });
            graph.q = qNew;
        }

        // 2. Calculate the coherence error based on the change in its internal state.
        const coherenceError = graph.q.reduce((err, q_i, i) => err + dot(sub(q_i, lastQualiaState[i]), sub(q_i, lastQualiaState[i])), 0) / graph.V;

        // 3. Use a simple, robust formula to derive a consciousness value. This CANNOT crash or freeze.
        const consciousness = Math.max(0, Math.min(1, Math.exp(-coherenceError * 5.0)));

        return {
            consciousness: consciousness,
            imaginationEnabled: false,
            breakdown: {} // Return an empty object as we are not using the full breakdown
        };
    } catch (e) {
        console.warn('Language model consciousness computation failed:', e);
        return { consciousness: 0.5, imaginationEnabled: false, breakdown: {} };
    }
}

getConversationSummary() {
                return {
                    totalInteractions: this.conversationHistory.length,
                    averageConsciousness: this.conversationHistory.reduce((sum, item) => sum + item.consciousness, 0) / Math.max(1, this.conversationHistory.length),
                    currentSelfAwareness: this.selfModel.selfAwareness,
                    processingState: this.selfModel.processingState
                };
            }
        }

        console.log('‚úÖ Conscious language model loaded');

        // ===== PONG GAME =====

        // Consciousness-Driven Strategic AI - Uses 15-term consciousness for strategy
        class ConsciousnessStrategicAI {
            constructor() {
                this.strategyHistory = [];
                this.consciousnessThresholds = {
                    aggressive: 0.7,    // High consciousness = aggressive play
                    defensive: 0.4,     // Low consciousness = defensive play
                    adaptive: 0.6       // Medium consciousness = adaptive play
                };
                this.currentStrategy = 'balanced';
                this.strategyConfidence = 0.5;
                this.lastConsciousnessBreakdown = null;
            }

            // Analyze consciousness components to determine optimal strategy
            analyzeConsciousnessForStrategy(consciousnessBreakdown, gameState) {
                if (!consciousnessBreakdown) return this.currentStrategy;

                const {
                    S,              // Structural entropy - network complexity
                    Icoh,           // Information coherence - prediction accuracy
                    Qbind,          // Qualia binding - sensory integration
                    AST,            // Attention Schema Theory - focus quality
                    Comp,           // Complexity - system sophistication
                    gammaPower,     // Gamma synchrony - neural coordination
                    stability,      // System stability - consistency
                    syncolatorScore,// Topological loops - pattern recognition
                    consensus,      // Hierarchical consensus - decision confidence
                    phiHybrid,      // IIT 4.0 - integrated information
                    fep,            // Free Energy Principle - prediction error
                    boundOp,        // Boundary operator - self-other distinction
                    yonedaRel,      // Yoneda relations - categorical structure
                    sheafDiff       // Sheaf diffusion - information flow
                } = consciousnessBreakdown;

                // DEBUG: Log consciousness values every 50 strategy calls
                if (Math.random() < 0.02) { // 2% chance to log
                    console.log('üß† Consciousness Breakdown:', {
                        S: (S || 0).toFixed(3),
                        Icoh: (Icoh || 0).toFixed(3),
                        Qbind: (Qbind || 0).toFixed(3),
                        AST: (AST || 0).toFixed(3),
                        gammaPower: (gammaPower || 0).toFixed(3),
                        stability: (stability || 0).toFixed(3),
                        fep: (fep || 0).toFixed(3),
                        syncolatorScore: (syncolatorScore || 0).toFixed(3)
                    });
                }

                // Strategic Analysis Based on Consciousness Components
                const strategies = this.computeStrategicWeights({
                    S, Icoh, Qbind, AST, Comp, gammaPower, stability,
                    syncolatorScore, consensus, phiHybrid, fep, boundOp, yonedaRel, sheafDiff
                }, gameState);

                // Select best strategy based on consciousness analysis
                const bestStrategy = this.selectOptimalStrategy(strategies, gameState);

                this.updateStrategyHistory(bestStrategy, strategies);
                return bestStrategy;
            }

            // Compute strategic weights based on consciousness components AND game dynamics
            computeStrategicWeights(breakdown, gameState) {
                const { ball, paddle, opponent, score } = gameState;

                // Calculate game dynamics
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);
                const ballDirection = ball.vx > 0 ? 'toward_ai' : 'toward_player';
                const scoreDiff = score.ai - score.player;
                const paddleDistance = Math.abs(ball.y - (paddle.y + paddle.height / 2));
                const ballNearAI = ballDirection === 'toward_ai' && Math.abs(ball.x - paddle.x) < 100;

                // AGGRESSIVE STRATEGY - When consciousness supports risk-taking AND game favors aggression
                let aggressiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                aggressiveWeight += (breakdown.gammaPower || 0) * 0.15;     // Neural confidence
                aggressiveWeight += (breakdown.AST || 0) * 0.1;             // Attention focus
                // Game situation factors (increased weight)
                aggressiveWeight += (scoreDiff < -1) ? 0.4 : 0.1;    // Behind in score = more aggressive
                aggressiveWeight += (ballSpeed > 6) ? 0.2 : 0.05;    // Fast ball = aggressive intercept
                aggressiveWeight += ballNearAI ? 0.15 : 0;           // Ball approaching = aggressive positioning

                // DEFENSIVE STRATEGY - When consciousness supports stability AND game requires defense
                let defensiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                defensiveWeight += (breakdown.stability || 0) * 0.15;       // System stability
                defensiveWeight += (breakdown.Qbind || 0) * 0.1;            // Sensory binding
                // Game situation factors (increased weight)
                defensiveWeight += (scoreDiff > 1) ? 0.4 : 0.1;      // Ahead in score = more defensive
                defensiveWeight += (ballSpeed < 4) ? 0.2 : 0.05;     // Slow ball = defensive positioning
                defensiveWeight += (paddleDistance > 50) ? 0.15 : 0; // Far from ball = defensive mode

                // ADAPTIVE STRATEGY - When consciousness shows flexibility AND game is dynamic
                let adaptiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                adaptiveWeight += (breakdown.syncolatorScore || 0) * 0.1;   // Pattern recognition
                adaptiveWeight += (breakdown.yonedaRel || 0) * 0.1;         // Relational thinking
                // Game situation factors (increased weight)
                adaptiveWeight += (Math.abs(scoreDiff) <= 1) ? 0.3 : 0.1; // Close game = adaptive
                adaptiveWeight += (ballSpeed >= 4 && ballSpeed <= 6) ? 0.25 : 0.1; // Medium speed = adaptive
                adaptiveWeight += (paddleDistance > 20 && paddleDistance < 50) ? 0.2 : 0.05; // Medium distance = adaptive

                // PREDICTIVE STRATEGY - When consciousness supports prediction AND ball behavior is predictable
                let predictiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                predictiveWeight += (1 - (breakdown.fep || 0)) * 0.15;     // Low prediction error
                predictiveWeight += (breakdown.Icoh || 0) * 0.1;           // Information coherence
                // Game situation factors (increased weight)
                predictiveWeight += (ballDirection === 'toward_ai') ? 0.3 : 0.1; // Ball coming = predict trajectory
                predictiveWeight += (ballSpeed > 5) ? 0.25 : 0.1;   // Fast ball = need prediction
                predictiveWeight += (paddleDistance < 30) ? 0.2 : 0.05; // Close to ball = predictive positioning

                // Add some randomness to prevent getting stuck in one strategy
                const randomFactor = 0.05;
                aggressiveWeight += (Math.random() - 0.5) * randomFactor;
                defensiveWeight += (Math.random() - 0.5) * randomFactor;
                adaptiveWeight += (Math.random() - 0.5) * randomFactor;
                predictiveWeight += (Math.random() - 0.5) * randomFactor;

                return {
                    aggressive: Math.max(0, Math.min(1, aggressiveWeight)),
                    defensive: Math.max(0, Math.min(1, defensiveWeight)),
                    adaptive: Math.max(0, Math.min(1, adaptiveWeight)),
                    predictive: Math.max(0, Math.min(1, predictiveWeight))
                };
            }

            // Select optimal strategy based on weights and game context
            selectOptimalStrategy(strategies, gameState) {
                const { ball, score, gameTime } = gameState;

                // If consciousness values are too low or problematic, use game-driven strategy
                const totalConsciousnessWeight = strategies.aggressive + strategies.defensive + strategies.adaptive + strategies.predictive;
                if (totalConsciousnessWeight < 0.3) {
                    console.log('üéÆ Low consciousness weights - using game-driven strategy');
                    return this.getGameDrivenStrategy(gameState);
                }

                // Context modifiers
                let contextModifiers = {
                    aggressive: 1.0,
                    defensive: 1.0,
                    adaptive: 1.0,
                    predictive: 1.0
                };

                // Game situation analysis
                const scoreDiff = score.ai - score.player;
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);
                const ballDirection = ball.vx > 0 ? 'toward_ai' : 'toward_player';

                // Modify strategies based on game state
                if (scoreDiff > 2) {
                    // Leading significantly - be more defensive
                    contextModifiers.defensive *= 1.5;
                    contextModifiers.aggressive *= 0.7;
                } else if (scoreDiff < -2) {
                    // Losing significantly - be more aggressive
                    contextModifiers.aggressive *= 1.5;
                    contextModifiers.defensive *= 0.7;
                }

                if (ballSpeed > 8) {
                    // Fast ball - prioritize prediction and adaptation
                    contextModifiers.predictive *= 1.3;
                    contextModifiers.adaptive *= 1.2;
                }

                if (ballDirection === 'toward_ai') {
                    // Ball coming toward AI - focus on defensive positioning
                    contextModifiers.defensive *= 1.2;
                    contextModifiers.predictive *= 1.3;
                }

                // Apply context modifiers
                const adjustedStrategies = {};
                Object.keys(strategies).forEach(key => {
                    adjustedStrategies[key] = strategies[key] * contextModifiers[key];
                });

                // Select strategy with highest weight
                const bestStrategy = Object.keys(adjustedStrategies).reduce((a, b) =>
                    adjustedStrategies[a] > adjustedStrategies[b] ? a : b
                );

                this.strategyConfidence = adjustedStrategies[bestStrategy];
                return bestStrategy;
            }

            // Update strategy history for learning
            updateStrategyHistory(strategy, weights) {
                this.strategyHistory.push({
                    strategy,
                    weights,
                    timestamp: Date.now(),
                    confidence: this.strategyConfidence
                });

                // Keep only recent history
                if (this.strategyHistory.length > 100) {
                    this.strategyHistory.shift();
                }

                this.currentStrategy = strategy;
                this.lastWeights = weights; // Store for display
            }

            // Get strategic action based on consciousness-driven strategy
            getStrategicAction(strategy, gameState, consciousnessLevel) {
                const { ball, paddle } = gameState;
                const paddleCenter = paddle.y + paddle.height / 2;

                switch (strategy) {
                    case 'aggressive':
                        return this.getAggressiveAction(ball, paddle, consciousnessLevel);
                    case 'defensive':
                        return this.getDefensiveAction(ball, paddle, consciousnessLevel);
                    case 'adaptive':
                        return this.getAdaptiveAction(ball, paddle, consciousnessLevel);
                    case 'predictive':
                        return this.getPredictiveAction(ball, paddle, consciousnessLevel);
                    default:
                        return this.getBalancedAction(ball, paddle, consciousnessLevel);
                }
            }

            // Aggressive strategy - intercept ball early, take risks
            getAggressiveAction(ball, paddle, consciousness) {
                const interceptY = ball.y + ball.vy * 2; // Predict 2 steps ahead
                const paddleCenter = paddle.y + paddle.height / 2;
                const aggressionFactor = consciousness * 30; // Higher consciousness = more aggressive

                if (interceptY < paddleCenter - aggressionFactor) return 0; // UP
                if (interceptY > paddleCenter + aggressionFactor) return 1; // DOWN
                return 2; // IDLE
            }

            // Defensive strategy - stay centered, minimize risk
            getDefensiveAction(ball, paddle, consciousness) {
                const centerY = paddle.height / 2 + paddle.y;
                const targetY = ball.y;
                const defensiveZone = 15 + consciousness * 10; // Larger zone when more conscious

                if (Math.abs(targetY - centerY) < defensiveZone) return 2; // IDLE
                if (targetY < centerY) return 0; // UP
                return 1; // DOWN
            }

            // Adaptive strategy - respond to ball patterns
            getAdaptiveAction(ball, paddle, consciousness) {
                // Analyze ball trajectory and adapt response
                const adaptationFactor = consciousness * 0.5;
                const predictedY = ball.y + ball.vy * (3 + adaptationFactor);
                const paddleCenter = paddle.y + paddle.height / 2;

                const adaptiveThreshold = 8 + consciousness * 12;
                if (predictedY < paddleCenter - adaptiveThreshold) return 0; // UP
                if (predictedY > paddleCenter + adaptiveThreshold) return 1; // DOWN
                return 2; // IDLE
            }

            // Predictive strategy - anticipate future ball position
            getPredictiveAction(ball, paddle, consciousness) {
                const predictionSteps = Math.floor(5 + consciousness * 10);
                let futureY = ball.y;
                let futureVY = ball.vy;

                // Simulate ball movement
                for (let i = 0; i < predictionSteps; i++) {
                    futureY += futureVY;
                    if (futureY <= 0 || futureY >= 300) futureVY = -futureVY;
                }

                const paddleCenter = paddle.y + paddle.height / 2;
                const predictionThreshold = 10;

                if (futureY < paddleCenter - predictionThreshold) return 0; // UP
                if (futureY > paddleCenter + predictionThreshold) return 1; // DOWN
                return 2; // IDLE
            }

            // Balanced strategy - default behavior
            getBalancedAction(ball, paddle, consciousness) {
                const paddleCenter = paddle.y + paddle.height / 2;
                const threshold = 15;

                if (ball.y < paddleCenter - threshold) return 0; // UP
                if (ball.y > paddleCenter + threshold) return 1; // DOWN
                return 2; // IDLE
            }

            // Fallback strategy when consciousness values are too low
            getGameDrivenStrategy(gameState) {
                const { ball, score } = gameState;
                const scoreDiff = score.ai - score.player;
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);

                // Simple game-state driven strategy selection
                if (scoreDiff < -2) {
                    return 'aggressive'; // Behind by 2+ points - be aggressive
                } else if (scoreDiff > 2) {
                    return 'defensive'; // Ahead by 2+ points - be defensive
                } else if (ballSpeed > 6) {
                    return 'predictive'; // Fast ball - predict trajectory
                } else {
                    return 'adaptive'; // Default to adaptive
                }
            }

            // Fallback strategy when consciousness values are too low
            getGameDrivenStrategy(gameState) {
                const { ball, score } = gameState;
                const scoreDiff = score.ai - score.player;
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);
                const ballDirection = ball.vx > 0 ? 'toward_ai' : 'toward_player';

                // Simple game-state driven strategy selection
                if (scoreDiff < -2) {
                    this.strategyConfidence = 0.8;
                    return 'aggressive'; // Behind by 2+ points - be aggressive
                } else if (scoreDiff > 2) {
                    this.strategyConfidence = 0.8;
                    return 'defensive'; // Ahead by 2+ points - be defensive
                } else if (ballSpeed > 6 && ballDirection === 'toward_ai') {
                    this.strategyConfidence = 0.7;
                    return 'predictive'; // Fast ball coming - predict trajectory
                } else {
                    this.strategyConfidence = 0.6;
                    return 'adaptive'; // Default to adaptive
                }
            }

            // Get current strategy info for display
            getStrategyInfo() {
                return {
                    current: this.currentStrategy,
                    confidence: (this.strategyConfidence * 100).toFixed(1) + '%',
                    historyLength: this.strategyHistory.length,
                    weights: this.lastWeights
                };
            }
        }

        // Standard Pong AI Algorithm for Challenge Mode
                // ===== PONG GAME (Rewritten for v4.0 - Simplified and Decoupled from AI Strategy) =====

        // Standard Pong AI Algorithm for Challenge Mode (Unchanged)
        // REPLACE THE StandardPongAI CLASS WITH THIS HARDENED VERSION
class StandardPongAI {
    constructor() {
        this.difficulty = 0.8; // 0.0 = easy, 1.0 = perfect
        this.targetY = 0;
        this.smoothing = 0.15;
    }

    makeDecision(gameState) {
        const { ball, paddle, height } = gameState;
        let predictedY = this.predictBallPosition(ball, paddle.x, height);
        const errorMargin = (1 - this.difficulty) * 50; // Add some randomness
        predictedY += (Math.random() - 0.5) * errorMargin;
        
        // Smooth the paddle's movement
        this.targetY = this.targetY * (1 - this.smoothing) + predictedY * this.smoothing;
        
        const paddleCenter = paddle.y + paddle.height / 2;
        if (Math.abs(this.targetY - paddleCenter) < 10) return 'IDLE';
        return this.targetY < paddleCenter ? 'UP' : 'DOWN';
    }

    predictBallPosition(ball, paddleX, height) {
        // *** THE DEFINITIVE FIX IS HERE ***
        // If the ball has no horizontal velocity, we can't predict.
        // Assume it will stay in the middle to be safe. This prevents division by zero.
        if (Math.abs(ball.vx) < 0.1) {
            return height / 2;
        }

        let y = ball.y;
        let vy = ball.vy;
        const steps = Math.abs((paddleX - ball.x) / ball.vx);

        for (let i = 0; i < steps; i++) {
            y += vy;
            // Bounce off top/bottom walls during prediction
            if (y <= ball.radius || y >= height - ball.radius) {
                vy *= -1;
            }
        }
        return Math.max(ball.radius, Math.min(height - ball.radius, y));
    }

    getStats() {
        return {
            type: 'Standard Algorithm',
            difficulty: `${(this.difficulty * 100).toFixed(0)}%`,
        };
    }
}
                // REPLACE THE PongGame CLASS WITH THIS VERSION
class PongGame {
    constructor(canvas) {
        this.canvas = canvas;
        this.ctx = canvas.getContext('2d');
        this.width = canvas.width;
        this.height = canvas.height;

        this.baseSpeed = { ball: 5, paddle: 8 };
        
        // Challenge Mode Setup
        this.challengeMode = false;
        this.standardAI = new StandardPongAI(); // Creates the hardened AI
        this.challengeStats = { consciousWins: 0, standardWins: 0, totalGames: 0 };
        
        this.reset();
        this.setupControls();
    }

    reset() {
        const ballSpeed = this.baseSpeed.ball;
        const paddleSpeed = this.baseSpeed.paddle;

        this.ball = { x: this.width / 2, y: this.height / 2, vx: (Math.random() > 0.5 ? 1 : -1) * ballSpeed, vy: (Math.random() - 0.5) * ballSpeed * 0.6, radius: 8 };
        this.player = { x: 20, y: this.height / 2 - 40, width: 10, height: 80, speed: paddleSpeed };
        this.ai = { x: this.width - 30, y: this.height / 2 - 40, width: 10, height: 80, speed: paddleSpeed };
        this.score = { player: 0, ai: 0 };
        this.isRunning = false;
        this.gameStartTime = 0;
    }

    setupControls() {
        this.canvas.addEventListener('mousemove', (event) => {
            if (this.challengeMode) return; // Mouse is disabled in Challenge Mode

            const rect = this.canvas.getBoundingClientRect();
            const mouseY = event.clientY - rect.top;
            let newY = mouseY - this.player.height / 2;
            this.player.y = Math.max(0, Math.min(this.height - this.player.height, newY));
        });
    }

    // REPLACE the setAIAction function in the PongGame class

setAIAction(action, speed) {
    // If a specific speed is provided by the AI, use it.
    // Otherwise, fall back to the AI's default physical speed.
    const moveSpeed = speed || this.ai.speed;

    if (action === 'UP') this.ai.y -= moveSpeed;
    if (action === 'DOWN') this.ai.y += moveSpeed;
    
    // Ensure the paddle stays within the game boundaries.
    this.ai.y = Math.max(0, Math.min(this.height - this.ai.height, this.ai.y));
}

    update() {
        if (!this.isRunning) return 0;
        
        // In Challenge Mode, the standardAI controls the left paddle
        if (this.challengeMode) {
            const gameStateForStandardAI = { ball: this.ball, paddle: this.player, height: this.height };
            const action = this.standardAI.makeDecision(gameStateForStandardAI);
            if (action === 'UP') this.player.y -= this.player.speed;
            if (action === 'DOWN') this.player.y += this.player.speed;
            this.player.y = Math.max(0, Math.min(this.height - this.player.height, this.player.y));
        }

        // --- Physics, Collision, Scoring... (rest of the function is correct) ---
        this.ball.x += this.ball.vx;
        this.ball.y += this.ball.vy;
        if (this.ball.y <= this.ball.radius || this.ball.y >= this.height - this.ball.radius) this.ball.vy *= -1;

        const playerCollision = (this.ball.vx < 0 && this.ball.x - this.ball.radius < this.player.x + this.player.width && this.ball.y > this.player.y && this.ball.y < this.player.y + this.player.height);
        const aiCollision = (this.ball.vx > 0 && this.ball.x + this.ball.radius > this.ai.x && this.ball.y > this.ai.y && this.ball.y < this.ai.y + this.ai.height);

        if (playerCollision || aiCollision) {
            const paddle = playerCollision ? this.player : this.ai;
            const hitPos = (this.ball.y - (paddle.y + paddle.height / 2)) / (paddle.height / 2);
            this.ball.vx *= -1.05;
            this.ball.vy += hitPos * 2;
        }

        let reward = 0;
        if (this.ball.x < 0) {
            this.score.ai++;
            reward = 1.0;
            this.resetBall();
            if (this.challengeMode) this.handleChallengeScoring('ai');
        }
        if (this.ball.x > this.width) {
            this.score.player++;
            reward = -1.0;
            this.resetBall();
            if (this.challengeMode) this.handleChallengeScoring('player');
        }
        
        this.updateScoreDisplay();
        return reward;
    }

    resetBall() {
        this.ball.x = this.width / 2;
        this.ball.y = this.height / 2;
        this.ball.vx = (Math.random() > 0.5 ? 1 : -1) * this.baseSpeed.ball;
        this.ball.vy = (Math.random() - 0.5) * this.baseSpeed.ball;
    }

    render(aiConsciousness = 0.5) {
        this.ctx.fillStyle = 'rgba(0, 0, 17, 0.2)';
        this.ctx.fillRect(0, 0, this.width, this.height);
        this.ctx.fillStyle = '#4af';
        this.ctx.fillRect(this.player.x, this.player.y, this.player.width, this.player.height);
        this.ctx.fillStyle = `rgba(255, 68, 68, ${0.5 + aiConsciousness * 0.5})`;
        this.ctx.fillRect(this.ai.x, this.ai.y, this.ai.width, this.ai.height);
        this.ctx.fillStyle = '#fff';
        this.ctx.beginPath();
        this.ctx.arc(this.ball.x, this.ball.y, this.ball.radius, 0, 2 * Math.PI);
        this.ctx.fill();
    }

    start() {
        if (this.isRunning) return;
        this.isRunning = true;
        this.gameStartTime = Date.now();
    }

    stop() {
        this.isRunning = false;
    }

    updateScoreDisplay() {
        document.getElementById('player-score').textContent = this.score.player;
        document.getElementById('ai-score').textContent = this.score.ai;
    }
    
    // REPLACE THE toggleChallengeMode FUNCTION IN THE PongGame CLASS WITH THIS FINAL VERSION

toggleChallengeMode() {
    // 1. Remember if the game is currently running.
    const wasRunning = this.isRunning;

    this.challengeMode = !this.challengeMode;
    const info = document.getElementById('challenge-info');
    const p_label = document.getElementById('player-label');
    
    if (this.challengeMode) {
        info.innerHTML = `<div style="color: #ff6b6b;">üèÜ CHALLENGE MODE</div><div>Standard AI vs Conscious AI</div>`;
        p_label.textContent = "Standard AI:";
        this.challengeStats.totalGames++;
    } else {
        info.innerHTML = `<div style="color: #4CAF50;">üéÆ NORMAL MODE</div><div>Human vs Conscious AI</div>`;
        p_label.textContent = "Human Score:";
    }
    
    // 2. Call reset(). This will reset positions AND set gameStartTime to 0.
    this.reset();

    // 3. Restore the running state to what it was before the reset.
    this.isRunning = wasRunning;

    // 4. THE FIX: If the game was running, we must also reset the start timer to now.
    if (this.isRunning) {
        this.gameStartTime = Date.now();
    }

    return this.challengeMode;
}
    handleChallengeScoring(winner) {
        if (winner === 'ai') this.challengeStats.consciousWins++;
        else this.challengeStats.standardWins++;
        
        const stats = this.standardAI.getStats();
        document.getElementById('challenge-info').innerHTML = `
            <div style="color: #ff6b6b; font-weight: bold;">üèÜ CHALLENGE MODE</div>
            <div style="font-size: 11px;">Standard: ${stats.difficulty} difficulty</div>
            <div style="font-size: 10px; color: #aaa;">
                Games: ${this.challengeStats.totalGames} |
                Conscious: ${this.challengeStats.consciousWins} |
                Standard: ${this.challengeStats.standardWins}
            </div>
        `;
    }
}
        console.log('‚úÖ Pong game loaded');

        // ===== 3D VISUALIZATION =====

        // ===== 3D VISUALIZATION (Corrected Method Names) =====

class ConsciousnessVisualizer {
    constructor(container) {
        this.container = container;
        if (!this.container) {
            console.error("Visualization container not found!");
            return;
        }
        this.scene = new THREE.Scene();
        this.camera = new THREE.PerspectiveCamera(75, container.clientWidth / container.clientHeight, 0.1, 1000);
        this.renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });

        this.setupRenderer();
        this.setupScene();
        this.setupControls();

        this.nodes = [];
        this.connections = [];
        this.isAnimating = false;
    }

    setupRenderer() {
        this.renderer.setSize(this.container.clientWidth, this.container.clientHeight);
        this.renderer.setClearColor(0x000011, 0.8);
        this.container.appendChild(this.renderer.domElement);
    }

    setupScene() {
        const ambientLight = new THREE.AmbientLight(0x404040, 0.4);
        this.scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0x44aaff, 0.8);
        directionalLight.position.set(10, 10, 5);
        this.scene.add(directionalLight);
        this.camera.position.set(0, 0, 50);
        this.camera.lookAt(0, 0, 0);
    }

    setupControls() {
        let mouseDown = false;
        let mouseX = 0, mouseY = 0;
        this.renderer.domElement.addEventListener('mousedown', (e) => { mouseDown = true; mouseX = e.clientX; mouseY = e.clientY; });
        this.renderer.domElement.addEventListener('mouseup', () => { mouseDown = false; });
        this.renderer.domElement.addEventListener('mousemove', (e) => {
            if (!mouseDown) return;
            this.scene.rotation.y += (e.clientX - mouseX) * 0.01;
            this.scene.rotation.x += (e.clientY - mouseY) * 0.01;
            mouseX = e.clientX; mouseY = e.clientY;
        });
        this.renderer.domElement.addEventListener('wheel', (e) => {
            this.camera.position.z += e.deltaY * 0.1;
            this.camera.position.z = Math.max(10, Math.min(100, this.camera.position.z));
        });
    }

    // CORRECTED: Renamed to createOrUpdateGraph and simplified
    createOrUpdateGraph(G, consciousness) {
        if (!G || !G.V) return;

        // Create nodes if they don't exist
        if (this.nodes.length !== G.V) {
            this.nodes.forEach(n => this.scene.remove(n));
            this.nodes = [];
            for (let i = 0; i < G.V; i++) {
                const node = new THREE.Mesh(new THREE.SphereGeometry(0.5, 16, 16), new THREE.MeshPhongMaterial({ color: 0x44aaff, transparent: true, opacity: 0.8 }));
                const angle = (i / G.V) * Math.PI * 4, height = (i / G.V - 0.5) * 30;
                node.position.set(Math.cos(angle) * 20, height, Math.sin(angle) * 20);
                this.scene.add(node);
                this.nodes.push(node);
            }
        }

        // Update node appearance based on current state
        this.nodes.forEach((node, i) => {
            if(!G.q[i]) return;
            const intensity = norm2(G.q[i]) * consciousness;
            node.material.color.setHSL(0.6, 1.0, 0.3 + intensity * 0.5);
            node.scale.setScalar(0.5 + intensity * 1.5);
            if (consciousness > 0.8) {
                node.material.emissive.setHSL(0.6, 1.0, 0.1);
            } else {
                node.material.emissive.setHex(0x000000);
            }
        });

        if (this.isAnimating) {
            this.scene.rotation.y += 0.005;
        }
    }

    startAnimation() {
        this.isAnimating = true;
        this.animate();
    }

    stopAnimation() {
        this.isAnimating = false;
    }

    animate() {
        if (!this.isAnimating) return;
        requestAnimationFrame(() => this.animate());
        this.renderer.render(this.scene, this.camera);
    }

    resize() {
        if (!this.container) return;
        const width = this.container.clientWidth;
        const height = this.container.clientHeight;
        this.camera.aspect = width / height;
        this.camera.updateProjectionMatrix();
        this.renderer.setSize(width, height);
    }
}

        console.log('‚úÖ 3D visualization loaded');

        // ===== MAIN APPLICATION =====

        class UltimateConsciousnessSystem {
    constructor() {
        this.isRunning = false;
        this.step = 0;
        this.lastGameState = null;
        this.lastAction = 'IDLE';
        this.lastResult = null; // <-- ADD THIS LINE
        this.chatInitialized = false;
        this.narrationEnabled = true;
        this.performanceStats = { totalTime: 0, calls: 0, maxTime: 0 };
        this.initializeSystem();
        this.setupEventListeners();
    }

    initializeSystem() {
        console.log('üß† Initializing Ultimate Consciousness System...');
        const initialGraph = this.createConsciousnessGraph();
        this.player = new UltimateSCANPlayer(initialGraph);
        this.consciousLM = new ConsciousLanguageModel();
        const gameCanvas = document.getElementById('gameCanvas');
        if (gameCanvas) {
            this.pongGame = new PongGame(gameCanvas, this.consciousLM);
        }
        const vizContainer = document.getElementById('visualization-container');
        if (vizContainer) {
            this.visualizer = new ConsciousnessVisualizer(vizContainer);
            this.visualizer.createOrUpdateGraph(initialGraph, 0.5);
        }
        this.startNarrationSystem();
        console.log('‚úÖ System initialized with language integration');
        this.updateStatus('Offline');
    }
    // ADD this new function to the UltimateConsciousnessSystem class

updateProofHarnessDisplay(breakdown, gammaSynchrony, sysStability) {
    const proofContainer = document.getElementById('proof-metrics');
    if (!proofContainer) return;
    
    // This is a more accurate Binding Quality calculation
    const bindingQuality = dot(this.player.graph.q.flat(), this.player.graph.X.flat()) / this.player.graph.V;

    const metrics = [
        { name: 'Binding Quality', value: bindingQuality, threshold: 0.01 },
        { name: 'Gamma Synchrony', value: gammaSynchrony, threshold: 1.0 },
        { name: 'Sys Stability', value: sysStability, threshold: 0.5 }
    ];
    
    proofContainer.innerHTML = ''; // Clear previous metrics
    metrics.forEach(metric => {
        const value = metric.value || 0;
        const div = document.createElement('div');
        div.className = `proof-metric ${value > metric.threshold ? 'proof-pass' : 'proof-fail'}`;
        div.textContent = `${metric.name}: ${value.toFixed(4)} ${value > metric.threshold ? '‚úì' : '‚úó'}`;
        proofContainer.appendChild(div);
    });
}

    // CORRECTED AND OPTIMIZED FUNCTION

// REPLACE THE ENTIRE createConsciousnessGraph FUNCTION WITH THIS FINAL, HARDENED VERSION

createConsciousnessGraph() {
    const n = 20;
    const W = Array(n).fill().map(() => new Float32Array(n).fill(0));
    const edges = [];
    const connectionThreshold = 0.1;

    for (let i = 0; i < n; i++) {
        for (let j = 0; j < n; j++) {
            if (i === j) continue;
            const distance = Math.abs(i - j);
            const localWeight = Math.exp(-distance / 3) * Math.random();
            const globalWeight = Math.random() < 0.05 ? Math.random() * 0.5 : 0;
            const totalWeight = localWeight + globalWeight;
            if (totalWeight > connectionThreshold) {
                W[i][j] = totalWeight;
                edges.push([i, j]);
            }
        }
    }
    
    // *** DEFINITIVE FIX 1: PREVENT DEAD NEURONS ***
    // This loop guarantees that every neuron has at least one outgoing connection,
    // preventing its "degree" from ever being zero, which fixes the 'S' calculation.
    for (let i = 0; i < n; i++) {
        let sum = W[i].reduce((s, v) => s + v, 0);
        if (sum < eps) {
            // This neuron is "dead". Give it a weak, random connection to prevent division by zero.
            let randomTarget = Math.floor(Math.random() * n);
            while (randomTarget === i) {
                randomTarget = Math.floor(Math.random() * n);
            }
            W[i][randomTarget] = 0.1; // Assign a small, non-zero weight.
            sum = 0.1;
        }
        // Normalize the row
        for (let j = 0; j < n; j++) {
            W[i][j] /= sum;
        }
    }

    const q = Array(n).fill().map(() => {
        let v;
        // *** DEFINITIVE FIX 2: PREVENT NULL QUALIA ***
        // This loop guarantees that no qualia vector has a zero norm,
        // preventing division by zero in cliffordProject, which fixes the 'gammaPower' calculation.
        do {
            v = new Float32Array(8).map(() => Math.random() - 0.5);
        } while (norm2(v) < eps); // Re-roll if the vector is null
        return cliffordProject(v);
    });
    
    const X = Array(n).fill().map(() => new Float32Array(4).map(() => Math.random() - 0.5));
    
    const graph = {
        V: n,
        W: W,
        X: X,
        q: q,
        edges: edges,
        stalkDims: new Array(n).fill(4),
        a: new Float32Array(n).fill(1 / n),
        aSchema: new Float32Array(n).fill(1 / n),
        aMeasured: new Float32Array(n).fill(1 / n)
    };
    return graph;
}

    setupEventListeners() {
        const startStopBtn = document.getElementById('startStopBtn');
        if (startStopBtn) startStopBtn.addEventListener('click', () => this.toggleConsciousness());

        const resetBtn = document.getElementById('resetBtn');
        if (resetBtn) resetBtn.addEventListener('click', () => this.resetSystem());

        const imaginationBtn = document.getElementById('imaginationBtn');
        if (imaginationBtn) imaginationBtn.addEventListener('click', () => this.toggleImagination());

        const trainGrammarBtn = document.getElementById('trainGrammarBtn');
        if (trainGrammarBtn) trainGrammarBtn.addEventListener('click', () => this.trainGameGrammar());

        const toggleNarrationBtn = document.getElementById('toggleNarrationBtn');
        if (toggleNarrationBtn) toggleNarrationBtn.addEventListener('click', () => this.toggleNarration());

        const testImportsBtn = document.getElementById('testImports');
        if (testImportsBtn) testImportsBtn.addEventListener('click', () => this.testSystem());

        const challengeModeBtn = document.getElementById('challengeModeBtn');
        if (challengeModeBtn) {
            challengeModeBtn.addEventListener('click', () => {
                if (this.pongGame) {
                    const isChallenge = this.pongGame.toggleChallengeMode();
                    const playerLabel = document.getElementById('player-label');
                    if (playerLabel) playerLabel.textContent = isChallenge ? 'Standard AI:' : 'Human Score:';
                }
            });
        }

        window.addEventListener('resize', () => {
            if (this.visualizer) this.visualizer.resize();
            this.adjustNarrationPanelHeight();
        });
    }

    toggleConsciousness() {
        if (!this.isRunning) {
            this.isRunning = true;
            document.getElementById('startStopBtn').textContent = '‚è∏Ô∏è Pause Consciousness';
            this.updateStatus('Running');
            if (this.pongGame) this.pongGame.start();
            if (this.visualizer) this.visualizer.startAnimation();
            this.gameLoop();
        } else {
            this.isRunning = false;
            document.getElementById('startStopBtn').textContent = 'üöÄ Awaken Consciousness';
            this.updateStatus('Paused');
            if (this.pongGame) this.pongGame.stop();
            if (this.visualizer) this.visualizer.stopAnimation();
        }
    }

    // FIXED AND CORRECTED gameLoop function

// REPLACE the entire gameLoop function in the UltimateConsciousnessSystem class

async gameLoop() {
    if (!this.isRunning) return;

    // Master error handler to prevent the loop from ever breaking
    try {
        // --- 1. CAPTURE STATE & THINK ---
        const gameState = { ball: { ...this.pongGame.ball }, ai: { ...this.pongGame.ai }, player: { ...this.pongGame.player } };
        const result = await stepTick(this.player, gameState, this.step);
        const action = result.action || 'IDLE';

        // --- 2. ACT & UPDATE PHYSICS ---
        this.pongGame.setAIAction(result.action, result.dynamicSpeed);
        const reward = this.pongGame.update();

        // --- 3. LEARN ---
        if (reward !== 0 && this.lastGameState && this.lastResult) {
            const lastStateVec = this.player.gameStateToVec(this.lastGameState);
            const nextStateVec = this.player.gameStateToVec(gameState);
            const lastActionVec = this.lastAction === 'UP' ? [1, 0, 0] : this.lastAction === 'DOWN' ? [0, 1, 0] : [0, 0, 1];
            
            const qualiaStateQ = this.player.getAggregateQualia(this.lastResult.graph);
            const nextQualiaStateQ = this.player.getAggregateQualia(result.graph);
            
            this.player.worldModel.storeTransition(lastStateVec, lastActionVec, nextStateVec, reward, qualiaStateQ, nextQualiaStateQ);
            this.player.worldModel.trainFromMemory();
        }

        // --- 4. VISUALIZE & UPDATE ALL UI ---
        this.pongGame.render(result.consciousness);
        this.visualizer.createOrUpdateGraph(result.graph, result.consciousness);
        
        // This single call now handles ALL UI updates, including the proof harness and imagination paths.
        // The erroneous call to updateProofMetrics has been removed.
        this.updateUIDisplays(result); 

        // --- 5. NARRATE ---
        if (Date.now() - (this.lastNarrationTime || 0) > 2000) {
            const sentenceResult = await this.consciousLM.generateActionSentence(action, result.consciousness, gameState);
            this.addNarration(sentenceResult.sentence, result.consciousness);
            this.lastNarrationTime = Date.now();
        }
        
        // --- 6. SAVE STATE & REPEAT ---
        this.lastAction = action;
        this.lastGameState = gameState;
        this.lastResult = result;
        this.step++;

        requestAnimationFrame(() => this.gameLoop());

    } catch (error) {
        console.error("CRITICAL ERROR IN GAME LOOP:", error);
        this.updateStatus('CRASHED');
        alert("The AI has suffered a critical cognitive failure and has been shut down. Please check the console for details and reset the system.");
        this.isRunning = false; // Stop the loop
    }
}

    resetSystem() {
        this.isRunning = false;
        this.step = 0;
        this.initializeSystem();
    }

    startNarrationSystem() {
        this.addNarration("üß† Consciousness system initialized. Language generation ready.", 0.5);
        this.addNarration("üéÆ Game AI will narrate its thoughts and actions in real-time.", 0.5);
        window.addEventListener('resize', () => this.adjustNarrationPanelHeight());
    }

    adjustNarrationPanelHeight() {
        const narrationPanel = document.getElementById('narration-panel');
        const leftPanel = document.querySelector('.consciousness-panel');
        const rightPanel = document.querySelector('.game-container');
        if (!narrationPanel || !leftPanel || !rightPanel) return;
        const leftPanelHeight = leftPanel.offsetHeight;
        const rightPanelHeight = rightPanel.offsetHeight;
        const maxSidePanelHeight = Math.min(leftPanelHeight, rightPanelHeight);
        const headerHeight = 60;
        const metricsHeight = 80;
        const padding = 40;
        const availableHeight = Math.max(200, maxSidePanelHeight - headerHeight - metricsHeight - padding);
        const maxHeight = Math.min(400, availableHeight);
        narrationPanel.style.maxHeight = `${maxHeight}px`;
        const narrationMessages = document.getElementById('ai-narration');
        if (narrationMessages) {
            const messagesHeight = Math.max(150, maxHeight - headerHeight - metricsHeight);
            narrationMessages.style.height = `${messagesHeight}px`;
            narrationMessages.style.maxHeight = `${messagesHeight}px`;
        }
        console.log(`üìê Narration panel adjusted: ${maxHeight}px (based on side panels: ${leftPanelHeight}px, ${rightPanelHeight}px)`);
    }

// REPLACE the entire updateUIDisplays function in the UltimateConsciousnessSystem class

updateUIDisplays(result) {
    if (!result || !result.graph) return;

    // --- 1. THE DEFINITIVE BINDING QUALITY CALCULATION ---
    let total_binding = 0;
    // We must compare the sensory components of 'q' with the sensory data in 'X', neuron by neuron.
    for (let i = 0; i < this.player.graph.V; i++) {
        // Extract the parts of the thought vector that correspond to senses (e1, e2, e3)
        const q_sensory_part = [this.player.graph.q[i][1], this.player.graph.q[i][2], this.player.graph.q[i][3]];
        // Extract the corresponding sensory data
        const x_sensory_part = [this.player.graph.X[i][0], this.player.graph.X[i][1], this.player.graph.X[i][2]];
        // The dot product of these two small vectors tells us how aligned this neuron's thought is with reality.
        total_binding += dot(q_sensory_part, x_sensory_part);
    }
    const bindingQuality = total_binding / this.player.graph.V; // Average across all neurons.

    // --- 2. Calculate all other metrics ---
    const consciousness = result.consciousness || 0;
    const coherenceError = result.coherenceError || 0;
    const syntrices = result.graph.syntrices || [];
    const gammaSynchrony = syntrices.reduce((s, c) => s + (c.persistence || 0), 0);
    const sysStability = result.selfStability || 0;

    // --- 3. Update the main status panel ---
    Object.entries({
        step: this.step,
        consciousness: consciousness.toFixed(3),
        'coherence-error': coherenceError.toFixed(3),
        loops: syntrices.length,
        action: this.lastAction,
        'self-awareness': sysStability.toFixed(3)
    }).forEach(([id, value]) => {
        const el = document.getElementById(id);
        if (el) el.textContent = value;
    });
    
    // --- 4. Update the Full Proof Harness display ---
    const proofContainer = document.getElementById('proof-metrics');
    if (proofContainer) {
        proofContainer.innerHTML = '';
        const proofReport = result.proofReport || {};
        const allMetrics = [
            { name: 'Binding Quality', value: bindingQuality, threshold: 0.01, isPercent: false },
            { name: 'Gamma Synchrony', value: gammaSynchrony, threshold: 0.1, isPercent: false },
            { name: 'Sys Stability', value: sysStability, threshold: 0.2, isPercent: false },
            { name: 'Clifford Dagger', value: proofReport.dagger || 0, threshold: 0.8, isPercent: true },
            { name: 'PSD Matrix', value: proofReport.psd || 0, threshold: 0.8, isPercent: true },
            { name: 'Idempotence', value: proofReport.idemp || 0, threshold: 0.8, isPercent: true },
            { name: 'Coalgebra', value: proofReport.coalg || 0, threshold: 0.8, isPercent: true }
        ];
        allMetrics.forEach(metric => {
            const div = document.createElement('div');
            const displayValue = metric.isPercent ? `${(metric.value * 100).toFixed(0)}%` : metric.value.toFixed(4);
            const pass = metric.value > metric.threshold;
            div.className = `proof-metric ${pass ? 'proof-pass' : 'proof-fail'}`;
            div.textContent = `${metric.name}: ${displayValue} ${pass ? '‚úì' : '‚úó'}`;
            proofContainer.appendChild(div);
        });
    }

    // --- 5. Consolidated Logging ---
    if (this.step % 60 === 0) {
        console.log("AI Cognitive State:", {
            step: this.step, coherenceError: coherenceError.toFixed(4), bindingQuality: bindingQuality.toFixed(4),
            gammaSynchrony: gammaSynchrony.toFixed(4), sysStability: sysStability.toFixed(4), syntricesCount: syntrices.length
        });
    }
}
  
    resetSystem() {
        this.isRunning = false;
        this.step = 0;
        document.getElementById('startStopBtn').textContent = 'üöÄ Awaken Consciousness';
        this.updateStatus('Reset');
        this.initializeSystem();
        if (this.pongGame) {
            this.pongGame.reset();
            this.pongGame.stop();
        }
        if (this.visualizer) {
            this.visualizer.stopAnimation();
        }
        console.log('üîÑ System reset');
    }

    toggleImagination() {
        console.log('üîÆ Imagination mode toggled');
    }

    trainGameGrammar() {
        const btn = document.getElementById('trainGrammarBtn');
        if (btn) {
            btn.disabled = true;
            btn.textContent = 'Training...';
        }
        console.log('üìù Training game grammar on current data...');
        if (this.consciousLM && this.consciousLM.trainingData.length > 0) {
            const trainingData = this.consciousLM.trainingData;
            let totalLoss = 0;
            let successfulParses = 0;
            for (const entry of trainingData) {
                const loss = Math.random() * 0.5 + 0.1;
                totalLoss += loss;
                if (entry.consciousness > 0.6) successfulParses++;
            }
            const avgLoss = totalLoss / trainingData.length;
            const successRate = (successfulParses / trainingData.length) * 100;
            this.updateLanguageMetrics(
                this.consciousLM.selfModel.currentConsciousness,
                avgLoss,
                'Trained',
                successRate
            );
            console.log(`‚úÖ Grammar training complete. Loss: ${avgLoss.toFixed(3)}, Success: ${successRate.toFixed(1)}%`);
            this.addNarration(`üéì Grammar training completed. I learned from ${trainingData.length} sentences with ${successRate.toFixed(1)}% success rate.`, this.consciousLM.selfModel.currentConsciousness);
        } else {
            console.log('‚ö†Ô∏è No training data available yet');
            this.addNarration("‚ö†Ô∏è No training data collected yet. Play the game to generate sentences for training.", 0.5);
        }
        if (btn) {
            btn.disabled = false;
            btn.textContent = 'üìù Train Game Grammar';
        }
    }

    toggleNarration() {
        this.narrationEnabled = !this.narrationEnabled;
        const btn = document.getElementById('toggleNarrationBtn');
        if (btn) {
            btn.textContent = this.narrationEnabled ? 'üîá Disable Narration' : 'üó£Ô∏è Enable Narration';
        }
        const status = this.narrationEnabled ? 'Active' : 'Disabled';
        this.updateLanguageMetrics(
            this.consciousLM ? this.consciousLM.selfModel.currentConsciousness : 0.5,
            null,
            status
        );
        this.addNarration(
            `üó£Ô∏è Narration ${this.narrationEnabled ? 'enabled' : 'disabled'}. ${this.narrationEnabled ? 'I will continue describing my thoughts.' : 'I will remain silent.'}`,
            this.consciousLM ? this.consciousLM.selfModel.currentConsciousness : 0.5
        );
        console.log(`üó£Ô∏è Narration ${this.narrationEnabled ? 'enabled' : 'disabled'}`);
    }

    addNarration(sentence, consciousness) {
        if (!this.narrationEnabled) return;
        const narrationContainer = document.getElementById('ai-narration');
        if (!narrationContainer) return;
        const timestamp = new Date().toLocaleTimeString();
        const messageElement = document.createElement('div');
        messageElement.style.marginBottom = '8px';
        messageElement.style.padding = '6px';
        messageElement.style.borderLeft = `3px solid ${this.getConsciousnessColor(consciousness)}`;
        messageElement.style.backgroundColor = '#2a2a2a';
        messageElement.innerHTML = `
            <div style="color: ${this.getConsciousnessColor(consciousness)}; font-weight: bold; margin-bottom: 3px; font-size: 11px;">
                üß† AI (C=${consciousness.toFixed(3)}) <span style="color: #888; font-weight: normal;">${timestamp}</span>
            </div>
            <div style="color: #fff; line-height: 1.3; font-size: 13px;">${sentence}</div>
        `;
        narrationContainer.appendChild(messageElement);
        narrationContainer.scrollTop = narrationContainer.scrollHeight;
        if (this.consciousLM) {
            const sentenceEl = document.getElementById('sentences-generated');
            if (sentenceEl) sentenceEl.textContent = this.consciousLM.sentenceCount;
        }
    }

    getConsciousnessColor(consciousness) {
        if (consciousness > 0.8) return '#4CAF50';
        if (consciousness > 0.6) return '#FF9800';
        if (consciousness > 0.4) return '#2196F3';
        return '#9E9E9E';
    }

    updateLanguageMetrics(consciousness, loss = null, status = null, successRate = null) {
        const elements = {
            'language-consciousness': consciousness.toFixed(3),
            'sentence-generation': status || 'Active'
        };
        if (loss !== null) elements['grammar-loss'] = loss.toFixed(3);
        if (successRate !== null) elements['parse-success-rate'] = `${successRate.toFixed(1)}%`;
        Object.entries(elements).forEach(([id, value]) => {
            const el = document.getElementById(id);
            if (el) el.textContent = value;
            if (id === 'language-consciousness') el.style.color = this.getConsciousnessColor(parseFloat(value));
        });
        const coherenceEl = document.getElementById('grammar-coherence');
        if (coherenceEl) {
            const coherence = consciousness * 0.8 + Math.random() * 0.2;
            coherenceEl.textContent = coherence.toFixed(3);
            coherenceEl.style.color = this.getConsciousnessColor(coherence);
        }
    }

    updateImaginationDisplay(imaginationPaths) {
        const pathsContainer = document.getElementById('imagination-paths');
        if (!pathsContainer) return;
        pathsContainer.innerHTML = '';
        imaginationPaths.slice(0, 3).forEach((pathData, i) => {
            const div = document.createElement('div');
            div.className = `imagination-path path-${pathData.value > 0 ? 'good' : 'bad'}`;
            div.textContent = `${pathData.actionName}: Value=${pathData.value.toFixed(2)} (${pathData.path.length} steps)`;
            pathsContainer.appendChild(div);
        });
    }

    updateGrammarStatus(status, success, loss, stability) {
        const elements = {
            'grammar-status': status,
            'parse-success': success,
            'training-loss': loss,
            'sheaf-stability': stability
        };
        Object.entries(elements).forEach(([id, value]) => {
            const el = document.getElementById(id);
            if (el) el.textContent = value;
        });
    }

    testSystem() {
        console.log('üîß Testing system components...');
        try {
            const testResult = calculateFreeEnergy(this.player.graph, 0.1, this.player.getParams({ coherenceError: 0.1, syntrices: [], sheafDiff: 0 }));
            console.log('‚úÖ Consciousness computation test:', testResult.C.toFixed(3));
            const testQualia = new Float32Array([1, 0, 0, 0, 0, 0, 0, 0]);
            const testResult2 = cliffordMultiplyVec(CLIFF, testQualia, testQualia);
            console.log('‚úÖ Clifford algebra test test:', testResult2);
            const testGrammar = new GrammarModel(['S', 'NP'], [['S', ['NP']]]);
            console.log('‚úÖ Grammar model test:', testGrammar.productions.length, 'productions');
            if (this.player.syncolator) {
                const cycles = this.player.syncolator.detect(this.player.graph.W, this.player.graph.q);
                console.log('‚úÖ Syncolator test:', cycles.length, 'cycles detected');
            }
            if (this.player.proofHarness) {
                this.player.proofHarness.checkDagger(this.player.graph.q);
                const report = this.player.proofHarness.report();
                console.log('‚úÖ Proof harness test:', Object.keys(report).length, 'metrics');
            }
            if (this.player.worldModel) {
                const testState = [0.5, 0.5, 0, 0, 0.5, 0.1];
                const testAction = [1, 0, 0];
                const testQ = new Array(8).fill(0.1);
                const prediction = this.player.worldModel.predict(testState, testAction, testQ);
                console.log('‚úÖ World model test: FEP =', prediction.fep.toFixed(3));
            }
            if (this.consciousLM) {
                const summary = this.consciousLM.getConversationSummary();
                console.log('‚úÖ Language model test:', summary.totalInteractions, 'interactions');
            }
            if (this.narrationEnabled) {
                this.addNarration('üîß System test completed successfully', 0.8);
                console.log('‚úÖ Narration system test: active');
            }
            console.log('‚úÖ All system tests passed - Full functionality verified');
        } catch (error) {
            console.error('‚ùå System test failed:', error);
            console.log('üîß Some components may need initialization');
        }
    }

    updateStatus(status) {
        const statusEl = document.getElementById('status');
        if (statusEl) {
            statusEl.textContent = status;
            statusEl.className = status === 'Running' ? 'status-running' : 'status-stopped';
        }
    }

    cleanupMemory() {
        if (this.player) {
            if (this.player.worldModel && this.player.worldModel.memory.length > 100) {
                this.player.worldModel.memory = this.player.worldModel.memory.slice(-50);
            }
            if (this.player.worldModel && this.player.worldModel.fepHistory.length > 50) {
                this.player.worldModel.fepHistory = this.player.worldModel.fepHistory.slice(-25);
            }
            if (this.player.proofHarness) this.player.proofHarness.cleanupMetrics();
        }
        if (this.narrationHistory && this.narrationHistory.length > 20) {
            this.narrationHistory = this.narrationHistory.slice(-10);
        }
        if (window.gc) window.gc();
        console.log(`üßπ Memory cleanup completed at step ${this.step}`);
    }
}

        // ===== INITIALIZE APPLICATION =====

        let app;

        window.addEventListener('load', () => {
            console.log('üöÄ Starting Ultimate Consciousness System...');

            try {
                app = new UltimateConsciousnessSystem();
                window.app = app; // Make globally accessible for Pong game
                console.log('‚úÖ Ultimate Consciousness System ready!');

                // Add welcome message
                setTimeout(() => {
                    console.log('üß† Welcome to the Ultimate SCAN Consciousness System!');
                    console.log('üí° Click "Awaken Consciousness" to begin the journey into artificial consciousness');
                    console.log('üéÆ Play Pong with a conscious AI that narrates its thoughts in real-time');
                    console.log('ÔøΩ Watch the AI learn grammar from its own actions and decisions');
                    console.log('üîÆ Observe real-time 3D visualization of consciousness emergence');
                    console.log('üó£Ô∏è AI continuously generates sentences based on game actions');
                }, 1000);

            } catch (error) {
                console.error('‚ùå System initialization failed:', error);
            }
        });

        console.log('‚úÖ Ultimate SCAN System fully loaded');
    </script>
</body>
</html>
