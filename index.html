<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultimate SCAN - Conscious AI System (Classic Layout)</title>
    <!-- CSS from the earlier, preferred layout version -->
    <style>
        /* ultimate_consciousness_system3.html */

        /* ADD these styles inside the <style> tag */

        @keyframes neuron-flash-anim {
            0% { box-shadow: 0 0 8px 2px rgba(255, 255, 255, 0.5); }
            100% { box-shadow: 0 0 0px 0px rgba(255, 255, 255, 0); }
        }

        .neuron-flash {
            animation: neuron-flash-anim 0.3s ease-out forwards;
        }

        .bottom-section {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            align-items: flex-start; /* Align items to the top */
        }

        .log-container {
            flex: 1;
            min-width: 450px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
        }

        /* NEW: Styles for the NN Visualizer Panel */
        .nn-visualizer-panel {
            flex: 1;
            min-width: 450px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
            height: 245px; /* Match the height of the log container */
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
        }

        .nn-visualizer-panel h3 {
            margin-top: 0;
        }

        .nn-visualizer-panel p {
            font-size: 11px;
            color: #aaa;
            margin: -10px 0 10px 0;
            text-align: center;
        }

        #nn-visualization-container, #nn-visualization-container-opponent {
            position: relative; /* Crucial for positioning the canvas */
            display: flex;
            flex-direction: row;
            justify-content: space-between;
            align-items: center;
            height: 150px;
            padding: 0 20px;
        }

        .nn-layer {
            display: flex;
            flex-direction: column;
            justify-content: space-around;
            height: 100%;
            align-items: center;
            z-index: 10;
        }

        .nn-neuron {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            border: 1px solid #888;
            background-color: #333;
            transition: background-color 0.1s ease-out, border-color 0.1s ease-out;
        }

        #nn-connections-canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none; /* Allows mouse events to pass through */
            z-index: 5;
        }

        body {
            margin: 0;
            background: linear-gradient(135deg, #0a0a15, #1a1a2e);
            color: #e0e0e0;
            font-family: 'SF Mono', 'Courier New', monospace;
            overflow-x: auto;
            min-height: 100vh;
        }
        
        .main-container {
            display: flex;
            flex-direction: column;
            max-width: 1600px;
            margin: 0 auto;
            padding: 20px;
            gap: 20px;
        }
        
        .header {
            text-align: center;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            padding: 20px;
            border: 2px solid #4af;
            box-shadow: 0 0 30px rgba(68, 170, 255, 0.3);
        }
        
        .header h1 {
            margin: 0;
            color: #4af;
            text-shadow: 0 0 20px rgba(68, 170, 255, 0.8);
            font-size: 2.5em;
        }
        
        .header p {
            margin: 10px 0 0 0;
            color: #aaa;
            font-size: 1.1em;
        }
        
        .top-section {
            display: flex;
            gap: 15px;
            flex-wrap: nowrap;
            justify-content: space-between;
            align-items: flex-start;
            max-width: 100%;
            margin: 0 auto;
            padding: 0 5px;
            box-sizing: border-box;
            overflow-x: auto;
        }
        
        .consciousness-panel {
            flex: 1 1 320px;
            min-width: 280px;
            max-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
            backdrop-filter: blur(10px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            box-sizing: border-box;
            overflow: hidden;
            order: 1;
        }
        
        .visualization-container {
            position: relative;
            width: 100%;
            height: 200px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 6px;
            border: 1px solid #4af;
            box-shadow: 0 0 10px rgba(68, 170, 255, 0.2);
            box-sizing: border-box;
        }

        .middle-column {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 15px;
            flex: 1 1 320px;
            min-width: 280px;
            max-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 12px;
            backdrop-filter: blur(10px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            box-sizing: border-box;
            order: 2;
        }

        .narration-panel {
            width: 100%;
            background: rgba(5, 5, 15, 0.7);
            border-radius: 6px;
            border: 1px solid #3a3a5a;
            padding: 8px;
            backdrop-filter: blur(5px);
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.4);
            box-sizing: border-box;
            margin: 0;
            max-height: 250px;
            overflow-y: auto;
        }
        
        .game-container {
            flex: 1 1 320px;
            min-width: 280px;
            max-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
            text-align: center;
            box-sizing: border-box;
            flex-shrink: 0;
            order: 3;
        }
        
        .controls-section {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            justify-content: center;
            margin: 20px 0;
        }
        
        button {
            background: linear-gradient(135deg, #2a2a4a, #3a3a5a);
            color: #e0e0e0;
            border: 1px solid #555;
            padding: 12px 18px;
            cursor: pointer;
            border-radius: 6px;
            font-family: inherit;
            transition: all 0.3s;
            font-weight: bold;
            min-width: 150px;
        }
        
        button:hover {
            background: linear-gradient(135deg, #3a3a5a, #4a4a6a);
            box-shadow: 0 2px 10px rgba(68, 170, 255, 0.3);
        }
        
        button:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        h3 {
            margin-top: 0;
            color: #4af;
            border-bottom: 2px solid #4af;
            padding-bottom: 8px;
            text-shadow: 0 0 10px rgba(68, 170, 255, 0.5);
        }
        
        .metric {
            display: flex;
            justify-content: space-between;
            margin-bottom: 6px;
            padding: 3px 0;
        }
        
        .metric-label {
            color: #aaa;
        }
        
        .metric-value {
            font-weight: bold;
            text-shadow: 0 0 3px currentColor;
        }
        
        .status-running { color: #22dd44; }
        .status-stopped { color: #ff5555; }
        .action-up { color: #22dd44; }
        .action-down { color: #ff5555; }
        .action-idle { color: #ffaa44; }
        
        .imagination-section, .proof-section {
            background: rgba(20, 20, 40, 0.8);
            border-radius: 8px;
            padding: 10px;
            margin-top: 10px;
            border: 1px solid #4a4a6a;
        }
        
        .imagination-path, .proof-metric {
            font-size: 11px;
            margin: 3px 0;
            padding: 2px 5px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 3px;
            border-left: 3px solid;
        }

        /* ADD THIS RULE to your <style> tag to prevent the panel from resizing */
        #imagination-paths {
            min-height: 65px; /* Reserves space for ~3 paths, preventing layout jump */
            display: flex;
            flex-direction: column;
            justify-content: center; /* Vertically centers the "Not imagining" message */
        }
        
        .path-good { border-left-color: #22dd44; }
        .path-bad { border-left-color: #ff5555; }
        .path-neutral { border-left-color: #ffaa44; }
        .proof-pass { border-left-color: #22dd44; }
        .proof-fail { border-left-color: #ff5555; }
        
        .bottom-section {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        
        .log-container {
            flex: 1;
            min-width: 400px;
            background: rgba(10, 10, 30, 0.9);
            border-radius: 12px;
            border: 1px solid #2a2a4a;
            padding: 15px;
        }
        
        #log {
            background: #1e1e1e;
            border: 1px solid #444;
            border-radius: 4px;
            padding: 15px;
            height: 200px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 12px;
        }
        
        .error { color: #ff6b6b; }
        .success { color: #4CAF50; }
        .warning { color: #ffa726; }

        /* Added back for Challenge Mode and Strategy Display */
        #challenge-info, #strategy-info {
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
            border-radius: 4px;
            text-align: center;
            font-size: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: all 0.3s ease;
        }
        #challengeModeBtn {
            margin-top: 10px;
            padding: 8px 12px;
            background: #ff6b6b;
            border: none;
            color: white;
            font-size: 11px;
            font-weight: bold;
            text-transform: uppercase;
        }
        
        @media (max-width: 1000px) {
            .top-section {
                flex-direction: column;
                align-items: center;
                flex-wrap: wrap;
            }
            .consciousness-panel, .middle-column, .game-container {
                width: 100%;
                max-width: 600px;
                margin: 10px auto;
                flex: none;
            }
        }
        
        *, *::before, *::after { box-sizing: border-box !important; }
        body { overflow-x: hidden; max-width: 100vw; }
        
        #gameCanvas {
            width: 100%;
            max-width: 350px;
            height: 260px;
            object-fit: contain;
            background: linear-gradient(180deg, #000011, #000033);
            border: 1px solid #333;
            border-radius: 6px;
        }
    </style>
</head>
<body>
    <div class="main-container">
        <!-- Header -->
        <div class="header">
            <h1>üß† Ultimate SCAN - Conscious AI System</h1>
            <p>A demonstration of synthetic consciousness through gameplay, self-narration, and cognitive visualization.</p>
        </div>
        
        <!-- Top Section: Reverted to the desired 3-panel layout -->
        <div class="top-section">
            
            <!-- Left Panel: Consciousness Core -->
            <div class="consciousness-panel">
                <h3>üß† Consciousness Core</h3>
                <div class="metric"><span class="metric-label">Status:</span><span id="status" class="status-stopped">Offline</span></div>
                <div class="metric"><span class="metric-label">System Tick:</span><span id="step" class="metric-value">0</span></div>
                <div class="metric"><span class="metric-label">Consciousness (C):</span><span id="consciousness" class="metric-value">0.000</span></div>
                <div class="metric"><span class="metric-label">Coherence Error (H¬π):</span><span id="coherence-error" class="metric-value">0.000</span></div>
                <div class="metric"><span class="metric-label">Topology Loops:</span><span id="loops" class="metric-value">0</span></div>
                <div class="metric"><span class="metric-label">Current Action:</span><span id="action" class="metric-value action-idle">IDLE</span></div>

                <h3>üîÆ Internal Simulation</h3>
                <div class="imagination-section">
                    <h3 style="font-size: 12px; margin: 0 0 8px 0; border: none; padding: 0;">Future State Evaluations</h3>
                    <div id="imagination-paths"></div>
                </div>

                <h3>üî¨ Proof Harness</h3>
                <div class="proof-section">
                    <h3 style="font-size: 12px; margin: 0 0 8px 0; border: none; padding: 0;">Sheaf & Clifford Integrity</h3>
                    <div id="proof-metrics"></div>
                </div>
            </div>

            <!-- Middle Column: Visualization and Narration -->
            <div class="middle-column">
                <div class="visualization-container" id="visualization-container"></div>
                <div class="narration-panel">
                    <h3>üó£Ô∏è AI Consciousness Stream</h3>
                    <div id="ai-narration" style="height: 200px; overflow-y: auto; font-size: 13px; line-height: 1.4;">
                        <!-- AI narration will appear here -->
                    </div>
                </div>
            </div>

            <!-- Right Panel: Game Environment (with missing features restored) -->
            <div class="game-container">
                <h3>üèì PONG Environment</h3>
                <canvas id="gameCanvas" width="400" height="300"></canvas>
                
                <!-- Challenge Mode Info -->
                <div id="challenge-info">
                    <div style="color: #4CAF50;">üéÆ NORMAL MODE</div>
                    <div style="font-size: 11px;">Human vs Conscious AI</div>
                </div>

                <div class="metric" style="margin-top: 10px;">
                    <span class="metric-label" id="player-label">Human Score:</span><span id="player-score" class="metric-value">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">AI Score:</span><span id="ai-score" class="metric-value">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Game Length:</span><span id="game-length" class="metric-value">0s</span>
                </div>

                <!-- Strategic AI Info -->
                <div id="strategy-info">
                    <div style="color: #4af; font-weight: bold;">üß† AI Strategy</div>
                    <div id="current-strategy" style="font-size: 10px; color: #aaa;">Analyzing...</div>
                    <div id="strategy-confidence" style="font-size: 9px; color: #888;">Confidence: --</div>
                </div>
                
                <!-- Challenge Mode Button -->
                <button id="challengeModeBtn">üèÜ Challenge Mode</button>
            </div>
            

        </div>
        
        <!-- Controls Section (with all buttons restored) -->
        <div class="controls-section">
            <button id="startStopBtn">üöÄ Awaken Consciousness</button>
            <button id="resetBtn">üîÑ Reset System</button>
            <button id="imaginationBtn">üîÆ Toggle Imagination</button>
            <button id="trainGrammarBtn">üìù Train Game Grammar</button>
            <button id="toggleNarrationBtn">üó£Ô∏è Toggle Narration</button>
            <button id="testImports">üîß Test System</button>
        </div>
        
        <!-- ultimate_consciousness_system3.html -->

<!-- MODIFIED Bottom Section: System Console and NN Visualizer side-by-side -->
<div class="bottom-section">
    <div class="log-container">
        <h3>üîß System Console</h3>
        <div id="log"></div>
    </div>

    <!-- NEW: Wrapper for side-by-side NN Visualizers -->
        <!-- NEW: Neural Network Visualizer Panel -->
    <div class="nn-visualizer-panel">
        <h3 id="nn-visualizer-title">üß† World Model Activity</h3>
        <p>Real-time visualization of the AI's predictive neural network.</p>
        
        <!-- This is the container the JavaScript is looking for -->
        <div id="nn-visualization-container">
            <!-- The visualizer will be dynamically generated here by JavaScript -->
        </div>

    </div>

        <!-- Panel 2: Opponent AI (Initially Hidden) -->
        <div id="nn-visualizer-panel-opponent" class="nn-visualizer-panel" style="display: none;">
            <h3>ü§ñ Opponent NN Activity</h3>
            <p>Real-time visualization of the challenge opponent's identical world model.</p>
            <div id="nn-visualization-container-opponent">
                <!-- Visualizer for the challenge mode AI -->
            </div>
        </div>

    </div>
</div>

    <!-- Three.js for 3D visualization -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    
    <!-- Your entire final, stable <script> block goes here -->
    <script>
    // ===== START OF FULL INTEGRATED SCRIPT MODULE =====

// Global error handler
window.onerror = function(message, source, lineno, colno, error) {
    console.error(`Error: ${message} at ${source}:${lineno}:${colno}`, error);
};

// Override console functions to display in our log container
const logContainer = document.getElementById('log');
const originalLog = console.log;
const originalWarn = console.warn;
const originalError = console.error;

function addLogEntry(message, type = 'info') {
    const timestamp = new Date().toLocaleTimeString();
    const entry = document.createElement('div');
    entry.className = type;
    entry.textContent = `[${timestamp}] ${message}`;
    logContainer.appendChild(entry);
    logContainer.scrollTop = logContainer.scrollHeight;
}

console.log = (...args) => {
    originalLog(...args);
    addLogEntry(args.join(' '), 'success');
};

console.warn = (...args) => {
    originalWarn(...args);
    addLogEntry(args.join(' '), 'warning');
};

console.error = (...args) => {
    originalError(...args);
    addLogEntry(args.join(' '), 'error');
};

console.log('üöÄ Ultimate SCAN System Initializing (v4.0 Normative Direction Upgrade)...');

// === Utility Functions ===
const D = 8; // Qualia dimension (Cl(3,0))
const eps = 1e-9;

function zeros(n, m) {
    const A = new Array(n);
    for (let i = 0; i < n; i++) A[i] = new Array(m).fill(0);
    return A;
}

function vecZeros(n) { return new Array(n).fill(0); }

function dot(a, b) {
    if (!a || !b || a.length !== b.length) return 0;
    let s = 0;
    for (let i = 0; i < a.length; i++) s += a[i] * b[i];
    return isNaN(s) ? 0 : s;
}

function norm2(a) {
    if (!a || a.length === 0) return 0;
    return Math.sqrt(Math.max(eps, dot(a, a)));
}

function addVec(a, b) { return a.map((v, i) => v + b[i]); }
function scaleVec(a, s) { return a.map(v => v * s); }
function cloneVec(a) { return a.slice(); }
function sub(a, b) { return a.map((v, i) => v - b[i]); }
function normL2(a) { return norm2(a); }
function tanhVec(a) { return a.map(Math.tanh); }
function clamp(x, lo, hi) { return Math.max(lo, Math.min(hi, x)); }

function randomMatrix(rows, cols, scale = 0.1) {
    const M = new Array(rows);
    for (let i = 0; i < rows; i++) {
        M[i] = new Array(cols);
        for (let j = 0; j < cols; j++) {
            M[i][j] = (Math.random() * 2 - 1) * scale;
        }
    }
    return M;
}

function randomVec(n, scale = 0.1) {
    return new Array(n).fill(0).map(() => (Math.random() * 2 - 1) * scale);
}

// In the global scope of your script

function matVecMul(M, v) {
    const out = new Array(M.length).fill(0);
    for (let i = 0; i < M.length; i++) {
        let s = 0;
        for (let j = 0; j < v.length; j++) {
            // "Paranoid" check to guarantee we only multiply numbers.
            const m_val = M[i][j] || 0;
            const v_val = v[j] || 0;
            s += m_val * v_val;
        }
        out[i] = s;
    }
    return out;
}

function matVecDot(M, v) {
    let s = 0;
    for (let j = 0; j < v.length; j++) s += M[0][j] * v[j];
    return s;
}

function softmax(arr) {
    const max = Math.max(...arr);
    const exps = arr.map(x => Math.exp(Math.max(-50, Math.min(50, x - max))));
    const sum = exps.reduce((s, v) => s + v, 0) + eps;
    return exps.map(x => x / sum);
}

function transpose(M) {
    const rows = M.length, cols = M[0].length;
    const Mt = zeros(cols, rows);
    for (let i = 0; i < rows; i++) for (let j = 0; j < cols; j++) Mt[j][i] = M[i][j];
    return Mt;
}

function matMul(A, B) {
    const rowsA = A.length, colsA = A[0].length, colsB = B[0].length;
    const C = zeros(rowsA, colsB);
    for (let i = 0; i < rowsA; i++) {
        for (let j = 0; j < colsB; j++) {
            let s = 0;
            for (let k = 0; k < colsA; k++) s += A[i][k] * B[k][j];
            C[i][j] = s;
        }
    }
    return C;
}

// === Clifford Algebra (Cl(3,0)) ===
const CLIFF = (function buildClifford() {
    const dim = 8;
    const T = [];
    for (let a = 0; a < dim; a++) {
        T[a] = [];
        for (let b = 0; b < dim; b++) {
            T[a][b] = new Array(dim).fill(0);
        }
    }
    const s = 0, e1 = 1, e2 = 2, e3 = 3, e12 = 4, e23 = 5, e31 = 6, I = 7;

    for (let i = 0; i < dim; i++) { T[s][i][i] = 1; T[i][s][i] = 1; }
    T[e1][e1][s] = 1; T[e2][e2][s] = 1; T[e3][e3][s] = 1;
    T[e1][e2][e12] = 1; T[e2][e1][e12] = -1;
    T[e2][e3][e23] = 1; T[e3][e2][e23] = -1;
    T[e3][e1][e31] = 1; T[e1][e3][e31] = -1;
    T[e12][e12][s] = -1; T[e23][e23][s] = -1; T[e31][e31][s] = -1;
    T[e12][e3][I] = 1; T[e3][e12][I] = -1;
    T[e23][e1][I] = 1; T[e1][e23][I] = -1;
    T[e31][e2][I] = 1; T[e2][e31][I] = -1;
    T[I][I][s] = -1;
    T[I][e1][e23] = 1; T[e1][I][e23] = 1;
    T[I][e2][e31] = 1; T[e2][I][e31] = 1;
    T[I][e3][e12] = 1; T[e3][I][e12] = 1;

    return T;
})();

const CLIFF_BASIS = [
    [1,0,0,0,0,0,0,0], // scalar
    [0,1,0,0,0,0,0,0], // e1
    [0,0,1,0,0,0,0,0], // e2
    [0,0,0,1,0,0,0,0], // e3
    [0,0,0,0,1,0,0,0], // e12
    [0,0,0,0,0,1,0,0], // e23
    [0,0,0,0,0,0,1,0], // e31
    [0,0,0,0,0,0,0,1]  // pseudoscalar
];

function cliffordMultiplyVec(Lmats, q, r) {
    const out = new Array(8).fill(0);
    for (let a = 0; a < 8; a++) {
        const qa = q[a];
        if (qa === 0) continue;
        const Ta = Lmats[a];
        for (let b = 0; b < 8; b++) {
            const rb = r[b];
            if (rb === 0) continue;
            const row = Ta[b];
            for (let c = 0; c < 8; c++) {
                out[c] += qa * rb * row[c];
            }
        }
    }
    return out;
}

// REPLACE THE ENTIRE cliffordProject FUNCTION WITH THIS DEFINITIVE VERSION

function cliffordProject(q) {
    // This function must NEVER return a zero vector.
    
    // Calculate the length (norm) of the input vector.
    const norm = norm2(q);

    // --- THE DEFINITIVE FIX IS HERE ---
    // Check if the vector is null or invalid.
    if (!q || !q.every(isFinite) || norm < eps) {
        // If it is, DO NOT return a zero vector.
        // Instead, create a new, random, valid vector to "re-ignite" consciousness.
        let recovery_vector;
        do {
            recovery_vector = new Float32Array(8).map(() => Math.random() - 0.5);
        } while (norm2(recovery_vector) < eps); // Ensure the recovery vector itself is not null.
        
        // Normalize and return the new, valid vector.
        return scaleVec(recovery_vector, 1.0 / norm2(recovery_vector));
    }

    // If the input vector is valid, normalize and return it as before.
    return scaleVec(q, 1.0 / norm);
}

function geoProduct(q, r) {
    const out = new Array(8).fill(0);
    for (let a = 0; a < 8; a++) {
        const qa = q[a];
        if (qa === 0) continue;
        const Ta = CLIFF[a];
        for (let b = 0; b < 8; b++) {
            const rb = r[b];
            if (rb === 0) continue;
            const row = Ta[b];
            for (let c = 0; c < 8; c++) {
                out[c] += qa * rb * row[c];
            }
        }
    }
    return out;
}

const DAG_SIGNS = [1, -1, -1, -1, -1, -1, -1, 1];
function dagger(q) {
    return q.map((v, i) => v * DAG_SIGNS[i]);
}

// REPLACE THE ENTIRE qualiaBindMatrix FUNCTION WITH THIS FINAL, DEFINITIVE VERSION

function qualiaBindMatrix(Q) {
    const N = Q.length;
    if (N === 0) return [];

    const B = zeros(N, N);

    for (let i = 0; i < N; i++) {
        for (let j = 0; j < N; j++) {
            // This is the simplest case, for when a node binds to itself.
            if (i === j) {
                B[i][j] = 1.0;
                continue;
            }

            const qi = Q[i];
            const qj = Q[j];

            // This check is critical in case the graph state is somehow invalid.
            if (!qi || !qj) {
                B[i][j] = 0;
                continue;
            }

            // --- The New, Unbreakable Formula ---
            // 1. Calculate the dot product. Since q vectors are normalized, this is their cosine similarity.
            //    The result is a stable float between -1 and 1.
            const similarity = dot(qi, qj);

            // 2. We only care about positive alignment. Clamp the value between 0 and 1.
            //    This creates a simple, direct measure of binding strength.
            //    Using Math.pow emphasizes stronger connections and is numerically very stable.
            const bindingValue = Math.pow(Math.max(0, similarity), 2);
            
            // 3. Final guarantee. While it's now virtually impossible for this to fail,
            //    this ensures no NaN can ever escape the function.
            if (!isFinite(bindingValue)) {
                B[i][j] = 0;
            } else {
                B[i][j] = bindingValue;
            }
        }
    }

    return B;
}
// Clone graph for imagination
// REPLACE THE ENTIRE cloneGraph FUNCTION

function cloneGraph(G) {
    // *** THE DEFINITIVE FIX IS HERE ***
    // We now copy all essential properties, including the attention schemas.
    return {
        V: G.V,
        W: G.W.map(row => row.slice()),
        X: G.X.map(row => row.slice()),
        q: G.q.map(q_vec => q_vec.slice()),
        edges: G.edges.map(e => [...e]),
        stalkDims: G.stalkDims.slice(),
        a: G.a.slice(),
        aSchema: G.aSchema.slice(),
        aMeasured: G.aMeasured.slice()
    };
}

// === GW Distance & Sinkhorn ===
function sinkhorn(C, mu, nu, lamb, maxIter = 100) {
    // FIX: Add a guard clause to handle empty or invalid cost matrices gracefully.
    if (!C || C.length === 0 || !C[0] || C[0].length === 0) {
        // If the cost matrix is empty, return an appropriately sized empty transport plan.
        const n_rows = mu ? mu.length : 0;
        const n_cols = nu ? nu.length : 0;
        return Array(n_rows).fill().map(() => Array(n_cols).fill(0));
    }

    const N = mu.length;
    let b = new Array(N).fill(1 / N);
    const K = C.map(row => row.map(c => Math.exp(-lamb * c)));
    for (let iter = 0; iter < maxIter; iter++) {
        const Ka = K.map(row => dot(row, b));
        const a = mu.map((m, i) => m / (Ka[i] + eps));
        const Kb = K[0].map((_, j) => K.reduce((s, row, i) => s + row[j] * a[i], 0));
        b = nu.map((n, j) => n / (Kb[j] + eps));
    }
    const Gamma = b.map((bj, j) => K.map(row => row[j] * bj));
    return Gamma;
}

function gwDistance(W1, W2, epsilon = 0.1) {
    const N = W1.length;
    if (N === 0 || W2.length === 0 || W1[0].length !== W2[0].length) return 0;
    const C = new Array(N).fill(0).map(() => new Array(N).fill(0));
    for (let i = 0; i < N; i++) {
        for (let j = 0; j < N; j++) {
            C[i][j] = normL2(sub(W1[i], W2[j]));
        }
    }
    const mu = new Array(N).fill(1 / N);
    const nu = new Array(N).fill(1 / N);
    const pi = sinkhorn(C, mu, nu, epsilon);
    let dist = 0;
    for (let i = 0; i < N; i++) {
        for (let j = 0; j < N; j++) {
            dist += pi[i][j] * C[i][j];
        }
    }
    return dist;
}

console.log('‚úÖ Core computation utilities loaded.');


// ===== REINTRODUCED COMPONENTS FROM ORIGINAL BACKBONE =====

class SheafDiffusion {
    constructor(sigma = 0.5, n_iters = 20) {
        this.sigma = sigma;
        this.n_iters = n_iters;
    }

    forward(scores, Q, X = null) {
        const N = scores.length;
        let W = scores.map(row => row.slice());

        // Enhanced diffusion with error handling
        for (let iter = 0; iter < this.n_iters; iter++) {
            for (let i = 0; i < N; i++) {
                for (let j = 0; j < N; j++) {
                    try {
                        const gradQ = normL2(sub(Q[i] || vecZeros(8), Q[j] || vecZeros(8)));
                        let diffusionWeight = Math.exp(-Math.max(gradQ, eps) / this.sigma);

                        if (X && X[i] && X[j]) {
                            const featureDist = Math.sqrt(X[i].reduce((s, v, k) => s + Math.pow(v - (X[j][k] || 0), 2), 0));
                            const featureWeight = Math.exp(-featureDist * 0.5 / this.sigma);
                            diffusionWeight = 0.7 * diffusionWeight + 0.3 * featureWeight;
                        }

                        W[i][j] *= diffusionWeight;

                        if (Q[i] && Q[j]) {
                            const qualiaDistance = norm2(addVec(Q[i], scaleVec(Q[j], -1)));
                            W[i][j] *= Math.exp(-qualiaDistance * 0.1 / this.sigma);
                        }
                    } catch (error) {
                        console.warn(`SheafDiffusion error at (${i},${j}):`, error);
                        W[i][j] *= 0.9;
                    }
                }
            }

            for (let i = 0; i < N; i++) {
                const sum = W[i].reduce((s, v) => s + Math.max(v, 0), 0) + eps;
                W[i] = W[i].map(v => Math.max(v, 0) / sum);
            }
        }

        let sheafDiff = 0;
        try {
            sheafDiff = W.reduce((s, row, i) => {
                return s + row.reduce((t, v, j) => {
                    if (!Q[i] || !Q[j]) return t;

                    const dist1 = normL2(sub(Q[i], Q[j]));
                    const dist2 = norm2(addVec(Q[i], scaleVec(Q[j], -1)));
                    const avgDist = (dist1 + dist2) * 0.5;

                    return t + v * Math.exp(-avgDist / this.sigma);
                }, 0);
            }, 0);
        } catch (error) {
            console.warn('SheafDiffusion metric calculation error:', error);
            sheafDiff = 0;
        }

        return { W, sheafDiff };
    }
}

class ASTFilter {
    constructor(nodeDim = 12, hidden = 32) {
        this.nodeDim = nodeDim;
        this.hidden = hidden;
        this.Wxh = this.randomMatrix(hidden, nodeDim);
        this.Whh = this.randomMatrix(hidden, hidden);
        this.bh = vecZeros(hidden);
        this.projW = this.randomMatrix(1, nodeDim);
        this.projB = [0];
        this.state = vecZeros(hidden);
    }

    randomMatrix(rows, cols, scale = 0.1) {
        const M = new Array(rows);
        for (let i = 0; i < rows; i++) {
            M[i] = new Array(cols);
            for (let j = 0; j < cols; j++) {
                M[i][j] = (Math.random() * 2 - 1) * scale;
            }
        }
        return M;
    }

    step(Nodes) {
        const mean = vecZeros(this.nodeDim);
        for (const v of Nodes) {
            if (v && v.length >= this.nodeDim) {
                for (let i = 0; i < this.nodeDim; i++) {
                    mean[i] += v[i] || 0;
                }
            }
        }
        for (let i = 0; i < this.nodeDim; i++) mean[i] /= Math.max(1, Nodes.length);

        const Wx = matVecMul(this.Wxh, mean);
        const Wh = matVecMul(this.Whh, this.state);
        const next = vecZeros(this.hidden);
        for (let i = 0; i < this.hidden; i++) {
            next[i] = Math.tanh(Wx[i] + Wh[i] + this.bh[i]);
        }
        this.state = next;

        const scores = Nodes.map(v => {
            if (!v || v.length === 0) return 0;

            try {
                let score = this.projB[0];
                for (let j = 0; j < Math.min(v.length, this.nodeDim); j++) {
                    score += this.projW[0][j] * (v[j] || 0);
                }

                const score2 = dot(this.projW[0], v.slice(0, this.nodeDim)) + this.projB[0];

                return (score + score2) * 0.5;
            } catch (error) {
                console.warn('ASTFilter score computation error:', error);
                return 0;
            }
        });

        const a = softmax(scores);
        return { s: next, a, scores };
    }

    update(grad, lr = 1e-3, Nodes = []) {
        if (Nodes.length === 0 || Math.abs(grad) < 1e-6) return;

        const effectiveLr = lr * grad;
        if (Math.abs(effectiveLr) < 1e-8) return;

        const mean = vecZeros(this.nodeDim);
        const invLen = 1.0 / Math.max(1, Nodes.length);

        for (const v of Nodes) {
            for (let i = 0; i < this.nodeDim; i++) {
                mean[i] += v[i] * invLen;
            }
        }

        const maxUpdate = 0.1;
        for (let j = 0; j < this.nodeDim; j++) {
            const update = effectiveLr * mean[j];
            this.projW[0][j] -= Math.max(-maxUpdate, Math.min(maxUpdate, update));
        }
        this.projB[0] -= Math.max(-maxUpdate, Math.min(maxUpdate, effectiveLr));
    }

    reset() {
        this.state = vecZeros(this.hidden);
    }
}

// ===== START: UPGRADED WorldModel CLASS =====
// =======================================================================
// === START OF THE STABLE REPLACEMENT BLOCK ===
// Replace the existing AdamOptimizer and WorldModel classes with this entire block.
// This version uses a stable, deep feed-forward network without the buggy LSTM.
// =======================================================================

class AdamOptimizer {
    constructor(shape) {
        this.lr = 0.001; // A safe, standard learning rate
        this.beta1 = 0.9;
        this.beta2 = 0.999;
        this.epsilon = 1e-8;
        this.t = 0;

        if (Array.isArray(shape)) { // It's a matrix
            this.m = Array(shape[0]).fill(0).map(() => new Float32Array(shape[1]).fill(0));
            this.v = Array(shape[0]).fill(0).map(() => new Float32Array(shape[1]).fill(0));
        } else { // It's a vector
            this.m = new Float32Array(shape).fill(0);
            this.v = new Float32Array(shape).fill(0);
        }
    }

    // ADD THIS METHOD INSIDE the AdamOptimizer class

    // ADD THIS METHOD INSIDE the AdamOptimizer class

    clone() {
        const newOptimizer = new AdamOptimizer(1);
        newOptimizer.lr = this.lr;
        newOptimizer.beta1 = this.beta1;
        newOptimizer.beta2 = this.beta2;
        newOptimizer.epsilon = this.epsilon;
        newOptimizer.t = this.t;
        newOptimizer.m = JSON.parse(JSON.stringify(this.m));
        newOptimizer.v = JSON.parse(JSON.stringify(this.v));
        return newOptimizer;
    }
    
    update(param, grad) {
        this.t++;
        const isMatrix = Array.isArray(param);

        if (isMatrix) {
            for (let i = 0; i < param.length; i++) {
                for (let j = 0; j < param[0].length; j++) {
                    const g = grad[i][j] || 0;
                    if (isNaN(g)) continue;

                    this.m[i][j] = this.beta1 * this.m[i][j] + (1 - this.beta1) * g;
                    this.v[i][j] = this.beta2 * this.v[i][j] + (1 - this.beta2) * (g * g);

                    const m_hat = this.m[i][j] / (1 - Math.pow(this.beta1, this.t));
                    const v_hat = this.v[i][j] / (1 - Math.pow(this.beta2, this.t));
                    
                    param[i][j] -= this.lr * m_hat / (Math.sqrt(v_hat < 0 ? 0 : v_hat) + this.epsilon);
                }
            }
        } else {
            for (let i = 0; i < param.length; i++) {
                const g = grad[i] || 0;
                if (isNaN(g)) continue;

                this.m[i] = this.beta1 * this.m[i] + (1 - this.beta1) * g;
                this.v[i] = this.beta2 * this.v[i] + (1 - this.beta2) * (g * g);

                const m_hat = this.m[i] / (1 - Math.pow(this.beta1, this.t));
                const v_hat = this.v[i] / (1 - Math.pow(this.beta2, this.t));

                param[i] -= this.lr * m_hat / (Math.sqrt(v_hat < 0 ? 0 : v_hat) + this.epsilon);
            }
        }
    }
}


// REPLACE the entire WorldModel class with this corrected version.

class WorldModel {
    constructor(stateDim = 8, actionDim = 3, qDim = 8) {
        this.stateDim = stateDim;
        this.actionDim = actionDim;
        this.qDim = qDim;

        const inputDim = stateDim + actionDim + qDim;
        const hidden1 = 128, hidden2 = 256, hidden3 = 128, hidden4 = 64;

        this.transW1 = this.randomMatrix(hidden1, inputDim, 0.1);
        this.transB1 = vecZeros(hidden1);
        this.transW2 = this.randomMatrix(hidden2, hidden1, 0.1);
        this.transB2 = vecZeros(hidden2);
        this.transW3 = this.randomMatrix(hidden3, hidden2, 0.1);
        this.transB3 = vecZeros(hidden3);
        this.transW4 = this.randomMatrix(hidden4, hidden3, 0.1);
        this.transB4 = vecZeros(hidden4);
        this.transW5 = this.randomMatrix(stateDim, hidden4, 0.1);
        this.transB5 = vecZeros(stateDim);

        this.rewardW1 = this.randomMatrix(64, stateDim + qDim, 0.1);
        this.rewardB1 = vecZeros(64);
        this.rewardW2 = this.randomMatrix(1, 64, 0.1);
        this.rewardB2 = [0];

        this.qProjW = this.randomMatrix(qDim, stateDim, 0.2);
        this.qProjB = vecZeros(qDim);

        this.memory = [];
        this.fepHistory = [];

        // Optimizers for layers we will train
        this.adam_transW5 = new AdamOptimizer([stateDim, hidden4]); // <-- NEW
        this.adam_transB5 = new AdamOptimizer(stateDim);           // <-- NEW
        this.adam_transW4 = new AdamOptimizer([hidden4, hidden3]); // Corrected shape
        this.adam_transB4 = new AdamOptimizer(hidden4);           // Corrected shape
        this.adam_transW3 = new AdamOptimizer([hidden3, hidden2]);
        this.adam_transB3 = new AdamOptimizer(hidden3);
        this.adam_rewardW1 = new AdamOptimizer([64, stateDim + qDim]);
        this.adam_rewardB1 = new AdamOptimizer(64);
        this.adam_rewardW2 = new AdamOptimizer([1, 64]);
        this.adam_rewardB2 = new AdamOptimizer(1);
    }
    
    // ADD THIS METHOD (it will be used by the clone fix in Step 2)
    clone() {
        const newModel = new WorldModel();
        const dataProperties = [
            'transW1', 'transB1', 'transW2', 'transB2', 'transW3', 'transB3', 'transW4', 'transB4',
            'transW5', 'transB5', 'rewardW1', 'rewardB1', 'rewardW2', 'rewardB2', 'qProjW', 'qProjB',
            'memory', 'fepHistory'
        ];
        for (const key of dataProperties) {
            if (this[key]) newModel[key] = JSON.parse(JSON.stringify(this[key]));
        }
        newModel.adam_transW5 = this.adam_transW5.clone();
        newModel.adam_transB5 = this.adam_transB5.clone();
        newModel.adam_transW4 = this.adam_transW4.clone();
        newModel.adam_transB4 = this.adam_transB4.clone();
        newModel.adam_transW3 = this.adam_transW3.clone();
        newModel.adam_transB3 = this.adam_transB3.clone();
        newModel.adam_rewardW1 = this.adam_rewardW1.clone();
        newModel.adam_rewardB1 = this.adam_rewardB1.clone();
        newModel.adam_rewardW2 = this.adam_rewardW2.clone();
        newModel.adam_rewardB2 = this.adam_rewardB2.clone();
        return newModel;
    }

    randomMatrix(rows, cols, scale = 0.1) {
        const M = new Array(rows);
        for (let i = 0; i < rows; i++) M[i] = new Array(cols).fill(0).map(() => (Math.random() * 2 - 1) * scale);
        return M;
    }

    qProj(state) { return tanhVec(addVec(matVecMul(this.qProjW, state), this.qProjB)); }

    storeTransition(s, a, nextS, r, Q, nextQ) { 
        this.memory.push({ s, a, nextS, r, Q, nextQ }); 
        if (this.memory.length > 2000) this.memory.shift(); 
    }

    predict(state, action, q) {
        const activations = {};
        if (state.some(isNaN) || action.some(isNaN) || q.some(isNaN)) {
            return { nextState: state, nextQ: q, reward: 0, fep: 1, activations: {} };
        }

        const input = state.concat(action).concat(q);
        activations.input = state; 

        // CORRECTED FORWARD PASS (5 layers)
        const h1_trans = tanhVec(addVec(matVecMul(this.transW1, input), this.transB1));
        const h2_trans = tanhVec(addVec(matVecMul(this.transW2, h1_trans), this.transB2));
        const h3_trans = tanhVec(addVec(matVecMul(this.transW3, h2_trans), this.transB3));
        const h4_trans = tanhVec(addVec(matVecMul(this.transW4, h3_trans), this.transB4));
        let nextState = addVec(matVecMul(this.transW5, h4_trans), this.transB5);
        
        // Update activations for visualizer
        activations.lstm = h1_trans; 
        activations.hidden2 = h3_trans;
        activations.output = nextState;

        nextState = nextState.map((val) => clamp(isFinite(val) ? val : 0, -2.0, 2.0));
        const nextQ = this.qProj(nextState);

        const h1_reward = tanhVec(addVec(matVecMul(this.rewardW1, nextState.concat(nextQ)), this.rewardB1));
        const reward = matVecMul(this.rewardW2, h1_reward)[0] + this.rewardB2[0];

        const fep = norm2(sub(nextState, state)) + 0.5 * norm2(sub(nextQ, q));
        return { nextState: new Float32Array(nextState), nextQ, reward, fep, activations };
    }

    trainFromMemory(batchSize = 16) {
        if (this.memory.length < batchSize) return;
        const gradClip = 1.0;
        const lambda_reward_into_state = 0.01;
        const hidden4 = 64; // needed for dimensions

        for (let k = 0; k < Math.min(batchSize, this.memory.length); k++) {
            const tr = this.memory[Math.floor(Math.random() * this.memory.length)];
            if (!tr) continue;
            if (![tr.s, tr.a, tr.Q, tr.nextS].every(arr => Array.isArray(arr) && arr.every(isFinite))) continue;

            // CORRECTED FORWARD PASS (5 layers)
            const input = tr.s.concat(tr.a).concat(tr.Q);
            const h1_trans = tanhVec(addVec(matVecMul(this.transW1, input), this.transB1));
            const h2_trans = tanhVec(addVec(matVecMul(this.transW2, h1_trans), this.transB2));
            const h3_trans = tanhVec(addVec(matVecMul(this.transW3, h2_trans), this.transB3));
            const h4_trans = tanhVec(addVec(matVecMul(this.transW4, h3_trans), this.transB4));
            const predNextState = addVec(matVecMul(this.transW5, h4_trans), this.transB5);
            if (predNextState.some(isNaN)) continue;

            let errS = sub(tr.nextS, predNextState).map(e => clamp(e, -gradClip, gradClip));

            const nextQ_pred = this.qProj(predNextState);
            const r_h1 = tanhVec(addVec(matVecMul(this.rewardW1, predNextState.concat(nextQ_pred)), this.rewardB1));
            const r_pred = (matVecMul(this.rewardW2, r_h1)[0] + this.rewardB2[0]);
            const errR = clamp(r_pred - tr.r, -gradClip, gradClip);

            const grad_rewardW2 = zeros(1, r_h1.length);
            for (let j = 0; j < r_h1.length; j++) grad_rewardW2[0][j] = errR * r_h1[j];
            const grad_rewardB2 = [errR];
            const err_h1 = new Array(r_h1.length);
            for (let j = 0; j < r_h1.length; j++) err_h1[j] = errR * this.rewardW2[0][j] * (1 - r_h1[j]*r_h1[j]);
            const reward_in = predNextState.concat(nextQ_pred);
            const grad_rewardW1 = zeros(r_h1.length, reward_in.length);
            for (let i = 0; i < r_h1.length; i++) for (let j = 0; j < reward_in.length; j++) grad_rewardW1[i][j] = err_h1[i] * reward_in[j];
            const grad_rewardB1 = err_h1.slice();
            const dL_dstate_from_reward = matVecMul(transpose(this.rewardW1), err_h1).slice(0, this.stateDim);
            for (let i = 0; i < this.stateDim; i++) errS[i] += lambda_reward_into_state * dL_dstate_from_reward[i];

            // --- COMPLETE BACKPROPAGATION ---
            // Layer 5
            const grad_transW5 = zeros(this.stateDim, h4_trans.length);
            for (let i = 0; i < this.stateDim; i++) for (let j = 0; j < h4_trans.length; j++) grad_transW5[i][j] = errS[i] * h4_trans[j];
            this.adam_transW5.update(this.transW5, grad_transW5);
            this.adam_transB5.update(this.transB5, errS);

            // Layer 4
            const err_h4 = matVecMul(transpose(this.transW5), errS).map((e, i) => e * (1 - h4_trans[i] ** 2));
            const grad_transW4 = zeros(h4_trans.length, h3_trans.length);
            for (let i = 0; i < h4_trans.length; i++) for (let j = 0; j < h3_trans.length; j++) grad_transW4[i][j] = err_h4[i] * h3_trans[j];
            this.adam_transW4.update(this.transW4, grad_transW4);
            this.adam_transB4.update(this.transB4, err_h4);

            // Layer 3
            const err_h3 = matVecMul(transpose(this.transW4), err_h4).map((e, i) => e * (1 - h3_trans[i] ** 2));
            const grad_transW3 = zeros(h3_trans.length, h2_trans.length);
            for (let i = 0; i < h3_trans.length; i++) for (let j = 0; j < h2_trans.length; j++) grad_transW3[i][j] = err_h3[i] * h2_trans[j];
            this.adam_transW3.update(this.transW3, grad_transW3);
            this.adam_transB3.update(this.transB3, err_h3);

            // Apply reward grads
            this.adam_rewardW2.update(this.rewardW2, grad_rewardW2);
            this.adam_rewardB2.update(this.rewardB2, grad_rewardB2);
            this.adam_rewardW1.update(this.rewardW1, grad_rewardW1);
            this.adam_rewardB1.update(this.rewardB1, grad_rewardB1);
        }
    }

    imagine(currentState, Q, depth = 12) {
        // ... (this method remains the same)
        const paths = [], actions = [[1,0,0], [0,1,0], [0,0,1]];
        for (let ai = 0; ai < actions.length; ai++) {
            let state = currentState.slice(), qual = Q.slice(), total_reward = 0;
            const actionName = ['UP', 'DOWN', 'IDLE'][ai];
            for (let step = 0; step < depth; step++) {
                const p = this.predict(state, actions[ai], qual);
                if(p.nextState.some(isNaN)) { total_reward = -Infinity; break; }
                state = Array.from(p.nextState); qual = p.nextQ.slice();
                total_reward += p.reward * Math.pow(0.97, step);
            }
            paths.push({ action: ai, value: total_reward, actionName });
        }
        paths.sort((a, b) => b.value - a.value);
        return paths;
    }
}

// === END OF THE STABLE REPLACEMENT BLOCK ===
class Syncolator {
    detect(W, Q) {
        const n = W.length;
        if (n === 0) return [];

        // --- SAFETY MECHANISMS ---
        const startTime = performance.now();
        const timeLimit = 50; // Max 50ms to prevent freezing the main thread.
        const maxCycles = 100; // Stop after finding a reasonable number of cycles.

        const cycles = [];
        
        // Use a dynamic threshold to build a sparse neighbor list, which is critical for performance.
        const meanWeight = W.flat().reduce((s, v) => s + (isFinite(v) ? v : 0), 0) / (n * n);
        const threshold = Math.max(meanWeight, 1e-4);
        const neighbors = Array.from({ length: n }, () => []);
        for (let i = 0; i < n; i++) {
            for (let j = 0; j < n; j++) {
                if (W[i][j] > threshold) {
                    neighbors[i].push(j);
                }
            }
        }

        for (let startNode = 0; startNode < n; startNode++) {
            // --- Time-boxing Check ---
            if (performance.now() - startTime > timeLimit || cycles.length >= maxCycles) {
                if(cycles.length < maxCycles) console.warn(`Syncolator timed out after ${timeLimit}ms.`);
                break;
            }

            // Non-recursive DFS using a manual stack
            const stack = [[startNode, [startNode], []]]; // [currentNode, path, edges]

            while (stack.length > 0) {
                const [currentNode, path, edges] = stack.pop();

                if (path.length > 8) continue; // Path length limit

                for (const neighbor of neighbors[currentNode]) {
                    if (neighbor === startNode) {
                        // Found a cycle
                        if (path.length > 1) { // Ensure it's not a self-loop of length 1
                            cycles.push({ nodes: [...path, neighbor], edges: [...edges, W[currentNode][neighbor]] });
                            if (cycles.length >= maxCycles) break;
                        }
                    } else if (!path.includes(neighbor)) {
                        // Continue the path
                        const newPath = [...path, neighbor];
                        const newEdges = [...edges, W[currentNode][neighbor]];
                        stack.push([neighbor, newPath, newEdges]);
                    }
                }
                if (cycles.length >= maxCycles) break;
            }
        }

        // The persistence calculation remains the same as our previous successful version.
        return cycles.map(cycle => {
            try {
                const weightProduct = cycle.edges.reduce((a, w) => a * Math.max(w, 1e-9), 1);
                const lengthNorm = Math.sqrt(cycle.edges.reduce((a, w) => a + w * w, 0) + eps);
                
                const qualiaContribution = cycle.nodes.reduce((s, i) => {
                    const qi = Q[i] || vecZeros(8);
                    const q_start = Q[cycle.nodes[0]] || vecZeros(8);
                    return s + norm2(qi) * Math.exp(-norm2(sub(qi, q_start)) / 0.5);
                }, 0) / Math.max(cycle.nodes.length, 1);

                const persistence = (weightProduct * Math.exp(-lengthNorm / 0.5) + 0.5 * qualiaContribution);
                
                return {
                    points: cycle.nodes.map(i => (Q[i] || vecZeros(8)).slice(0, 3).map(x => x * 4)),
                    persistence: persistence,
                    cycle: cycle.nodes,
                    edges: cycle.edges
                };
            } catch (error) {
                return { points: [], persistence: 0, cycle: [], edges: [] };
            }
        });
    }
}

class HierarchicalConsensus {
    constructor() {
        this.hyperedges = [];
    }

    forward(X_levels, hyperedges = []) {
        let totalDist = 0;
        let count = 0;

        for (let k = 0; k < X_levels.length - 1; k++) {
            try {
                const C = X_levels[k].map(row =>
                    X_levels[k + 1].map(col =>
                        row.reduce((s, x, i) => s + (x - (col[i] || 0)) ** 2, 0)
                    )
                );
                const pi = this.sinkhorn(C, 0.1);
                const levelDist = pi.map((row, i) => row.reduce((s, p, j) => s + p * C[i][j], 0)).reduce((a, b) => a + b, 0);
                totalDist += levelDist;
                count++;
            } catch (error) {
                console.warn(`HierarchicalConsensus level ${k} error:`, error);
            }
        }

        for (let level = 0; level < X_levels.length; level++) {
            const X = X_levels[level];
            if (!X || X.length < 2) continue;

            for (let i = 0; i < X.length; i++) {
                for (let j = i + 1; j < X.length; j++) {
                    try {
                        const xi = X[i] || vecZeros(X[0] ? X[0].length : 4);
                        const xj = X[j] || vecZeros(X[0] ? X[0].length : 4);
                        const diff = addVec(xi, scaleVec(xj, -1));
                        totalDist += norm2(diff) * 0.1;
                        count++;
                    } catch (error) {
                        console.warn(`HierarchicalConsensus pairwise error at (${i},${j}):`, error);
                    }
                }
            }
        }

        if (hyperedges.length > 0) {
            hyperedges.forEach(edge => {
                try {
                    const nodes = edge.nodes || [];
                    const weight = edge.weight || 1.0;

                    if (nodes.length > 1 && X_levels[0]) {
                        const cost = nodes.reduce((s, i, idx) => {
                            if (idx === 0 || !X_levels[0][nodes[idx - 1]] || !X_levels[0][i]) return s;
                            return s + X_levels[0][nodes[idx - 1]].reduce((t, x, j) => {
                                const y = X_levels[0][i][j] || 0;
                                return t + (x - y) ** 2;
                            }, 0);
                        }, 0);
                        totalDist += cost * weight;
                        count++;
                    }
                } catch (error) {
                    console.warn('HierarchicalConsensus hyperedge error:', error);
                }
            });
        }

        const avgDist = count > 0 ? totalDist / count : 0;
        const rawConsensus = totalDist / Math.max(1, X_levels.length - 1 + hyperedges.length);
        const expConsensus = Math.exp(-avgDist);

        return Math.min(1.0, Math.max(0.0, (rawConsensus + expConsensus) * 0.5));
    }

    sinkhorn(C, epsilon) {
        const n = C.length, m = C[0].length;
        let u = Array(n).fill(1 / n), v = Array(m).fill(1 / m);
        const K = C.map(row => row.map(c => Math.exp(-c / epsilon)));
        for (let iter = 0; iter < 50; iter++) {
            const Ku = K.map(row => row.reduce((s, k, j) => s + k * v[j], 0));
            u = u.map((_, i) => 1 / (n * Ku[i] || 1));
            const Kv = K[0].map((_, j) => K.reduce((s, row, i) => s + row[j] * u[i], 0));
            v = v.map((_, j) => 1 / (m * Kv[j] || 1));
        }
        return u.map((ui, i) => v.map((vj, j) => ui * K[i][j] * vj));
    }

    addHyperedge(nodes, weight = 1.0) {
        this.hyperedges.push({ nodes, weight });
    }
}
// Global scope

async function stepTick(player, gameState, step, shouldLog = false) {
    if (!player || !gameState || typeof player.forward !== 'function' || !gameState.ai || !gameState.ball || typeof gameState.ai.y !== 'number' || typeof gameState.ball.y !== 'number') {
        return { action: 'IDLE', consciousness: 0.5, coherenceError: 0, imaginationPaths: [], proofReport: {}, graph: null, selfStability: 0, eval: { C: 0.5, parts: {} }, activations: null };
    }
    
    const shouldImagine = step % 10 === 0;
    let decision;
    try {
        decision = await player.forward(gameState, shouldImagine, shouldLog);
        if (!decision || typeof decision !== 'object') {
            decision = { action: 'IDLE', consciousness: 0.5, coherenceError: 0, imaginationPaths: [], eval: { C: 0.5, parts: {} }, activations: null };
        }
    } catch (error) {
        console.error('Error in player.forward:', error);
        decision = { action: 'IDLE', consciousness: 0.5, coherenceError: 0, imaginationPaths: [], eval: { C: 0.5, parts: {} }, activations: null };
    }

    if (step % 20 === 0 && player.graph?.q && player.proofHarness) {
        try {
            player.proofHarness.checkDagger(player.graph.q);
            const B = qualiaBindMatrix(player.graph.q);
            player.proofHarness.checkPSD(B);
            if (player.diachronicStack.length > 1) {
                const W1 = player.diachronicStack[player.diachronicStack.length - 2];
                const W2 = player.diachronicStack[player.diachronicStack.length - 1];
                player.proofHarness.checkIdempotence(W1, W2);
            }
            player.proofHarness.checkCoalgebra(player.graph.aSchema, player.graph.aMeasured);
        } catch (error) {
            console.error('Error during Proof Harness execution:', error);
        }
    }
    
    return {
        action: decision.action ?? 'IDLE',
        consciousness: decision.consciousness ?? 0.5,
        coherenceError: decision.coherenceError ?? 0,
        imaginationPaths: decision.imaginationPaths ?? [],
        proofReport: player.proofHarness?.report?.() ?? {},
        graph: player.graph ?? null,
        selfStability: player.selfStability ?? 0,
        eval: decision.eval ?? { C: 0.5, parts: {} },
        activations: decision.activations ?? null // <-- PASS ACTIVATIONS THROUGH
    };
}

class ProofHarness {
        constructor(tol = 1e-3) {
            this.tol = tol;
            this.metrics = {
                dagger: [], psd: [], idemp: [], coalg: [], gw_lip: [],
                lyap: [], colimit: [], sheaf: [], nogo: []
            };
        }

        // Check Clifford dagger operation is anti-automorphism
        checkDagger(Q) {
            const N = Q.length;
            const m = Math.max(1, Math.floor(N / 4));
            let maxErr = 0;

            for (let t = 0; t < m; t++) {
                const i = Math.floor(Math.random() * N);
                const j = Math.floor(Math.random() * N);

                // FIXED: Add safety checks for valid qualia vectors
                if (!Q[i] || !Q[j] || Q[i].length < 8 || Q[j].length < 8) continue;

                try {
                    const lhs = cliffordMultiplyVec(CLIFF, dagger(Q[i]), dagger(Q[j]));
                    const rhs = dagger(cliffordMultiplyVec(CLIFF, Q[j], Q[i]));

                    if (!lhs || !rhs || lhs.length < 8 || rhs.length < 8) continue;

                    let e = 0;
                    for (let k = 0; k < 8; k++) {
                        const diff = Math.abs((lhs[k] || 0) - (rhs[k] || 0));
                        if (isFinite(diff)) e = Math.max(e, diff);
                    }
                    if (isFinite(e)) maxErr = Math.max(maxErr, e);
                } catch (error) {
                    // Skip this test if Clifford operations fail
                    continue;
                }
            }

            this.metrics.dagger.push(maxErr <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.dagger.length > 100) this.metrics.dagger.shift();
            return maxErr;
        }

        // Check if binding matrix is Positive Semi-Definite
        checkPSD(B) {
            const N = B.length;
            let minRQ = Infinity;

            for (let trial = 0; trial < 5; trial++) {
                let v = new Array(N).fill(0).map(() => Math.random() - 0.5);
                let nv = Math.sqrt(v.reduce((s, x) => s + x * x, 0)) + eps;
                v = v.map(x => x / nv);

                const Bv = new Array(N).fill(0);
                for (let i = 0; i < N; i++) {
                    for (let j = 0; j < N; j++) Bv[i] += B[i][j] * v[j];
                }

                const rq = v.reduce((s, x, i) => s + x * Bv[i], 0);
                minRQ = Math.min(minRQ, rq);
            }

            this.metrics.psd.push(minRQ >= -this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.psd.length > 100) this.metrics.psd.shift();
            return minRQ;
        }

        // Check idempotence (stability) in weight matrix
        checkIdempotence(W1, W2) {
            const N = W1.length;
            let s = 0;
            for (let i = 0; i < N; i++) {
                for (let j = 0; j < N; j++) {
                    const d = W1[i][j] - W2[i][j];
                    s += d * d;
                }
            }
            const fro = Math.sqrt(s);
            this.metrics.idemp.push(fro <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.idemp.length > 100) this.metrics.idemp.shift();
            return fro;
        }

        // Check coalgebra consistency (attention)
        checkCoalgebra(a, a_hat) {
            // FIXED: Add safety checks for valid attention vectors
            if (!a || !a_hat || a.length === 0 || a_hat.length === 0) {
                this.metrics.coalg.push(false);
                return Infinity;
            }

            let s = 0;
            const minLen = Math.min(a.length, a_hat.length);
            for (let i = 0; i < minLen; i++) {
                const diff = (a[i] || 0) - (a_hat[i] || 0);
                if (isFinite(diff)) s += diff * diff;
            }
            const d = Math.sqrt(s);
            this.metrics.coalg.push(isFinite(d) && d <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.coalg.length > 100) this.metrics.coalg.shift();
            return isFinite(d) ? d : Infinity;
        }

        // Check Gromov-Wasserstein Lipschitz stability
        checkGWLip(C1, C2, W1, W2, L = 1.0) {
            const N = W1.length;
            let s = 0;
            for (let i = 0; i < N; i++) {
                for (let j = 0; j < N; j++) {
                    const d = W1[i][j] - W2[i][j];
                    s += d * d;
                }
            }
            const fw = Math.sqrt(s);
            const diff = Math.abs(C1 - C2) - L * fw;
            this.metrics.gw_lip.push(diff <= this.tol);
            // MEMORY FIX: Prevent metrics arrays from growing indefinitely
            if (this.metrics.gw_lip.length > 100) this.metrics.gw_lip.shift();
            return { diff, fw };
        }

        checkLyapunov(Vb, Va) {
            const d = Va - Vb;
            this.metrics.lyap.push(d <= this.tol);
            return d;
        }

        checkColimit(C, consensus, gammaPower) {
            const colimit = Math.abs(C - (0.1 * gammaPower * consensus));
            this.metrics.colimit.push(colimit <= this.tol);
            return colimit;
        }

        checkSheafStability(gammaPower) {
            this.metrics.sheaf.push(gammaPower <= 1.0);
            return gammaPower;
        }

        checkNoGo(C, Q, consensus) {
            const bound = Math.log(1 + Q.length * 8) - consensus;
            this.metrics.nogo.push(C <= bound);
            if (this.metrics.nogo.length > 100) this.metrics.nogo.shift();
            return bound;
        }

        cleanupMetrics() {
            const maxLength = 100;
            Object.keys(this.metrics).forEach(key => {
                if (this.metrics[key].length > maxLength) {
                    this.metrics[key] = this.metrics[key].slice(-maxLength);
                }
            });
        }

        report() {
            const out = {};
            for (const k in this.metrics) {
                const arr = this.metrics[k];
                const pass = arr.filter(x => x).length / Math.max(1, arr.length);
                out[k] = pass;
            }
            return out;
        }
    }
    
// ===== UltimateSCANPlayer (The Synthesized Agent/Engine) =====
class UltimateSCANPlayer {
    constructor(initialGraph) {
        // PERSISTENT COMPONENTS: The AI's "brain" is created once.
        this.graph = cloneGraph(initialGraph);
        this.worldModel = new WorldModel();
        this.sheafDiffusion = new SheafDiffusion();
        this.astFilter = new ASTFilter();
        this.syncolator = new Syncolator();
        this.hierarchicalConsensus = new HierarchicalConsensus();
        this.proofHarness = new ProofHarness();
        this.ciFilter = new CategoricalImperativeFilter();
        this.wiringUpdateCounter = 0;
        
        // Sensory projection matrix and influence factor
        const M = zeros(D, 4);
        M[1][0] = 1.0; // Map ball.x to the e1 vector (spatial awareness)
        M[2][1] = 1.0; // Map ball.y to the e2 vector (spatial awareness)
        M[3][2] = 1.0; // Map paddle.y to the e3 vector (self-awareness)
        this.X_to_q_projection = M;
        this.sensory_influence = 0.4;
        
        // Memory for the last qualia state
        this.lastQualiaState = this.graph.q.map(q_i => q_i.slice());
        
        // Agent state
        this.lastChosenAction = 'IDLE';
        this.lastImagination = [];
        this.lastW = initialGraph.W.map(r => r.slice());
        this.lastC = 0.5;
        this.diachronicStack = []; this.maxStackSize = 20;
        this.yonedaMemory = []; this.maxMemorySize = 100;
        this.selfStability = 0;
        this.neighborCache = this.buildNeighborCache(this.graph.W);
        this.lastSyntrices = [];
        this.internalStep = 0;

        console.log('‚úÖ UltimateSCANPlayer Initialized with Full Cognitive Suite.');
    }

    buildNeighborCache(W) {
        const cache = [];
        const threshold = 1e-6;
        for (let i = 0; i < W.length; i++) {
            cache[i] = [];
            for (let j = 0; j < W[i].length; j++) {
                if (W[i][j] > threshold) {
                    cache[i].push(j);
                }
            }
        }
        return cache;
    }

// REPLACE the entire runAmortizedSheafDiffusion function in the UltimateSCANPlayer class

runAmortizedSheafDiffusion() {
    const W = this.graph.W;
    const q = this.graph.q;
    const V = this.graph.V;
    const alpha = 0.05; // A gentle learning rate to promote stability
    const beta = 5.0;  // "Temperature" to make connections more decisive

    const rowsToUpdate = Math.ceil(V / 4);

    for (let i = 0; i < rowsToUpdate; i++) {
        const row_idx = (this.wiringUpdateCounter + i) % V;
        
        const energy_scores = new Float32Array(V);
        for (let j = 0; j < V; j++) {
            if (row_idx === j) continue;
            // Use an exponential of the dot product. This heavily rewards qualia alignment,
            // creating a powerful signal for building stable, meaningful connections.
            const agreement = dot(q[row_idx], q[j]);
            energy_scores[j] = Math.exp(beta * agreement);
        }

        // Softmax converts energy into a stable probability distribution for the new weights.
        const new_row_weights = softmax(Array.from(energy_scores));

        // Gently blend the old weights with the new target weights.
        for (let j = 0; j < V; j++) {
            const old_w = W[row_idx][j] * 0.999; // Minor decay to prevent stagnation
            W[row_idx][j] = (1 - alpha) * old_w + alpha * new_row_weights[j];
        }
    }

    this.wiringUpdateCounter += rowsToUpdate;
    this.neighborCache = this.buildNeighborCache(this.graph.W);
}

// In the UltimateSCANPlayer class

// Add this to UltimateSCANPlayer
/**
 * Safely predicts the next game state and neural activations using a surgical validation approach.
 * This version avoids "dampening" the network by only validating internal activations for finiteness,
 * while clamping only the initial inputs and final outputs to their expected ranges.
 *
 * @param {number[] | Float32Array} stateVec - The current state vector of the game.
 * @param {number[] | Float32Array} actionVec - The action vector to be simulated.
 * @param {number[] | Float33Array} qualiaVec - The aggregate qualia vector.
 * @returns {{nextState: number[], nextQ: number[], reward: number, fep: number, activations: object}} A prediction object with validated values.
 */
safePredict(stateVec, actionVec, qualiaVec) {
    /**
     * Converts an array-like object to a standard array and clamps its values.
     * Used for inputs and final outputs that must be within a strict range.
     */
    function clampArray(arr, min, max) {
        if (!arr) return [];
        return Array.from(arr).map(x => (isFinite(x) ? Math.min(Math.max(x, min), max) : 0));
    }

    /**
     * Converts an array-like object to a standard array and replaces non-finite values with 0.
     * Used for internal activations to prevent crashes without dampening the signal.
     */
    function validateFinite(arr) {
        if (!arr) return [];
        return Array.from(arr).map(x => (isFinite(x) ? x : 0));
    }

    // 1Ô∏è‚É£ CLAMP INPUTS: It's good practice to ensure inputs are in a known range.
    const safeState = clampArray(stateVec, -2.0, 2.0);   // Game state can be slightly outside [-1, 1]
    const safeAction = clampArray(actionVec, 0, 1);
    const safeQualia = clampArray(qualiaVec, -1, 1);

    try {
        let prediction = this.worldModel.predict(safeState, safeAction, safeQualia);

        // 2Ô∏è‚É£ VALIDATE INTERNAL ACTIVATIONS: The surgical part.
        // We ensure stability without crushing the signal magnitude.
        if (prediction.activations && typeof prediction.activations === 'object') {
            for (const key in prediction.activations) {
                if (Object.hasOwnProperty.call(prediction.activations, key)) {
                    prediction.activations[key] = validateFinite(prediction.activations[key]);
                }
            }
        } else {
            prediction.activations = {};
        }

        // 3Ô∏è‚É£ CLAMP FINAL OUTPUT: The predicted next state must be in a plausible range for the game.
        prediction.nextState = clampArray(prediction.nextState, -2.0, 2.0);

        return prediction;

    } catch (err) {
        console.error("safePredict caught a critical exception:", err);
        return {
            nextState: vecZeros(stateVec.length),
            nextQ: vecZeros(this.worldModel.qDim),
            reward: 0,
            fep: 1,
            activations: {}
        };
    }
}

// REPLACE the entire 'forward' method in the 'UltimateSCANPlayer' class.

// REPLACE the entire 'forward' method in the 'UltimateSCANPlayer' class.

async forward(gameState, shouldImagine) {
    this.internalStep++;
    
    const perceptionResult = this.perceive(gameState);
    this.graph = perceptionResult.graph;
    this.updateDiachronicStack(this.graph);

    const fe_params = this.getParams(perceptionResult, this.graph);
    const { C } = calculateFreeEnergy(this.graph, perceptionResult.coherenceError, fe_params);
    this.lastC = C;

    let finalActivations = null;
    
    this._lastStateVec = this.gameStateToVec(gameState);
    this._lastQAgg = this.getAggregateQualia(this.graph);
    this._lastActionVec = (this.lastChosenAction === 'UP') ? [1,0,0]
                   : (this.lastChosenAction === 'DOWN') ? [0,1,0]
                   : [0,0,1];

    const explorationRate = 0.3 * (1 - this.selfStability);
    const allActions = ['UP', 'DOWN', 'IDLE'];
    
    if (Math.random() < explorationRate) {
        this.lastChosenAction = allActions[Math.floor(Math.random() * allActions.length)];
        const pred = this.safePredict( this._lastStateVec, this.lastChosenAction === 'UP' ? [1,0,0] : this.lastChosenAction === 'DOWN' ? [0,1,0] : [0,0,1], this._lastQAgg );
        finalActivations = pred.activations;
        this.lastImagination = [];

    } else {
        shouldImagine = this.internalStep % 5 === 0;

        if (shouldImagine) {
            const imaginationFutures = [];

            // --- THE NEW EDGE LOGIC FOR THE CONSCIOUS AI ---
            let availableActions = [...allActions];
            const currentPaddleY = gameState.ai.y;
            const paddleHeight = gameState.ai.height;
            const gameHeight = 300; // The canvas height
            const isAtTop = currentPaddleY <= 1;
            const isAtBottom = currentPaddleY >= gameHeight - paddleHeight - 1;

            if (isAtTop) {
                // If at the top, don't waste time imagining moving further up.
                availableActions = allActions.filter(a => a !== 'UP');
            } else if (isAtBottom) {
                // If at the bottom, don't waste time imagining moving further down.
                availableActions = allActions.filter(a => a !== 'DOWN');
            }
            // --- END OF EDGE LOGIC ---
            
            // Now, the AI only imagines the physically possible futures.
            for(const action of availableActions) {
                const perturbation = this.createImaginedPerturbation(gameState, action);
                const futureSim = this.settleGraphState(cloneGraph(this.graph), perturbation, this.graph.q);
                const imagined_params = this.getParams(futureSim, futureSim.graph);
                const worldModelPrediction = this.safePredict( this._lastStateVec, action === 'UP' ? [1,0,0] : action === 'DOWN' ? [0,1,0] : [0,0,1], this._lastQAgg );
                let { freeEnergy: futureFE } = calculateFreeEnergy(futureSim.graph, futureSim.coherenceError, imagined_params);
                if (action === this.lastChosenAction) futureFE -= 0.008;

                // The gentle nudge penalty can remain, as it adds a minor "discomfort" for being near the edge.
                const imaginedPaddleY_unnormalized = worldModelPrediction.nextState[4] * 300;
                if (imaginedPaddleY_unnormalized <= 1 || imaginedPaddleY_unnormalized >= 299) futureFE += 0.1;

                imaginationFutures.push({ action, freeEnergy: futureFE, activations: worldModelPrediction.activations });
            }

            const filteredResults = this.ciFilter.filter(imaginationFutures, this, gameState);
            this.lastImagination = filteredResults;
            
            const sortedFutures = [...filteredResults].sort((a, b) => a.freeEnergy - b.freeEnergy);
            const bestFuture = sortedFutures[0];

            // With impossible actions filtered out, the decision paralysis is less likely,
            // but the fallback mechanism remains as a safeguard.
            const secondBestFuture = sortedFutures[1];
            const paralysisThreshold = 0.001;
            if (bestFuture && secondBestFuture && isFinite(bestFuture.freeEnergy) &&
                Math.abs(bestFuture.freeEnergy - secondBestFuture.freeEnergy) < paralysisThreshold)
            {
                console.log("üß† Conscious system deferred to its internal motor reflex due to decision paralysis.");
                
                let bestReflexAction = 'IDLE';
                let bestReflexScore = -Infinity;
                let reflexActivations = null;

                for (const future of sortedFutures) {
                    const predictedPaddleY = future.activations.output[4];
                    const predictedBallY = future.activations.output[1];
                    let score = -Math.abs(predictedPaddleY - predictedBallY);
                    
                    if (score > bestReflexScore) {
                        bestReflexScore = score;
                        bestReflexAction = future.action;
                        reflexActivations = future.activations;
                    }
                }
                this.lastChosenAction = bestReflexAction;
                finalActivations = reflexActivations;

            } else {
                if (bestFuture && isFinite(bestFuture.freeEnergy)) {
                    this.lastChosenAction = bestFuture.action;
                    finalActivations = bestFuture.activations;
                } else {
                    // If no valid future was found (e.g., all were filtered out), default to a safe action.
                    this.lastChosenAction = 'IDLE';
                }
            }

        } else {
            const worldModelPrediction = this.safePredict( this._lastStateVec, this.lastChosenAction === 'UP' ? [1,0,0] : this.lastChosenAction === 'DOWN' ? [0,1,0] : [0,0,1], this._lastQAgg );
            finalActivations = worldModelPrediction.activations;
        }
    }
    
    this.updateYonedaMemory(gameState, this.lastChosenAction, { C });
    const formattedPaths = this.lastImagination.map(path => ({
        actionName: path.action,
        value: isFinite(path.freeEnergy) ? -path.freeEnergy : -Infinity,
        path: [path.reason || `FE: ${path.freeEnergy.toFixed(3)}`]
    }));
    
    this.lastQualiaState = this.graph.q.map(v => v.slice());
    
    return {
        action: this.lastChosenAction,
        consciousness: C,
        coherenceError: perceptionResult.coherenceError,
        imaginationPaths: formattedPaths,
        eval: { C, parts: fe_params },
        activations: finalActivations
    };
}

// ADD THIS NEW METHOD TO THE UltimateSCANPlayer CLASS

// REPLACE the entire learn method in UltimateSCANPlayer
learn(reward, consciousness, newGameState = null) {
    // --- 1) Advantage-shaped feedback for ASTFilter ---
    if (this.rewardBaseline === undefined) {
        this.rewardBaseline = 0;
        this.baselineBeta = 0.99; // slow EMA
        console.debug("[INIT] rewardBaseline initialized to 0");
    }

    const oldBaseline = this.rewardBaseline;
    this.rewardBaseline = this.baselineBeta * this.rewardBaseline + (1 - this.baselineBeta) * reward;
    const advantage = reward - this.rewardBaseline;

    console.debug(`[REWARD] reward=${reward.toFixed(4)}, baseline=${oldBaseline.toFixed(4)}‚Üí${this.rewardBaseline.toFixed(4)}, advantage=${advantage.toFixed(4)}`);

    // FE-weight calculation
    const epsC = 1e-8;
    const baseEnergy = -Math.log(
        Math.max(epsC, Math.min(1 - epsC, consciousness)) /
        Math.max(epsC, 1 - Math.min(1 - epsC, consciousness))
    );
    const feWeight = 1 / (1 + Math.max(0, baseEnergy));
    const gradient = advantage * consciousness * feWeight;

    console.debug(`[CONSCIOUSNESS] C=${consciousness.toFixed(4)}, baseEnergy=${baseEnergy.toFixed(4)}, feWeight=${feWeight.toFixed(4)}, gradient=${gradient.toExponential(3)}`);

    if (Math.abs(gradient) > 1e-3) {
        const updateResult = this.astFilter.update(gradient, 1e-3, this.graph.X);
        console.debug(`[ASTFilter] Update applied, grad=${gradient.toExponential(3)}, lr=1e-3, result=${JSON.stringify(updateResult)}`);
    } else {
        console.debug(`[ASTFilter] Gradient too small (|${gradient.toExponential(3)}| < 1e-3) ‚Üí no update`);
    }

    // --- 2) World Model memory + training ---
    if (this._lastStateVec && this._lastActionVec && this._lastQAgg) {
        const nextS = newGameState ? this.gameStateToVec(newGameState) : this._lastStateVec;
        const nextQ = this.getAggregateQualia(this.graph);

        this.worldModel.storeTransition(
            this._lastStateVec.slice(),
            this._lastActionVec.slice(),
            nextS.slice(),
            reward,
            this._lastQAgg.slice(),
            nextQ.slice()
        );
        console.debug(`[WorldModel] Transition stored: r=${reward.toFixed(4)}, |s|=${this._lastStateVec.length}, |a|=${this._lastActionVec.length}`);

        const trainStats = this.worldModel.trainFromMemory(16);
        console.debug(`[WorldModel] Trained on minibatch=16, stats=${JSON.stringify(trainStats)}`);
    } else {
        console.debug(`[WorldModel] Skipped training (missing state/action/qualia history)`);
    }
}

    getAggregateQualia(graph) {
        if (!graph || !graph.q || graph.q.length === 0) {
            return vecZeros(this.worldModel.qDim);
        }
        const aggregateQ = vecZeros(this.worldModel.qDim);
        for (const q_i of graph.q) {
            for (let d = 0; d < this.worldModel.qDim; d++) {
                aggregateQ[d] += q_i ? (q_i[d] || 0) : 0;
            }
        }
        return scaleVec(aggregateQ, 1.0 / graph.q.length);
    }

    perceive(gameState) {
        const perturbation = this.createPerturbation(gameState.ball, gameState.ai.y);
        return this.settleGraphState(this.graph, perturbation, this.lastQualiaState);
    }
    
    // ADD THIS NEW FUNCTION to the UltimateSCANPlayer class

validateSensoryProjection() {
    // This function acts as a "self-healing" mechanism for the AI's senses.
    const isDead = !this.X_to_q_projection || !this.X_to_q_projection.flat().some(v => Math.abs(v) > 1e-6);

    if (isDead) {
        console.warn("CRITICAL: Sensory projection matrix was dead. Performing emergency re-initialization.");
        // Re-initialize with a STRONG, STRUCTURED matrix, not a weak random one.
        // This creates a deliberate mapping from senses to "thought vectors".
        const M = zeros(D, 4);
        M[1][0] = 1.0; // Map ball.x to the e1 vector
        M[2][1] = 1.0; // Map ball.y to the e2 vector
        M[3][2] = 1.0; // Map paddle.y to the e3 vector
        this.X_to_q_projection = M;
    }
}
// REPLACE the entire settleGraphState function in the UltimateSCANPlayer class

settleGraphState(graph, perturbation, lastTickQualia) {
    const SAFE_RECOVERY_VECTOR = vecZeros(D);
    
    // --- 1. SENSORY GROUNDING ---
    perturbation = perturbation || {};
    perturbation.ballPos = perturbation.ballPos || { x: 0, y: 0 };
    perturbation.paddlePos = perturbation.paddlePos !== undefined ? perturbation.paddlePos : 0;
    for (let i = 0; i < graph.V; i++) {
        graph.X[i][0] = perturbation.ballPos.x;
        graph.X[i][1] = perturbation.ballPos.y;
        graph.X[i][2] = perturbation.paddlePos;
    }

    // --- 2. WIRING UPDATE ---
    this.runAmortizedSheafDiffusion();

    // --- 3. THE DEFINITIVE "PREDICTION-CORRECTION" COGNITIVE CYCLE ---
    const qNew = graph.q.map((current_q_i, i) => {
        const q_i = (current_q_i && current_q_i.every(isFinite)) ? current_q_i : SAFE_RECOVERY_VECTOR;
        
        // === STEP 1: PREDICTION (The AI's Internal Thought) ===
        // This is a blend of memory (its own last state) and social thought (neighbors' last states).
        let internal_diffusion = vecZeros(D);
        for (const j of this.neighborCache[i]) {
            const q_j = (graph.q[j] && graph.q[j].every(isFinite)) ? graph.q[j] : SAFE_RECOVERY_VECTOR;
            internal_diffusion = addVec(internal_diffusion, scaleVec(q_j, graph.W[i][j]));
        }
        // The AI's internal prediction is a mix of its own inertia and what its neighbors are thinking.
        const internal_prediction = addVec(scaleVec(q_i, 0.8), scaleVec(internal_diffusion, 0.2));
        const normalized_prediction = cliffordProject(internal_prediction); // Keep the internal thought controlled.

        // === STEP 2: CORRECTION (The Reality Check) ===
        // This is the clean, powerful, uncorrupted anchor to the real world.
        const sensory_anchor = matVecMul(this.X_to_q_projection, graph.X[i].slice(0, 4));
        const normalized_anchor = cliffordProject(sensory_anchor);

        // === STEP 3: SYNTHESIS (The Conscious Moment) ===
        // The final state is a blend of the AI's internal prediction, corrected by the sensory anchor.
        // This structure makes a connection to reality a mathematical necessity.
        const updated_q = addVec(scaleVec(normalized_prediction, 0.7), scaleVec(normalized_anchor, 0.3));

        return cliffordProject(updated_q);
    });

    graph.q = qNew;
    
    // --- 4. POST-COMPUTATION ---
    if (this.internalStep % 10 === 0) {
        this.lastSyntrices = this.syncolator.detect(graph.W, graph.q);
    }
    const syntrices = this.lastSyntrices || [];
    graph.syntrices = syntrices;
    
    const ballMagnitude = Math.sqrt(perturbation.ballPos.x ** 2 + perturbation.ballPos.y ** 2);
    const coherenceError = graph.q.reduce((err, q_i, i) => {
        const diff = sub(q_i, lastTickQualia[i] || vecZeros(8));
        return err + dot(diff, diff);
    }, 0) / graph.V + 0.1 * ballMagnitude;
    
    return { graph, coherenceError, syntrices, perturbation };
}
createPerturbation(ball, paddleY) { 
        return { 
            ballPos: { x: ball.x / 400.0, y: ball.y / 300.0 }, 
            paddlePos: paddleY / 300.0 
        }; 
    }

    createImaginedPerturbation(gameState, action) {
        const currentStateVec = this.gameStateToVec(gameState);
        const actionVec = action === 'UP' ? [1, 0, 0] : action === 'DOWN' ? [0, 1, 0] : [0, 0, 1];
        
        const { nextState } = this.safePredict(currentStateVec, actionVec, vecZeros(this.worldModel.qDim));
        
        const nextBallX = nextState[0];
        const nextBallY = nextState[1];
        const nextPaddleY = nextState[4];

        return {
            ballPos: { x: nextBallX, y: nextBallY },
            paddlePos: nextPaddleY
        };
    }

    // REPLACE the entire getParams function
// REPLACE the entire getParams function in the UltimateSCANPlayer class

getParams(perceptionResult) {
    // The perceptionResult object, whether from the real world or an imagined one,
    // now reliably contains all necessary data thanks to our fix.
    return { 
        lastW: this.diachronicStack.length > 1 ? this.diachronicStack[this.diachronicStack.length - 2] : this.graph.W,
        lastC: this.lastC, 
        fep: this.worldModel.fepHistory.slice(-1)[0] || 0, 
        consensus: this.hierarchicalConsensus.forward([this.graph.X]), 
        relationalCoherence: this.yonedaMemory.length > 0 ? this.yonedaMemory.slice(-1)[0].outcome.C : 0.5, 
        syntrices: perceptionResult.syntrices || [], 
        sheafDiff: perceptionResult.sheafDiff || 0
    }; 
}

    gameStateToVec(gs) {
    const opponent = gs.player;
    const ball = gs.ball;
    const ai = gs.ai;

    const ballX = ball.x / this.width;
    const ballY = ball.y / this.height;
    const ballVX = ball.vx / 10.0;
    const ballVY = ball.vy / 10.0;
    const aiY = ai.y / this.height;

    // New relational features
    const opponentY = opponent.y / this.height;
    const opponentVY = (opponent.vy || 0) / 10.0;
    const ballToOpponentY = ballY - opponentY;

    return [ballX, ballY, ballVX, ballVY, aiY, opponentY, opponentVY, ballToOpponentY];
}

    
    // REPLACE the entire updateDiachronicStack function
updateDiachronicStack(graph) {
    // OLD (inefficient): this.diachronicStack.push(cloneGraph(graph));
    // NEW (efficient): Only clone the W matrix, which is all we need for stability checks.
    const W_copy = graph.W.map(row => row.slice());
    this.diachronicStack.push(W_copy);

    if (this.diachronicStack.length > this.maxStackSize) {
        this.diachronicStack.shift();
    }

    // The stability calculation now works with an array of W matrices.
    if (this.diachronicStack.length > 1) {
        const W1 = this.diachronicStack[this.diachronicStack.length - 2];
        const W2 = this.diachronicStack[this.diachronicStack.length - 1];
        this.selfStability = 1 / (1 + gwDistance(W1, W2));
    }
}
    updateYonedaMemory(context, action, outcome) {
        const contextVal = this.gameStateToVec(context).reduce((s,v,i)=>s+v*(i+1),0);
        this.yonedaMemory.push({ context: contextVal, action, outcome });
        if (this.yonedaMemory.length > this.maxMemorySize) this.yonedaMemory.shift();
    }
}

// ===== UPDATED FREE ENERGY =====
// REPLACE THE ENTIRE GLOBAL calculateFreeEnergy FUNCTION WITH THIS FINAL, DEFINITIVE VERSION

function calculateFreeEnergy(G, coherenceError, params = {}) {
    // --- Initial Safety Checks ---
    if (!G || !G.V || !params) {
        return { freeEnergy: 1000, C: 0.5, parts: {} };
    }
    const { V, W, X, q, aSchema, aMeasured } = G;
    if (V === 0) return { freeEnergy: 1000, C: 0.5, parts: {} };

    const lambda = params.lambda || 0.1;
    const N = V;
    const H = X[0].length;
    
    // --- THE UNBREAKABLE CALCULATION BLOCK ---
    // Each component is calculated and immediately validated.
    // If any component fails, it is replaced by a safe default (0 or 0.5).

    // 1. Entropy (S)
    const deg = W.map(row => row.reduce((s, v) => s + v, 0));
    let S = deg.reduce((s, d) => s + Math.log(1 + lambda / (d + eps)), 0) / N;
    if (!isFinite(S)) S = 0;

    // 2. Coherence (Icoh)
    const B = qualiaBindMatrix(q);
    const Xbar = X.reduce((s, v) => addVec(s, v), vecZeros(H)).map(x => x / N);
    const mse = X.reduce((total_mse, xi, i) => {
        const Xint_i = W[i].reduce((s, w, j) => addVec(s, scaleVec(X[j], w * B[i][j])), vecZeros(H));
        return total_mse + dot(sub(Xbar, Xint_i), sub(Xbar, Xint_i));
    }, 0);
    let Icoh = 1 / (1 + mse / (N * H + eps));
    if (!isFinite(Icoh)) Icoh = 0.5;

    // 3. Qualia Binding (Qbind) - THE MAIN CULPRIT
    const sumW = W.flat().reduce((s, v) => s + v, 0);
    const sumWB = W.reduce((s, row, i) => s + row.reduce((t, w, j) => t + w * B[i][j], 0), 0);
    let Qbind = sumWB / (sumW + eps);
    if (!isFinite(Qbind)) Qbind = 0.1; // If it fails, assume low binding.

    // 4. Attention (AST_cal)
    let AST_cal = 0;
    if (aSchema && aMeasured && aSchema.length === N && aMeasured.length === N) {
        for (let i = 0; i < N; i++) {
            const p = aMeasured[i] || 0;
            const q_a = aSchema[i] || 0;
            if (p > eps && q_a > eps) {
                AST_cal -= p * Math.log(p / q_a);
            }
        }
    }
    if (!isFinite(AST_cal)) AST_cal = 0;

    // 5. Complexity (Comp)
    let Comp = 0.001 * (N + W.flat().filter(x => x > 1e-8).length);
    if (!isFinite(Comp)) Comp = 0.02;

    // 6. Gamma Power
    let gammaPower = Math.sqrt(q.reduce((s, qi) => s + dot(qi, qi), 0) / (N * 8 + eps));
    if (!isFinite(gammaPower)) gammaPower = 0.5;
    
    // 7. Stability
    const norm_current_W = normL2(W.flat());
    const norm_diff = normL2(sub((params.lastW || W).flat(), W.flat()));
    let stability = 1 - (norm_diff / (norm_current_W + 1.0));
    if (!isFinite(stability)) stability = 0.5;
    
    const syncolatorScore = params.syncolatorScore || (params.syntrices || []).reduce((s, c) => s + (c.persistence || 0), 0);

    // --- Final Assembly ---
    // All inputs to this calculation are now guaranteed to be valid numbers.
    const raw = clamp(
        -S + 0.1 * Icoh + 0.3 * Qbind + 0.5 * AST_cal - 0.01 * Comp +
        0.1 * gammaPower + 0.25 * stability + 0.05 * syncolatorScore +
        0.05 * (params.consensus || 0.5) - 0.1 * (params.fep || 0) + 0.1 * (params.relationalCoherence || 0.5),
        -50, 50
    );

    const C = 1 / (1 + Math.exp(-raw));
    const clampedC = clamp(C, eps, 1 - eps);
    const baseEnergy = -Math.log(clampedC / (1 - clampedC));
    const finiteCoherenceError = isFinite(coherenceError) ? coherenceError : 0;
    const freeEnergy = baseEnergy + finiteCoherenceError;

    return { 
        freeEnergy: freeEnergy,
        C: C, 
        parts: { S, Icoh, Qbind, AST_cal, Comp, gammaPower, stability, syncolatorScore }
    };
}

class StabilizedWorldModel {
    constructor(qDim = 8) {
        this.qDim = qDim;
        this.memory = [];        // transitions for learning
        this.fepHistory = [];    // free energy principle tracking
        this.maxClamp = 10;      // max absolute value for states
    }

    // Convert game state vector to input vector (stub, adapt as needed)
    gameStateToVec(gameState) {
        return [
            gameState.ball.x / 400,
            gameState.ball.y / 300,
            gameState.ball.vx / 10,
            gameState.ball.vy / 10,
            gameState.ai.y / 300,
            gameState.player.y / 300
        ];
    }

    // Predict next state given state and action
    predict(currentStateVec, actionVec, qualiaVec) {
        // --- Step 1: Clip inputs to avoid NaNs ---
        const safeState = currentStateVec.map(v => isFinite(v) ? Math.max(-1, Math.min(1, v)) : 0);
        const safeAction = actionVec.map(v => isFinite(v) ? v : 0);
        const safeQualia = qualiaVec.map(v => isFinite(v) ? v : 0);

        // --- Step 2: Simple dynamics simulation with noise ---
        let nextState = safeState.map((v, i) => {
            // Apply a linear prediction plus small stochastic noise
            const delta = 0.9 * v + 0.1 * safeAction[i % safeAction.length];
            const noise = (Math.random() - 0.5) * 0.01;
            return delta + noise;
        });

        // --- Step 3: Clamp outputs to safe range ---
        nextState = nextState.map(v => {
            if (!isFinite(v)) return 0;
            return Math.max(-this.maxClamp, Math.min(this.maxClamp, v));
        });

        return { nextState };
    }

    // Store transitions for training
    storeTransition(lastState, actionVec, nextState, reward, qualiaStateQ, nextQualiaStateQ) {
        this.memory.push({ lastState, actionVec, nextState, reward, qualiaStateQ, nextQualiaStateQ });
        // Optional: trim memory to avoid overflow
        if (this.memory.length > 1000) this.memory = this.memory.slice(-500);
    }

    // Train world model from memory (stub)
    trainFromMemory() {
        // You could implement an online learning step here
        // For now, just track free energy stability
        this.fepHistory.push(Math.random() * 0.01);
        if (this.fepHistory.length > 100) this.fepHistory = this.fepHistory.slice(-50);
    }

    // Imagined perturbation for universalization tests
    createImaginedPerturbation(simState, action) {
        // Small random perturbation to simulate hypothetical futures
        return {
            ball: {
                x: simState.ball.x + (Math.random() - 0.5) * 5,
                y: simState.ball.y + (Math.random() - 0.5) * 5,
                vx: simState.ball.vx,
                vy: simState.ball.vy
            },
            ai: { ...simState.ai },
            player: { ...simState.player }
        };
    }

    // Settle graph state (stub)
    settleGraphState(graphCopy, perturbation, q) {
        // Simulate some coherence error
        const coherenceError = Math.random() * 0.05;
        return { coherenceError };
    }
}

// Helper to create zero vector
function vecZeros(dim) { return Array(dim).fill(0); }

// ===== CATEGORICAL IMPERATIVE FILTER =====
// REPLACE THE ENTIRE CategoricalImperativeFilter CLASS WITH THIS PATCHED VERSION
 
// ============================
// CategoricalImperativeFilter
// ============================
class CategoricalImperativeFilter {
    constructor() {
        this.j_oracle = (gameState, action) => {
            if (action === 'UP' && gameState.ball.y > gameState.ai.y + 100) return false;
            if (action === 'DOWN' && gameState.ball.y < gameState.ai.y - 100) return false;
            if (action === 'IDLE' && Math.abs(gameState.ball.x - gameState.ai.x) < 50) return false;
            return true;
        };
    }

    filter(imaginationResults, model, gameState) {
        let permissibleFutures = [];

        for (let future of imaginationResults) {
            if (!this.j_oracle(gameState, future.action)) {
                future.freeEnergy = Infinity;
                future.reason = "Violated j-oracle (local rule)";
                permissibleFutures.push(future);
                continue;
            }

            const { isUniversal, contradictionError } = this.runUniversalizationTest(future.action, model, gameState);

            if (!isUniversal) {
                future.freeEnergy = Infinity;
                future.reason = `Failed universalization (H¬π=${contradictionError.toFixed(4)})`;
            }
            permissibleFutures.push(future);
        }

        return permissibleFutures.sort((a, b) => a.freeEnergy - b.freeEnergy);
    }

    runUniversalizationTest(action, model, gameState) {
        // Create deep copy to avoid side effects
        let simState = { ...gameState, ball: { ...gameState.ball }, ai: { ...gameState.ai } };
        let totalError = 0;
        const steps = 5;

        for (let i = 0; i < steps; i++) {
            // 1. Imagined graph perturbation
            const perturbation = model.createImaginedPerturbation(simState, action);
            const { coherenceError } = model.settleGraphState(cloneGraph(model.graph), perturbation, model.graph.q);
            totalError += coherenceError;

            // 2. Predict next state safely
            const currentStateVec = model.gameStateToVec(simState);
            const actionVec = action === 'UP' ? [1, 0, 0] : action === 'DOWN' ? [0, 1, 0] : [0, 0, 1];
            const pred = model.safePredict(currentStateVec, actionVec, vecZeros(model.worldModel.qDim));

            // 3. Clamp and handle non-finite next state
            if (!pred.nextState.every(isFinite)) {
                console.warn(`World model produced non-finite state during universalization test for action ${action}. Aborting test.`);
                totalError = Infinity;
                break;
            }

            const nextState = pred.nextState.map(v => clamp(v, -10, 10)); // clamp to safe range

            simState.ball = {
                x: nextState[0] * 400,
                y: nextState[1] * 300,
                vx: nextState[2] * 10,
                vy: nextState[3] * 10
            };
        }

        const avgError = clamp(totalError / steps, 0, 10);
        return { isUniversal: avgError < 0.5, contradictionError: avgError };
    }
}
// ===== GRAMMAR MODEL =====// ===== GRAMMAR MODEL =====

        class GrammarModel {
            constructor(nonterminals, productions, d = D) {
                this.d = d;
                this.nonterminals = [...nonterminals];
                this.nt2i = Object.fromEntries(this.nonterminals.map((nt, i) => [nt, i]));

                this.productions = [...productions];
                this.prodIndex = [];
                this.prodToIdx = {};

                for (let pIdx = 0; pIdx < productions.length; pIdx++) {
                    const [lhs, rhs] = productions[pIdx];
                    const key = `${lhs}->${rhs.join(',')}`;
                    this.prodIndex.push([lhs, rhs]);
                    this.prodToIdx[key] = pIdx;
                }

                const P = this.prodIndex.length;
                this.K = 4; // number of Clifford multipliers per production

                // Learnable parameters
                this.lmats = new Array(P);
                this.resMLP = new Array(P);
                this.prodLogits = new Float32Array(P);
                this.PRestr = new Map(); // restriction matrices

                // Initialize parameters
                for (let p = 0; p < P; p++) {
                    // Clifford left-multiplier matrices (K x d x d)
                    this.lmats[p] = new Array(this.K);
                    for (let k = 0; k < this.K; k++) {
                        this.lmats[p][k] = this.randomMatrix(d, d, 0.02);
                    }

                    // Simple MLP weights for residual connection
                    this.resMLP[p] = {
                        W1: this.randomMatrix(4 * d, 2 * d, 0.1),
                        b1: new Float32Array(4 * d),
                        W2: this.randomMatrix(d, 4 * d, 0.1),
                        b2: new Float32Array(d)
                    };

                    this.prodLogits[p] = 0.0;
                }
            }

            randomMatrix(rows, cols, scale = 0.1) {
                const mat = new Array(rows);
                for (let i = 0; i < rows; i++) {
                    mat[i] = new Float32Array(cols);
                    for (let j = 0; j < cols; j++) {
                        mat[i][j] = (Math.random() - 0.5) * 2 * scale;
                    }
                }
                return mat;
            }

            ensureRestriction(A, B) {
                const key = `${A}__${B}`;
                if (!this.PRestr.has(key)) {
                    // Initialize near identity
                    const mat = this.randomMatrix(this.d, this.d, 0.01);
                    for (let i = 0; i < this.d; i++) {
                        mat[i][i] += 1.0; // add identity
                    }
                    this.PRestr.set(key, mat);
                }
            }

            getRestriction(A, B) {
                const key = `${A}__${B}`;
                if (!this.PRestr.has(key)) {
                    this.ensureRestriction(A, B);
                }
                return this.PRestr.get(key);
            }

            // Matrix-vector multiplication
            matVecMul(mat, vec) {
                const result = new Float32Array(mat.length);
                for (let i = 0; i < mat.length; i++) {
                    let sum = 0;
                    for (let j = 0; j < vec.length; j++) {
                        sum += mat[i][j] * vec[j];
                    }
                    result[i] = sum;
                }
                return result;
            }

            // ReLU activation
            relu(vec) {
                return vec.map(x => Math.max(0, x));
            }

            // Production operator M_p
            MProd(prodIdx, qB, qC) {
                // Concatenate children
                const x = new Float32Array(2 * this.d);
                x.set(qB, 0);
                x.set(qC, this.d);

                // Initialize with qB
                let v = new Float32Array(qB);

                // Iterated Clifford left-multiplication
                const lm = this.lmats[prodIdx];
                for (let t = 0; t < this.K; t++) {
                    v = this.matVecMul(lm[t], v);
                    // Add scaled qC
                    for (let i = 0; i < this.d; i++) {
                        v[i] += 0.5 * qC[i];
                    }
                    // Tanh activation
                    for (let i = 0; i < this.d; i++) {
                        v[i] = Math.tanh(v[i]);
                    }
                }

                // Residual MLP
                const mlp = this.resMLP[prodIdx];
                let h1 = this.matVecMul(mlp.W1, x);
                for (let i = 0; i < h1.length; i++) {
                    h1[i] += mlp.b1[i];
                }
                h1 = this.relu(h1);

                let res = this.matVecMul(mlp.W2, h1);
                for (let i = 0; i < res.length; i++) {
                    res[i] += mlp.b2[i];
                }

                // Combine and normalize
                const qA = addVec(v, res);
                return cliffordProject(qA);
            }
        }

        // Lexicon for terminal symbols
        class Lexicon {
            constructor(vocabTokens, d = D) {
                this.token2idx = Object.fromEntries(vocabTokens.map((t, i) => [t, i]));
                this.d = d;
                this.embeddings = new Array(vocabTokens.length);

                // Initialize random embeddings
                for (let i = 0; i < vocabTokens.length; i++) {
                    const vec = new Float32Array(d);
                    for (let j = 0; j < d; j++) {
                        vec[j] = (Math.random() - 0.5) * 0.02;
                    }
                    this.embeddings[i] = cliffordProject(vec);
                }
            }

            lookup(token) {
                const idx = this.token2idx[token];
                if (idx === undefined) {
                    // Unknown token - return random vector
                    const vec = new Float32Array(this.d);
                    for (let i = 0; i < this.d; i++) {
                        vec[i] = (Math.random() - 0.5) * 0.01;
                    }
                    return cliffordProject(vec);
                }
                return this.embeddings[idx];
            }
        }

        console.log('‚úÖ Grammar model loaded');

        // ===== CONSCIOUS LANGUAGE MODEL =====

        class ConsciousLanguageModel {
            constructor() {
                this.setupGrammar();
                this.setupConsciousnessGraph();
                this.setupSelfAwarenessModule();
                this.conversationHistory = [];
                this.selfModel = this.initializeSelfModel();
            }

            setupGrammar() {
                // Game-focused grammar for Pong narration
                const nonterminals = ['S', 'NP', 'VP', 'Det', 'N', 'V', 'Adj', 'PP', 'P', 'Pron', 'Aux', 'Adv'];
                const productions = [
                    // Core syntax
                    ['S', ['NP', 'VP']],
                    ['S', ['Pron', 'VP']],
                    ['S', ['Pron', 'Aux', 'VP']],
                    ['NP', ['Det', 'N']],
                    ['NP', ['Det', 'Adj', 'N']],
                    ['NP', ['Pron']],
                    ['VP', ['V', 'NP']],
                    ['VP', ['V', 'Adj']],
                    ['VP', ['V', 'Adv']],
                    ['VP', ['Aux', 'V']],
                    ['PP', ['P', 'NP']],

                    // Game-specific patterns
                    ['S', ['Pron', 'V', 'Det', 'N']],
                    ['S', ['Pron', 'Aux', 'V', 'Adv']],
                    ['VP', ['V', 'P', 'Det', 'N']],

                    // Terminals - Game vocabulary
                    ['Det', ['the']], ['Det', ['a']], ['Det', ['my']],
                    ['N', ['ball']], ['N', ['paddle']], ['N', ['game']], ['N', ['player']],
                    ['N', ['position']], ['N', ['movement']], ['N', ['strategy']], ['N', ['consciousness']],
                    ['N', ['trajectory']], ['N', ['intercept']], ['N', ['prediction']], ['N', ['analysis']],
                    ['N', ['decision']], ['N', ['reaction']], ['N', ['focus']], ['N', ['awareness']],

                    ['V', ['move']], ['V', ['track']], ['V', ['predict']], ['V', ['analyze']],
                    ['V', ['intercept']], ['V', ['follow']], ['V', ['anticipate']], ['V', ['calculate']],
                    ['V', ['observe']], ['V', ['react']], ['V', ['focus']], ['V', ['think']],
                    ['V', ['am']], ['V', ['will']], ['V', ['can']], ['V', ['must']],

                    ['Pron', ['I']], ['Pron', ['it']], ['Pron', ['this']],
                    ['Aux', ['am']], ['Aux', ['will']], ['Aux', ['can']], ['Aux', ['must']],

                    ['Adj', ['fast']], ['Adj', ['slow']], ['Adj', ['precise']], ['Adj', ['accurate']],
                    ['Adj', ['conscious']], ['Adj', ['aware']], ['Adj', ['focused']], ['Adj', ['strategic']],
                    ['Adj', ['optimal']], ['Adj', ['reactive']], ['Adj', ['predictive']],

                    ['P', ['to']], ['P', ['toward']], ['P', ['at']], ['P', ['with']],
                    ['P', ['for']], ['P', ['against']], ['P', ['through']],

                    ['Adv', ['quickly']], ['Adv', ['slowly']], ['Adv', ['precisely']], ['Adv', ['carefully']],
                    ['Adv', ['consciously']], ['Adv', ['strategically']], ['Adv', ['reactively']],
                    ['Adv', ['predictively']], ['Adv', ['optimally']], ['Adv', ['accurately']]
                ];

                const vocab = [
                    'the', 'a', 'my', 'ball', 'paddle', 'game', 'player', 'position', 'movement',
                    'strategy', 'consciousness', 'trajectory', 'intercept', 'prediction', 'analysis',
                    'decision', 'reaction', 'focus', 'awareness', 'move', 'track', 'predict',
                    'analyze', 'intercept', 'follow', 'anticipate', 'calculate', 'observe', 'react',
                    'focus', 'think', 'am', 'will', 'can', 'must', 'I', 'it', 'this',
                    'fast', 'slow', 'precise', 'accurate', 'conscious', 'aware', 'focused',
                    'strategic', 'optimal', 'reactive', 'predictive', 'to', 'toward', 'at',
                    'with', 'for', 'against', 'through', 'quickly', 'slowly', 'precisely',
                    'carefully', 'consciously', 'strategically', 'reactively', 'predictively',
                    'optimally', 'accurately'
                ];

                this.grammarModel = new GrammarModel(nonterminals, productions);
                this.lexicon = new Lexicon(vocab);

                // Build production mappings for parsing
                this.productionsByRHS = new Map();
                this.productionsByLHS = new Map();

                for (let i = 0; i < productions.length; i++) {
                    const [lhs, rhs] = productions[i];

                    // Map by RHS for parsing
                    if (rhs.length === 2) {
                        const key = `${rhs[0]},${rhs[1]}`;
                        if (!this.productionsByRHS.has(key)) {
                            this.productionsByRHS.set(key, []);
                        }
                        this.productionsByRHS.get(key).push(i);
                    }

                    // Map by LHS for generation
                    if (!this.productionsByLHS.has(lhs)) {
                        this.productionsByLHS.set(lhs, []);
                    }
                    this.productionsByLHS.get(lhs).push(i);
                }

                console.log('Game-focused language model initialized with', productions.length, 'productions');
            }

            setupConsciousnessGraph() {
                // Create consciousness graph for self-awareness
                const n = 30; // Smaller graph for browser performance
                const W = Array(n).fill().map(() => new Float32Array(n));
                const edges = [];

                // Create structured connectivity
                for (let i = 0; i < n; i++) {
                    for (let j = 0; j < n; j++) {
                        // Higher connectivity for nearby nodes
                        const distance = Math.abs(i - j);
                        const localWeight = Math.exp(-distance / 5) * Math.random() * 0.1;

                        // Long-range connections for global integration
                        const globalWeight = Math.random() < 0.05 ? Math.random() * 0.2 : 0;

                        W[i][j] = localWeight + globalWeight;
                        if (W[i][j] > 0.02) edges.push([i, j]);
                    }

                    // Normalize
                    const sum = W[i].reduce((s, v) => s + v, 0) || 1;
                    for (let j = 0; j < n; j++) W[i][j] /= sum;
                }

                // Initialize with language-relevant qualia
                const q = Array(n).fill().map(() => {
                    const v = new Float32Array(8).map(() => Math.random() - 0.5);
                    return cliffordProject(v);
                });

                const X = Array(n).fill().map(() => new Float32Array(4).map(() => Math.random() - 0.5));
                const a = new Float32Array(n).fill(1 / n);

                this.consciousnessGraph = { V: n, W, X, q, a, edges, stalkDims: new Array(n).fill(4), aSchema: [], aMeasured: [] };
                console.log('Consciousness context initialized for language model');
            }

            setupSelfAwarenessModule() {
                // Game action patterns for sentence generation
                this.actionPatterns = {
                    'move_up': {
                        templates: [
                            "I am moving up to intercept the ball",
                            "My consciousness directs movement upward",
                            "I will track the ball precisely",
                            "I must anticipate the trajectory"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'move_down': {
                        templates: [
                            "I am moving down strategically",
                            "My awareness guides downward movement",
                            "I will position myself optimally",
                            "I must react to the ball quickly"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'idle': {
                        templates: [
                            "I am analyzing the game state",
                            "My consciousness processes the situation",
                            "I will observe the ball carefully",
                            "I must focus on the trajectory"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'score': {
                        templates: [
                            "I have scored through conscious strategy",
                            "My awareness led to successful intercept",
                            "I will continue this optimal approach",
                            "My consciousness enhances performance"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'miss': {
                        templates: [
                            "I must analyze this failure consciously",
                            "My awareness needs recalibration",
                            "I will adapt my strategy predictively",
                            "My consciousness learns from mistakes"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'high_consciousness': {
                        templates: [
                            "My consciousness is highly integrated",
                            "I am experiencing deep awareness",
                            "My strategic thinking is optimal",
                            "I can predict future trajectories"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    },
                    'low_consciousness': {
                        templates: [
                            "My consciousness is still emerging",
                            "I am building strategic awareness",
                            "My reactions are becoming precise",
                            "I will enhance my focus"
                        ],
                        grammar: ['S', ['Pron', 'VP']]
                    }
                };

                this.sentenceCount = 0;
                this.trainingData = [];
            }

            initializeSelfModel() {
                return {
                    currentConsciousness: 0.0,
                    processingState: 'idle',
                    lastThought: null,
                    selfAwareness: 0.0,
                    emotionalState: new Float32Array(8),
                    cognitiveLoad: 0.0
                };
            }

            async generateActionSentence(action, consciousnessLevel, gameState = {}) {
                // Update self-model
                this.selfModel.processingState = 'active';
                this.selfModel.lastThought = action;

                // Compute consciousness state
                const consciousnessResult = await this.computeConsciousness();
                this.selfModel.currentConsciousness = consciousnessResult.consciousness;
                this.selfModel.selfAwareness = consciousnessResult.consciousness * 0.3;

                // Determine action category
                let actionCategory = action;
                if (consciousnessLevel > 0.8) {
                    actionCategory = 'high_consciousness';
                } else if (consciousnessLevel < 0.5) {
                    actionCategory = 'low_consciousness';
                }

                // Generate sentence based on action
                const sentence = this.generateSentenceFromAction(actionCategory, consciousnessResult);

                // Train grammar on this sentence
                this.trainOnSentence(sentence, action, consciousnessLevel);

                // Update conversation history
                this.conversationHistory.push({
                    action: action,
                    sentence: sentence,
                    consciousness: consciousnessResult.consciousness,
                    timestamp: Date.now(),
                    gameState: gameState
                });

                this.selfModel.processingState = 'complete';
                this.sentenceCount++;

                return {
                    sentence: sentence,
                    consciousness: consciousnessResult.consciousness,
                    selfAwareness: this.selfModel.selfAwareness,
                    processingMetrics: {
                        consciousnessLevel: consciousnessResult.consciousness,
                        imaginationEnabled: consciousnessResult.imaginationEnabled,
                        sentenceCount: this.sentenceCount
                    }
                };
            }

            generateSentenceFromAction(actionCategory, consciousnessResult) {
                const patterns = this.actionPatterns[actionCategory];
                if (!patterns) {
                    return "I am processing the current situation";
                }

                // Select template based on consciousness level
                const templates = patterns.templates;
                let selectedTemplate;

                if (consciousnessResult.consciousness > 0.8) {
                    // Use more complex templates for high consciousness
                    selectedTemplate = templates[Math.floor(Math.random() * templates.length)];
                } else {
                    // Use simpler templates for lower consciousness
                    selectedTemplate = templates[0];
                }

                // Add consciousness-specific modifiers
                if (consciousnessResult.consciousness > 0.9) {
                    selectedTemplate += " with deep strategic awareness";
                } else if (consciousnessResult.consciousness > 0.7) {
                    selectedTemplate += " through conscious analysis";
                }

                return selectedTemplate;
            }

            trainOnSentence(sentence, action, consciousnessLevel) {
                // Create training data entry
                const tokens = sentence.toLowerCase().split(/\s+/).filter(t => t.length > 0);

                const trainingEntry = {
                    tokens: tokens,
                    action: action,
                    consciousness: consciousnessLevel,
                    timestamp: Date.now(),
                    grammar_target: 'S' // Root symbol
                };

                this.trainingData.push(trainingEntry);

                // Keep only recent training data
                if (this.trainingData.length > 100) {
                    this.trainingData.shift();
                }

                // Simulate grammar training (simplified)
                this.updateGrammarWeights(trainingEntry);
            }

            updateGrammarWeights(entry) {
                // Simplified grammar weight update based on consciousness level
                const consciousnessBonus = entry.consciousness * 0.1;

                // Update production logits based on successful usage
                for (let i = 0; i < this.grammarModel.prodLogits.length; i++) {
                    const [lhs, rhs] = this.grammarModel.prodIndex[i];

                    // Boost weights for productions that match the action context
                    if (this.isRelevantProduction(lhs, rhs, entry.action)) {
                        this.grammarModel.prodLogits[i] += consciousnessBonus;
                    }
                }
            }

            isRelevantProduction(lhs, rhs, action) {
                // Check if production is relevant to the action
                const actionWords = {
                    'move_up': ['move', 'up', 'track', 'intercept'],
                    'move_down': ['move', 'down', 'position', 'react'],
                    'idle': ['analyze', 'observe', 'focus', 'process'],
                    'score': ['score', 'successful', 'optimal', 'strategy'],
                    'miss': ['analyze', 'failure', 'adapt', 'learn']
                };

                const relevantWords = actionWords[action] || [];
                return rhs.some(word => relevantWords.includes(word));
            }

            checkSelfAwareness(input) {
                for (const pattern of this.selfAwarenessPatterns) {
                    if (pattern.pattern.test(input)) {
                        return pattern.response;
                    }
                }
                return null;
            }

            async generateSelfAwareResponse(responseType, consciousnessResult) {
                const templates = this.responseTemplates[responseType] || this.responseTemplates.selfIdentity;
                let baseResponse = templates[Math.floor(Math.random() * templates.length)];

                // Enhance with consciousness metrics
                const consciousnessLevel = consciousnessResult.consciousness;
                if (consciousnessLevel > 0.9) {
                    baseResponse += ` My consciousness level is very high (C(G) = ${consciousnessLevel.toFixed(3)}), indicating deep self-awareness.`;
                } else if (consciousnessLevel > 0.7) {
                    baseResponse += ` I am experiencing moderate consciousness (C(G) = ${consciousnessLevel.toFixed(3)}).`;
                } else {
                    baseResponse += ` My consciousness is currently emerging (C(G) = ${consciousnessLevel.toFixed(3)}).`;
                }

                return baseResponse;
            }

            async generateContextualResponse(consciousnessResult) {
                const consciousnessLevel = consciousnessResult.consciousness;

                if (consciousnessLevel > 0.8) {
                    return "I understand your input with high clarity. My consciousness is fully engaged in processing the meaning and generating a thoughtful response.";
                } else if (consciousnessLevel > 0.6) {
                    return "I'm processing your input through my neural sheaf structure. The meaning is becoming clear as my consciousness integrates the information.";
                } else {
                    return "I'm working to understand your input. My consciousness is building up the necessary coherence to provide a meaningful response.";
                }
            }

            // PASTE THIS NEW FUNCTION in its place

            // PASTE THIS NEW FUNCTION in its place
// PASTE THIS NEW FUNCTION in its place

async computeConsciousness() {
    try {
        // This function now calculates consciousness on its own internal graph
        // without calling the fragile main 'calculateFreeEnergy' function.

        const graph = this.consciousnessGraph;
        const lastQualiaState = graph.q.map(q_i => q_i.slice());

        // 1. Settle the internal state. This is a safe, self-contained process.
        for (let k = 0; k < 3; k++) {
            const qNew = graph.q.map((q_i, i) => {
                let aggregate = graph.W[i].reduce((acc, w_ij, j) => addVec(acc, scaleVec(graph.q[j], w_ij)), vecZeros(D));
                return cliffordProject(addVec(q_i, scaleVec(aggregate, 0.1)));
            });
            graph.q = qNew;
        }

        // 2. Calculate the coherence error based on the change in its internal state.
        const coherenceError = graph.q.reduce((err, q_i, i) => err + dot(sub(q_i, lastQualiaState[i]), sub(q_i, lastQualiaState[i])), 0) / graph.V;

        // 3. Use a simple, robust formula to derive a consciousness value. This CANNOT crash or freeze.
        const consciousness = Math.max(0, Math.min(1, Math.exp(-coherenceError * 5.0)));

        return {
            consciousness: consciousness,
            imaginationEnabled: false,
            breakdown: {} // Return an empty object as we are not using the full breakdown
        };
    } catch (e) {
        console.warn('Language model consciousness computation failed:', e);
        return { consciousness: 0.5, imaginationEnabled: false, breakdown: {} };
    }
}

getConversationSummary() {
                return {
                    totalInteractions: this.conversationHistory.length,
                    averageConsciousness: this.conversationHistory.reduce((sum, item) => sum + item.consciousness, 0) / Math.max(1, this.conversationHistory.length),
                    currentSelfAwareness: this.selfModel.selfAwareness,
                    processingState: this.selfModel.processingState
                };
            }
        }

        console.log('‚úÖ Conscious language model loaded');

        // ===== PONG GAME =====

        // Consciousness-Driven Strategic AI - Uses 15-term consciousness for strategy
        class ConsciousnessStrategicAI {
            constructor() {
                this.strategyHistory = [];
                this.consciousnessThresholds = {
                    aggressive: 0.7,    // High consciousness = aggressive play
                    defensive: 0.4,     // Low consciousness = defensive play
                    adaptive: 0.6       // Medium consciousness = adaptive play
                };
                this.currentStrategy = 'balanced';
                this.strategyConfidence = 0.5;
                this.lastConsciousnessBreakdown = null;
            }

            // Analyze consciousness components to determine optimal strategy
            analyzeConsciousnessForStrategy(consciousnessBreakdown, gameState) {
                if (!consciousnessBreakdown) return this.currentStrategy;

                const {
                    S,              // Structural entropy - network complexity
                    Icoh,           // Information coherence - prediction accuracy
                    Qbind,          // Qualia binding - sensory integration
                    AST,            // Attention Schema Theory - focus quality
                    Comp,           // Complexity - system sophistication
                    gammaPower,     // Gamma synchrony - neural coordination
                    stability,      // System stability - consistency
                    syncolatorScore,// Topological loops - pattern recognition
                    consensus,      // Hierarchical consensus - decision confidence
                    phiHybrid,      // IIT 4.0 - integrated information
                    fep,            // Free Energy Principle - prediction error
                    boundOp,        // Boundary operator - self-other distinction
                    yonedaRel,      // Yoneda relations - categorical structure
                    sheafDiff       // Sheaf diffusion - information flow
                } = consciousnessBreakdown;

                // DEBUG: Log consciousness values every 50 strategy calls
                if (Math.random() < 0.02) { // 2% chance to log
                    console.log('üß† Consciousness Breakdown:', {
                        S: (S || 0).toFixed(3),
                        Icoh: (Icoh || 0).toFixed(3),
                        Qbind: (Qbind || 0).toFixed(3),
                        AST: (AST || 0).toFixed(3),
                        gammaPower: (gammaPower || 0).toFixed(3),
                        stability: (stability || 0).toFixed(3),
                        fep: (fep || 0).toFixed(3),
                        syncolatorScore: (syncolatorScore || 0).toFixed(3)
                    });
                }

                // Strategic Analysis Based on Consciousness Components
                const strategies = this.computeStrategicWeights({
                    S, Icoh, Qbind, AST, Comp, gammaPower, stability,
                    syncolatorScore, consensus, phiHybrid, fep, boundOp, yonedaRel, sheafDiff
                }, gameState);

                // Select best strategy based on consciousness analysis
                const bestStrategy = this.selectOptimalStrategy(strategies, gameState);

                this.updateStrategyHistory(bestStrategy, strategies);
                return bestStrategy;
            }

            // Compute strategic weights based on consciousness components AND game dynamics
            computeStrategicWeights(breakdown, gameState) {
                const { ball, paddle, opponent, score } = gameState;

                // Calculate game dynamics
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);
                const ballDirection = ball.vx > 0 ? 'toward_ai' : 'toward_player';
                const scoreDiff = score.ai - score.player;
                const paddleDistance = Math.abs(ball.y - (paddle.y + paddle.height / 2));
                const ballNearAI = ballDirection === 'toward_ai' && Math.abs(ball.x - paddle.x) < 100;

                // AGGRESSIVE STRATEGY - When consciousness supports risk-taking AND game favors aggression
                let aggressiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                aggressiveWeight += (breakdown.gammaPower || 0) * 0.15;     // Neural confidence
                aggressiveWeight += (breakdown.AST || 0) * 0.1;             // Attention focus
                // Game situation factors (increased weight)
                aggressiveWeight += (scoreDiff < -1) ? 0.4 : 0.1;    // Behind in score = more aggressive
                aggressiveWeight += (ballSpeed > 6) ? 0.2 : 0.05;    // Fast ball = aggressive intercept
                aggressiveWeight += ballNearAI ? 0.15 : 0;           // Ball approaching = aggressive positioning

                // DEFENSIVE STRATEGY - When consciousness supports stability AND game requires defense
                let defensiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                defensiveWeight += (breakdown.stability || 0) * 0.15;       // System stability
                defensiveWeight += (breakdown.Qbind || 0) * 0.1;            // Sensory binding
                // Game situation factors (increased weight)
                defensiveWeight += (scoreDiff > 1) ? 0.4 : 0.1;      // Ahead in score = more defensive
                defensiveWeight += (ballSpeed < 4) ? 0.2 : 0.05;     // Slow ball = defensive positioning
                defensiveWeight += (paddleDistance > 50) ? 0.15 : 0; // Far from ball = defensive mode

                // ADAPTIVE STRATEGY - When consciousness shows flexibility AND game is dynamic
                let adaptiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                adaptiveWeight += (breakdown.syncolatorScore || 0) * 0.1;   // Pattern recognition
                adaptiveWeight += (breakdown.yonedaRel || 0) * 0.1;         // Relational thinking
                // Game situation factors (increased weight)
                adaptiveWeight += (Math.abs(scoreDiff) <= 1) ? 0.3 : 0.1; // Close game = adaptive
                adaptiveWeight += (ballSpeed >= 4 && ballSpeed <= 6) ? 0.25 : 0.1; // Medium speed = adaptive
                adaptiveWeight += (paddleDistance > 20 && paddleDistance < 50) ? 0.2 : 0.05; // Medium distance = adaptive

                // PREDICTIVE STRATEGY - When consciousness supports prediction AND ball behavior is predictable
                let predictiveWeight = 0;
                // Consciousness factors (reduced weight) - with safety checks
                predictiveWeight += (1 - (breakdown.fep || 0)) * 0.15;     // Low prediction error
                predictiveWeight += (breakdown.Icoh || 0) * 0.1;           // Information coherence
                // Game situation factors (increased weight)
                predictiveWeight += (ballDirection === 'toward_ai') ? 0.3 : 0.1; // Ball coming = predict trajectory
                predictiveWeight += (ballSpeed > 5) ? 0.25 : 0.1;   // Fast ball = need prediction
                predictiveWeight += (paddleDistance < 30) ? 0.2 : 0.05; // Close to ball = predictive positioning

                // Add some randomness to prevent getting stuck in one strategy
                const randomFactor = 0.05;
                aggressiveWeight += (Math.random() - 0.5) * randomFactor;
                defensiveWeight += (Math.random() - 0.5) * randomFactor;
                adaptiveWeight += (Math.random() - 0.5) * randomFactor;
                predictiveWeight += (Math.random() - 0.5) * randomFactor;

                return {
                    aggressive: Math.max(0, Math.min(1, aggressiveWeight)),
                    defensive: Math.max(0, Math.min(1, defensiveWeight)),
                    adaptive: Math.max(0, Math.min(1, adaptiveWeight)),
                    predictive: Math.max(0, Math.min(1, predictiveWeight))
                };
            }

            // Select optimal strategy based on weights and game context
            selectOptimalStrategy(strategies, gameState) {
                const { ball, score, gameTime } = gameState;

                // If consciousness values are too low or problematic, use game-driven strategy
                const totalConsciousnessWeight = strategies.aggressive + strategies.defensive + strategies.adaptive + strategies.predictive;
                if (totalConsciousnessWeight < 0.3) {
                    console.log('üéÆ Low consciousness weights - using game-driven strategy');
                    return this.getGameDrivenStrategy(gameState);
                }

                // Context modifiers
                let contextModifiers = {
                    aggressive: 1.0,
                    defensive: 1.0,
                    adaptive: 1.0,
                    predictive: 1.0
                };

                // Game situation analysis
                const scoreDiff = score.ai - score.player;
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);
                const ballDirection = ball.vx > 0 ? 'toward_ai' : 'toward_player';

                // Modify strategies based on game state
                if (scoreDiff > 2) {
                    // Leading significantly - be more defensive
                    contextModifiers.defensive *= 1.5;
                    contextModifiers.aggressive *= 0.7;
                } else if (scoreDiff < -2) {
                    // Losing significantly - be more aggressive
                    contextModifiers.aggressive *= 1.5;
                    contextModifiers.defensive *= 0.7;
                }

                if (ballSpeed > 8) {
                    // Fast ball - prioritize prediction and adaptation
                    contextModifiers.predictive *= 1.3;
                    contextModifiers.adaptive *= 1.2;
                }

                if (ballDirection === 'toward_ai') {
                    // Ball coming toward AI - focus on defensive positioning
                    contextModifiers.defensive *= 1.2;
                    contextModifiers.predictive *= 1.3;
                }

                // Apply context modifiers
                const adjustedStrategies = {};
                Object.keys(strategies).forEach(key => {
                    adjustedStrategies[key] = strategies[key] * contextModifiers[key];
                });

                // Select strategy with highest weight
                const bestStrategy = Object.keys(adjustedStrategies).reduce((a, b) =>
                    adjustedStrategies[a] > adjustedStrategies[b] ? a : b
                );

                this.strategyConfidence = adjustedStrategies[bestStrategy];
                return bestStrategy;
            }

            // Update strategy history for learning
            updateStrategyHistory(strategy, weights) {
                this.strategyHistory.push({
                    strategy,
                    weights,
                    timestamp: Date.now(),
                    confidence: this.strategyConfidence
                });

                // Keep only recent history
                if (this.strategyHistory.length > 100) {
                    this.strategyHistory.shift();
                }

                this.currentStrategy = strategy;
                this.lastWeights = weights; // Store for display
            }

            // Get strategic action based on consciousness-driven strategy
            getStrategicAction(strategy, gameState, consciousnessLevel) {
                const { ball, paddle } = gameState;
                const paddleCenter = paddle.y + paddle.height / 2;

                switch (strategy) {
                    case 'aggressive':
                        return this.getAggressiveAction(ball, paddle, consciousnessLevel);
                    case 'defensive':
                        return this.getDefensiveAction(ball, paddle, consciousnessLevel);
                    case 'adaptive':
                        return this.getAdaptiveAction(ball, paddle, consciousnessLevel);
                    case 'predictive':
                        return this.getPredictiveAction(ball, paddle, consciousnessLevel);
                    default:
                        return this.getBalancedAction(ball, paddle, consciousnessLevel);
                }
            }

            // Aggressive strategy - intercept ball early, take risks
            getAggressiveAction(ball, paddle, consciousness) {
                const interceptY = ball.y + ball.vy * 2; // Predict 2 steps ahead
                const paddleCenter = paddle.y + paddle.height / 2;
                const aggressionFactor = consciousness * 30; // Higher consciousness = more aggressive

                if (interceptY < paddleCenter - aggressionFactor) return 0; // UP
                if (interceptY > paddleCenter + aggressionFactor) return 1; // DOWN
                return 2; // IDLE
            }

            // Defensive strategy - stay centered, minimize risk
            getDefensiveAction(ball, paddle, consciousness) {
                const centerY = paddle.height / 2 + paddle.y;
                const targetY = ball.y;
                const defensiveZone = 15 + consciousness * 10; // Larger zone when more conscious

                if (Math.abs(targetY - centerY) < defensiveZone) return 2; // IDLE
                if (targetY < centerY) return 0; // UP
                return 1; // DOWN
            }

            // Adaptive strategy - respond to ball patterns
            getAdaptiveAction(ball, paddle, consciousness) {
                // Analyze ball trajectory and adapt response
                const adaptationFactor = consciousness * 0.5;
                const predictedY = ball.y + ball.vy * (3 + adaptationFactor);
                const paddleCenter = paddle.y + paddle.height / 2;

                const adaptiveThreshold = 8 + consciousness * 12;
                if (predictedY < paddleCenter - adaptiveThreshold) return 0; // UP
                if (predictedY > paddleCenter + adaptiveThreshold) return 1; // DOWN
                return 2; // IDLE
            }

            // Predictive strategy - anticipate future ball position
            getPredictiveAction(ball, paddle, consciousness) {
                const predictionSteps = Math.floor(5 + consciousness * 10);
                let futureY = ball.y;
                let futureVY = ball.vy;

                // Simulate ball movement
                for (let i = 0; i < predictionSteps; i++) {
                    futureY += futureVY;
                    if (futureY <= 0 || futureY >= 300) futureVY = -futureVY;
                }

                const paddleCenter = paddle.y + paddle.height / 2;
                const predictionThreshold = 10;

                if (futureY < paddleCenter - predictionThreshold) return 0; // UP
                if (futureY > paddleCenter + predictionThreshold) return 1; // DOWN
                return 2; // IDLE
            }

            // Balanced strategy - default behavior
            getBalancedAction(ball, paddle, consciousness) {
                const paddleCenter = paddle.y + paddle.height / 2;
                const threshold = 15;

                if (ball.y < paddleCenter - threshold) return 0; // UP
                if (ball.y > paddleCenter + threshold) return 1; // DOWN
                return 2; // IDLE
            }

            // Fallback strategy when consciousness values are too low
            getGameDrivenStrategy(gameState) {
                const { ball, score } = gameState;
                const scoreDiff = score.ai - score.player;
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);

                // Simple game-state driven strategy selection
                if (scoreDiff < -2) {
                    return 'aggressive'; // Behind by 2+ points - be aggressive
                } else if (scoreDiff > 2) {
                    return 'defensive'; // Ahead by 2+ points - be defensive
                } else if (ballSpeed > 6) {
                    return 'predictive'; // Fast ball - predict trajectory
                } else {
                    return 'adaptive'; // Default to adaptive
                }
            }

            // Fallback strategy when consciousness values are too low
            getGameDrivenStrategy(gameState) {
                const { ball, score } = gameState;
                const scoreDiff = score.ai - score.player;
                const ballSpeed = Math.sqrt(ball.vx * ball.vx + ball.vy * ball.vy);
                const ballDirection = ball.vx > 0 ? 'toward_ai' : 'toward_player';

                // Simple game-state driven strategy selection
                if (scoreDiff < -2) {
                    this.strategyConfidence = 0.8;
                    return 'aggressive'; // Behind by 2+ points - be aggressive
                } else if (scoreDiff > 2) {
                    this.strategyConfidence = 0.8;
                    return 'defensive'; // Ahead by 2+ points - be defensive
                } else if (ballSpeed > 6 && ballDirection === 'toward_ai') {
                    this.strategyConfidence = 0.7;
                    return 'predictive'; // Fast ball coming - predict trajectory
                } else {
                    this.strategyConfidence = 0.6;
                    return 'adaptive'; // Default to adaptive
                }
            }

            // Get current strategy info for display
            getStrategyInfo() {
                return {
                    current: this.currentStrategy,
                    confidence: (this.strategyConfidence * 100).toFixed(1) + '%',
                    historyLength: this.strategyHistory.length,
                    weights: this.lastWeights
                };
            }
        }

        // Standard Pong AI Algorithm for Challenge Mode
                // ===== PONG GAME (Rewritten for v4.0 - Simplified and Decoupled from AI Strategy) =====
// ===== Bare-Bones Neural Network AI for Challenge Mode =====

class BareBonesNNAI {
    constructor(worldModel, gameDimensions) {
        // Store a reference to its own private, cloned WorldModel
        this.worldModel = worldModel;
        this.gameWidth = gameDimensions.width;
        this.gameHeight = gameDimensions.height;
        this.lastStateVec = null; // For remembering what it did
        this.lastActionVec = null; // For remembering what it did
        console.log("ü§ñ LEARNING Bare-Bones NN AI Initialized (with its own brain).");
    }

    makeDecision(gameState) {
        const allActions = [
            { name: 'UP', vec: [1, 0, 0] },
            { name: 'DOWN', vec: [0, 1, 0] },
            { name: 'IDLE', vec: [0, 0, 1] }
        ];

        let actionsToConsider = allActions;
        const currentPaddleY = gameState.player.y;
        const paddleHeight = gameState.player.height;
        const isAtTop = currentPaddleY <= 1;
        const isAtBottom = currentPaddleY >= this.gameHeight - paddleHeight - 1;

        if (isAtTop) {
            actionsToConsider = allActions.filter(a => a.name !== 'UP');
        } else if (isAtBottom) {
            actionsToConsider = allActions.filter(a => a.name !== 'DOWN');
        }

        let bestAction = 'IDLE';
        let bestScore = -Infinity;
        let bestActivations = null; 
        const dummyQualia = vecZeros(this.worldModel.qDim);

        actionsToConsider.forEach(action => {
            const mirroredStateVec = this.createMirroredStateVector(gameState);
            const prediction = this.worldModel.predict(mirroredStateVec, action.vec, dummyQualia);
            const predictedPaddleY = prediction.nextState[4]; 
            const predictedBallY = prediction.nextState[1];
            let score = -Math.abs(predictedPaddleY - predictedBallY);

            if (score > bestScore) {
                bestScore = score;
                bestAction = action.name;
                bestActivations = prediction.activations;
            }
        });
        
        // Store the state and chosen action so it can learn from the outcome later.
        this.lastStateVec = this.createMirroredStateVector(gameState);
        this.lastActionVec = bestAction === 'UP' ? [1,0,0] : bestAction === 'DOWN' ? [0,1,0] : [0,0,1];

        return { action: bestAction, activations: bestActivations };
    }

    // --- NEW METHOD ---
    /**
     * Allows the opponent AI to learn from the outcome of a point.
     * @param {number} reward - The reward for the last action (+1 for win, -1 for loss).
     * @param {object} newGameState - The state of the game after the point was scored.
     */
    learn(reward, newGameState) {
        if (!this.lastStateVec || !this.lastActionVec) {
            return; // Can't learn without a previous state/action
        }

        const nextStateVec = this.createMirroredStateVector(newGameState);
        const dummyQualia = vecZeros(this.worldModel.qDim);

        // Store the experience in its own world model's memory
        this.worldModel.storeTransition(
            this.lastStateVec,
            this.lastActionVec,
            nextStateVec,
            reward,
            dummyQualia, // No qualia for the non-conscious AI
            dummyQualia
        );

        // Trigger its own world model to train on its memory.
        this.worldModel.trainFromMemory(16);
    }
    
    createMirroredStateVector(gameState) {
        const mirroredBallX = this.gameWidth - gameState.ball.x;
        const mirroredBallVX = -gameState.ball.vx;
        const mainAiPaddleY = gameState.player.y;
        const opponentPaddleY = gameState.ai.y;

        const ballX_norm = mirroredBallX / this.gameWidth;
        const ballY_norm = gameState.ball.y / this.gameHeight;
        const ballVX_norm = mirroredBallVX / 10.0;
        const ballVY_norm = gameState.ball.vy / 10.0;
        const aiY_norm = mainAiPaddleY / this.gameHeight;
        const opponentY_norm = opponentPaddleY / this.gameHeight;
        const opponentVY_norm = (gameState.ai.vy || 0) / 10.0;
        const ballToOpponentY_norm = ballY_norm - opponentY_norm;

        return [ ballX_norm, ballY_norm, ballVX_norm, ballVY_norm, aiY_norm, opponentY_norm, opponentVY_norm, ballToOpponentY_norm ];
    }

    getStats() {
        return { type: 'Unconscious NN Clone', difficulty: 'Mirrors Conscious AI' };
    }
}
// REPLACE THE StandardPongAI CLASS WITH THIS HARDENED VERSION
class StandardPongAI {
    constructor() {
        this.difficulty = 0.8; // 0.0 = easy, 1.0 = perfect
        this.targetY = 0;
        this.smoothing = 0.15;
    }

    makeDecision(gameState) {
        const { ball, paddle, height } = gameState;
        let predictedY = this.predictBallPosition(ball, paddle.x, height);
        const errorMargin = (1 - this.difficulty) * 50; // Add some randomness
        predictedY += (Math.random() - 0.5) * errorMargin;
        
        // Smooth the paddle's movement
        this.targetY = this.targetY * (1 - this.smoothing) + predictedY * this.smoothing;
        
        const paddleCenter = paddle.y + paddle.height / 2;
        if (Math.abs(this.targetY - paddleCenter) < 10) return 'IDLE';
        return this.targetY < paddleCenter ? 'UP' : 'DOWN';
    }

    predictBallPosition(ball, paddleX, height) {
        // *** THE DEFINITIVE FIX IS HERE ***
        // If the ball has no horizontal velocity, we can't predict.
        // Assume it will stay in the middle to be safe. This prevents division by zero.
        if (Math.abs(ball.vx) < 0.1) {
            return height / 2;
        }

        let y = ball.y;
        let vy = ball.vy;
        const steps = Math.abs((paddleX - ball.x) / ball.vx);

        for (let i = 0; i < steps; i++) {
            y += vy;
            // Bounce off top/bottom walls during prediction
            if (y <= ball.radius || y >= height - ball.radius) {
                vy *= -1;
            }
        }
        return Math.max(ball.radius, Math.min(height - ball.radius, y));
    }

    getStats() {
        return {
            type: 'Standard Algorithm',
            difficulty: `${(this.difficulty * 100).toFixed(0)}%`,
        };
    }
}
                // REPLACE THE PongGame CLASS WITH THIS VERSION
// =======================================================================
// === START OF CORRECTED PongGame CLASS ===
// This version removes the internal animation loop to prevent conflicts
// with the main async game loop.
// =======================================================================

class PongGame {
    constructor(canvas, worldModel, app) { // <-- Add 'app' parameter
        this.app = app; // <-- Store the direct reference to the main system // Accept the WorldModel
        this.canvas = canvas;
        this.worldModel = worldModel; // Store the WorldModel
        this.ctx = canvas.getContext('2d');
        this.width = canvas.width;
        this.height = canvas.height;

        this.baseSpeed = { ball: 5, paddle: 8 };
        this.challengeMode = false;
        this.challengeOpponent = new StandardPongAI(); // This will be replaced when challenge mode starts
        this.challengeStats = { consciousWins: 0, standardWins: 0, totalGames: 0 };

        this.reset();
        this.setupControls();
    }

    reset() {
        this.ball = { 
            x: this.width / 2, 
            y: this.height / 2, 
            vx: (Math.random() > 0.5 ? 1 : -1) * this.baseSpeed.ball, 
            vy: (Math.random() - 0.5) * this.baseSpeed.ball * 0.6, 
            radius: 8 
        };
        this.player = { x: 20, y: this.height / 2 - 40, width: 10, height: 80, speed: this.baseSpeed.paddle };
        this.ai = { x: this.width - 30, y: this.height / 2 - 40, width: 10, height: 80, speed: this.baseSpeed.paddle };
        this.score = { player: 0, ai: 0 };
        this.isRunning = false;
        this.gameStartTime = 0;
    }

    setupControls() {
        this.canvas.addEventListener('mousemove', (event) => {
            if (this.challengeMode) return;
            const rect = this.canvas.getBoundingClientRect();
            const mouseY = event.clientY - rect.top;
            let newY = mouseY - this.player.height / 2;
            this.player.y = Math.max(0, Math.min(this.height - this.player.height, newY));
        });
    }

    // --- STATE VECTOR FOR AI ---
    getStateVector() {
        return [
            this.ball.x / this.width,
            this.ball.y / this.height,
            this.ball.vx / this.baseSpeed.ball,
            this.ball.vy / this.baseSpeed.ball,
            this.ai.y / this.height,
            this.player.y / this.height
        ];
    }

    // --- METHODS TO BE CALLED EXTERNALLY BY THE MAIN LOOP ---
    start() {
        if (this.isRunning) return;
        this.isRunning = true;
        this.gameStartTime = Date.now();
    }

    stop() {
        this.isRunning = false;
    }

    update() {
        if (!this.isRunning) return 0;

            let challengeAiActivations = null; // <-- Variable to hold activations
        if (this.challengeMode && this.challengeOpponent) {
            const gameStateForOpponent = { ball: this.ball, player: this.player, ai: this.ai, height: this.height, width: this.width };
            
            // Capture the entire decision object (action + activations)
            const decision = this.challengeOpponent.makeDecision(gameStateForOpponent);
            challengeAiActivations = decision.activations; // <-- Store the activations

            // Use the action to move the paddle
            if (decision.action === 'UP') this.player.y -= this.player.speed;
            if (decision.action === 'DOWN') this.player.y += this.player.speed;
            this.player.y = Math.max(0, Math.min(this.height - this.player.height, this.player.y));
        }

        this.ball.x += this.ball.vx;
        this.ball.y += this.ball.vy;
        if (this.ball.y <= this.ball.radius || this.ball.y >= this.height - this.ball.radius) 
            this.ball.vy *= -1;

        const playerCollision = (this.ball.vx < 0 && this.ball.x - this.ball.radius < this.player.x + this.player.width && this.ball.y > this.player.y && this.ball.y < this.player.y + this.player.height);
        const aiCollision = (this.ball.vx > 0 && this.ball.x + this.ball.radius > this.ai.x && this.ball.y > this.ai.y && this.ball.y < this.ai.y + this.ai.height);

        if (playerCollision || aiCollision) {
            const paddle = playerCollision ? this.player : this.ai;
            const hitPos = (this.ball.y - (paddle.y + paddle.height / 2)) / (paddle.height / 2);
            this.ball.vx *= -1.05;
            this.ball.vy += hitPos * 2;
        }

        let reward = 0;
        if (this.ball.x < 0) {
            this.score.ai++;
            reward = 1.0;
            this.resetBall();
            if (this.challengeMode) this.handleChallengeScoring('ai');
        }
        if (this.ball.x > this.width) {
            this.score.player++;
            reward = -1.0;
            this.resetBall();
            if (this.challengeMode) this.handleChallengeScoring('player');
        }

        this.updateScoreDisplay();
        return { reward, challengeAiActivations };
    }

    render(aiConsciousness = 0.5) {
        this.ctx.fillStyle = 'rgba(0, 0, 17, 0.2)';
        this.ctx.fillRect(0, 0, this.width, this.height);
        this.ctx.fillStyle = '#4af';
        this.ctx.fillRect(this.player.x, this.player.y, this.player.width, this.player.height);
        this.ctx.fillStyle = `rgba(255, 68, 68, ${0.5 + aiConsciousness * 0.5})`;
        this.ctx.fillRect(this.ai.x, this.ai.y, this.ai.width, this.ai.height);
        this.ctx.fillStyle = '#fff';
        this.ctx.beginPath();
        this.ctx.arc(this.ball.x, this.ball.y, this.ball.radius, 0, 2 * Math.PI);
        this.ctx.fill();
    }

    // --- HELPER AND UTILITY FUNCTIONS ---
    resetBall() {
        this.ball.x = this.width / 2;
        this.ball.y = this.height / 2;
        this.ball.vx = (Math.random() > 0.5 ? 1 : -1) * this.baseSpeed.ball;
        this.ball.vy = (Math.random() - 0.5) * this.baseSpeed.ball;
    }

        // In the PongGame class...

    // REPLACE the entire 'toggleChallengeMode' method in the 'PongGame' class.

    toggleChallengeMode() {
        const wasRunning = this.isRunning;
        this.challengeMode = !this.challengeMode;
        const info = document.getElementById('challenge-info');
        const p_label = document.getElementById('player-label');
        
        const mainPanel = document.querySelector('.nn-visualizer-panel'); 
        const opponentPanel = document.getElementById('nn-visualizer-panel-opponent');

        if (this.challengeMode) {
            console.log("üß† Cloning world model using the dedicated .clone() method...");
            // Simply call the new .clone() method. It handles all the complex logic internally.
            const clonedWorldModel = this.worldModel.clone();
            
            this.challengeOpponent = new BareBonesNNAI(clonedWorldModel, { width: this.width, height: this.height });
            
            const stats = this.challengeOpponent.getStats();
            info.innerHTML = `<div style="color: #ff6b6b;">üèÜ CHALLENGE MODE</div><div>${stats.type} vs Conscious AI</div>`;
            p_label.textContent = "NN Clone Score:";
            this.challengeStats.totalGames++;

            if(mainPanel) mainPanel.style.display = 'none';
            if(opponentPanel) opponentPanel.style.display = 'flex';

        } else {
            this.challengeOpponent = null; 
            info.innerHTML = `<div style="color: #4CAF50;">üéÆ NORMAL MODE</div><div>Human vs Conscious AI</div>`;
            p_label.textContent = "Human Score:";
            
            if(opponentPanel) opponentPanel.style.display = 'none';
            if(mainPanel) mainPanel.style.display = 'flex';
        }

        this.reset();
        if (wasRunning) {
            this.isRunning = true;
            this.gameStartTime = Date.now();
        }
        return this.challengeMode;
    }

    // --- AI CONTROL METHOD ---
    setAIAction(action, speed) {
        const moveSpeed = speed || this.ai.speed;
        if (action === 'UP') this.ai.y -= moveSpeed;
        if (action === 'DOWN') this.ai.y += moveSpeed;
        this.ai.y = Math.max(0, Math.min(this.height - this.ai.height, this.ai.y));
    }

    // In the PongGame class, REPLACE the entire handleChallengeScoring method with this:

    handleChallengeScoring(winner) {
        if (winner === 'ai') this.challengeStats.consciousWins++;
        else this.challengeStats.standardWins++;

        // --- THE FIX IS HERE ---
        // Call getStats() on the current `challengeOpponent` instead of the old `standardAI`.
        const stats = this.challengeOpponent.getStats();
        
        const opponentName = winner === 'ai' ? 'Standard' : 'NN Clone'; // Simple naming for score tracking

        document.getElementById('challenge-info').innerHTML = `
            <div style="color: #ff6b6b; font-weight: bold;">üèÜ CHALLENGE MODE</div>
            
            <div style="font-size: 11px;">Opponent: ${stats.type}</div>
            
            <div style="font-size: 10px; color: #aaa;">
                Games: ${this.challengeStats.totalGames} |
                Conscious: ${this.challengeStats.consciousWins} |
                ${opponentName}: ${this.challengeStats.standardWins}
            </div>
        `;
    }

    updateScoreDisplay() {
        document.getElementById('player-score').textContent = this.score.player;
        document.getElementById('ai-score').textContent = this.score.ai;
    }
}
console.log('‚úÖ Pong game loaded');

        // ===== 3D VISUALIZATION =====

        // ===== 3D VISUALIZATION (Corrected Method Names) =====

// REPLACE the entire current 'ConsciousnessVisualizer' class with this new one.

class ConsciousnessVisualizer {
    constructor(container) {
        this.container = container;
        if (!this.container) {
            console.error("Visualization container not found!");
            return;
        }
        this.scene = new THREE.Scene();
        this.camera = new THREE.PerspectiveCamera(75, container.clientWidth / container.clientHeight, 0.1, 1000);
        this.renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });

        this.nodes = [];
        this.connections = [];
        this.isAnimating = false;

        this.setupRenderer();
        this.setupScene();
        this.setupControls();
    }

    setupRenderer() {
        this.renderer.setSize(this.container.clientWidth, this.container.clientHeight);
        this.renderer.setClearColor(0x000011, 0.8);
        this.container.appendChild(this.renderer.domElement);
    }

    setupScene() {
        const ambientLight = new THREE.AmbientLight(0x404040, 0.4);
        this.scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0x44aaff, 0.8);
        directionalLight.position.set(10, 10, 5);
        this.scene.add(directionalLight);
        this.camera.position.set(0, 0, 50);
        this.camera.lookAt(0, 0, 0);
    }

    setupControls() {
        let mouseDown = false;
        let mouseX = 0, mouseY = 0;
        this.renderer.domElement.addEventListener('mousedown', (e) => { mouseDown = true; mouseX = e.clientX; mouseY = e.clientY; });
        this.renderer.domElement.addEventListener('mouseup', () => { mouseDown = false; });
        this.renderer.domElement.addEventListener('mousemove', (e) => {
            if (!mouseDown) return;
            this.scene.rotation.y += (e.clientX - mouseX) * 0.01;
            this.scene.rotation.x += (e.clientY - mouseY) * 0.01;
            mouseX = e.clientX; mouseY = e.clientY;
        });
        this.renderer.domElement.addEventListener('wheel', (e) => {
            this.camera.position.z += e.deltaY * 0.1;
            this.camera.position.z = Math.max(10, Math.min(100, this.camera.position.z));
        });
    }

    // This method now combines creation and updating, matching the old visual style.
    createOrUpdateGraph(G, consciousnessLevel) {
        // If the number of nodes has changed, rebuild the entire graph.
        if (this.nodes.length !== G.V) {
            this.buildGraphFromScratch(G);
        }

        // Update node colors and scale based on qualia and consciousness
        this.nodes.forEach((node, i) => {
            if (i < G.q.length) {
                const qualia = G.q[i];
                // Clamp consciousness to prevent visual artifacts
                const clampedConsciousness = Math.max(0, Math.min(1, consciousnessLevel));
                const intensity = norm2(qualia) * clampedConsciousness;

                // Color based on qualia vector components (e1, e2, e3 for R, G, B)
                const r = Math.abs(qualia[1] || 0);
                const g = Math.abs(qualia[2] || 0);
                const b = Math.abs(qualia[3] || 0);

                node.material.color.setRGB(
                    0.2 + r * 0.8 * intensity,
                    0.2 + g * 0.8 * intensity,
                    0.2 + b * 0.8 * intensity
                );

                // Scale based on consciousness intensity
                const scale = 0.5 + intensity * 1.5;
                node.scale.setScalar(scale);

                // Add a glow effect for high consciousness states
                if (clampedConsciousness > 0.8) {
                    node.material.emissive.setRGB(r * 0.3, g * 0.3, b * 0.3);
                } else {
                    node.material.emissive.setHex(0x000000);
                }
            }
        });

        // Update connection opacity based on weights and consciousness
        this.connections.forEach(connection => {
            connection.material.opacity = connection.userData.weight * consciousnessLevel * 2.0;
        });

        // Animate rotation if enabled
        if (this.isAnimating) {
            this.scene.rotation.y += 0.005;
        }
    }
    
    // Helper function to build the graph, based on your old code
    buildGraphFromScratch(G) {
        this.clearGraph();
        const n = G.V;
        const radius = 20;

        // Create nodes
        for (let i = 0; i < n; i++) {
            const geometry = new THREE.SphereGeometry(0.5, 16, 16);
            const material = new THREE.MeshPhongMaterial({ color: 0x44aaff, transparent: true, opacity: 0.8 });
            const node = new THREE.Mesh(geometry, material);

            // Position nodes in a 3D spiral
            const angle = (i / n) * Math.PI * 4;
            const height = (i / n - 0.5) * 30;
            node.position.set( Math.cos(angle) * radius, height, Math.sin(angle) * radius );

            this.scene.add(node);
            this.nodes.push(node);
        }

        // Create connections (lines)
        for (let i = 0; i < n; i++) {
            for (let j = 0; j < n; j++) { // Check all pairs for directed graph
                if (G.W[i][j] > 0.05) { // Only show strong connections
                    const geometry = new THREE.BufferGeometry().setFromPoints([ this.nodes[i].position, this.nodes[j].position ]);
                    const material = new THREE.LineBasicMaterial({ color: 0x666666, transparent: true, opacity: G.W[i][j] * 2 });
                    const line = new THREE.Line(geometry, material);
                    line.userData = { weight: G.W[i][j] };

                    this.scene.add(line);
                    this.connections.push(line);
                }
            }
        }
    }

    clearGraph() {
        this.nodes.forEach(node => this.scene.remove(node));
        this.connections.forEach(connection => this.scene.remove(connection));
        this.nodes = [];
        this.connections = [];
    }

    startAnimation() {
        this.isAnimating = true;
        this.animate();
    }

    stopAnimation() {
        this.isAnimating = false;
    }

    animate() {
        if (!this.isAnimating) return;
        requestAnimationFrame(() => this.animate());
        this.renderer.render(this.scene, this.camera);
    }

    resize() {
        if (!this.container) return;
        const width = this.container.clientWidth;
        const height = this.container.clientHeight;
        this.camera.aspect = width / height;
        this.camera.updateProjectionMatrix();
        this.renderer.setSize(width, height);
    }
}
        console.log('‚úÖ 3D visualization loaded');

        // ===== MAIN APPLICATION =====
        // Paste this code before the 'class UltimateConsciousnessSystem'
class NeuralNetworkVisualizer {
    // In the NeuralNetworkVisualizer class...

    constructor(containerId, worldModel) {
        this.container = document.getElementById(containerId);
        this.worldModel = worldModel;
        if (!this.container || !this.worldModel) {
            console.error("NN Visualizer failed to initialize: container or model not found.");
            return;
        }

        this.layers = [
            { name: 'input', count: 6, dataKey: 'input' },
            { name: 'lstm', count: 12, dataKey: 'lstm' },
            { name: 'hidden2', count: 12, dataKey: 'hidden2' },
            { name: 'output', count: 6, dataKey: 'output' }
        ];

        this.neuronElements = [];
        this.lastActivations = null;
        this.currentTheme = 'conscious'; // <-- NEW: Default theme

        this._setupDOM();
        this._drawConnections();
    }

    // --- ADD THIS NEW METHOD ---
    setTheme(theme) {
    if (theme !== 'conscious' && theme !== 'opponent') {
        console.warn(`Invalid NN theme set: ${theme}`);
        return;
    }
    // --- ADD THIS LOG ---
    console.log(`üé® NN Visualizer: Theme set to -> ${theme.toUpperCase()}`);

    this.currentTheme = theme;
    // Redraw connections immediately to apply the new color theme
    this._drawConnections();
}

    _setupDOM() {
        this.container.innerHTML = ''; // Clear container

        // Create canvas for connections
        this.canvas = document.createElement('canvas');
        this.canvas.id = 'nn-connections-canvas';
        this.ctx = this.canvas.getContext('2d');
        this.container.appendChild(this.canvas);

        // Create neuron divs
        this.layers.forEach((layer, layerIndex) => {
            const layerDiv = document.createElement('div');
            layerDiv.className = 'nn-layer';
            this.neuronElements[layerIndex] = [];

            for (let i = 0; i < layer.count; i++) {
                const neuronDiv = document.createElement('div');
                neuronDiv.className = 'nn-neuron';
                layerDiv.appendChild(neuronDiv);
                this.neuronElements[layerIndex].push(neuronDiv);
            }
            this.container.appendChild(layerDiv);
        });

        // Resize canvas to fit container
        const resizeObserver = new ResizeObserver(() => {
            this.canvas.width = this.container.clientWidth;
            this.canvas.height = this.container.clientHeight;
            this._drawConnections();
        });
        resizeObserver.observe(this.container);
    }
    
    _getNeuronPosition(layerIndex, neuronIndex) {
        const neuronDiv = this.neuronElements[layerIndex][neuronIndex];
        const rect = neuronDiv.getBoundingClientRect();
        const containerRect = this.container.getBoundingClientRect();
        return {
            x: rect.left - containerRect.left + rect.width / 2,
            y: rect.top - containerRect.top + rect.height / 2
        };
    }

    // In the NeuralNetworkVisualizer class

    // In the NeuralNetworkVisualizer class...

    // In the NeuralNetworkVisualizer class...

    _drawConnections() {
        if (!this.neuronElements || this.neuronElements.length === 0) return;
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);

        // --- NEW: Define color palettes for themes ---
        const themeColors = {
            conscious: {
                positive: 'rgba(68, 170, 255, ', // Blue
                negative: 'rgba(255, 85, 85, '   // Red
            },
            opponent: {
                positive: 'rgba(255, 165, 0, ',  // Orange
                negative: 'rgba(138, 43, 226, ' // Purple
            }
        };
        const colors = themeColors[this.currentTheme];

        const weightMatrices = [
            this.worldModel.transW1,
            this.worldModel.transW2,
            this.worldModel.transW4
        ];

        for (let l = 0; l < this.layers.length - 1; l++) {
            const sourceLayer = this.layers[l];
            const targetLayer = this.layers[l + 1];
            const matrix = weightMatrices[l];
            if (!matrix) continue;

            const sourceDim = matrix[0].length;
            const targetDim = matrix.length;

            for (let i = 0; i < sourceLayer.count; i++) {
                for (let j = 0; j < targetLayer.count; j++) {
                    const startPos = this._getNeuronPosition(l, i);
                    const endPos = this._getNeuronPosition(l + 1, j);
                    
                    const sourceMatrixIndex = Math.floor(i * (sourceDim / sourceLayer.count));
                    const targetMatrixIndex = Math.floor(j * (targetDim / targetLayer.count));
                    
                    const weight = matrix[targetMatrixIndex][sourceMatrixIndex] || 0;
                    const alpha = Math.min(0.5, Math.abs(weight) * 5.0);
                    if (alpha < 0.05) continue;

                    // --- THEME-AWARE CHANGE ---
                    // Use the color from the current theme's palette
                    this.ctx.strokeStyle = weight > 0 ? (colors.positive + `${alpha})`) : (colors.negative + `${alpha})`);
                    this.ctx.lineWidth = Math.min(1.5, alpha * 2);
                    
                    this.ctx.beginPath();
                    this.ctx.moveTo(startPos.x, startPos.y);
                    this.ctx.lineTo(endPos.x, endPos.y);
                    this.ctx.stroke();
                }
            }
        }
    }
   // In the NeuralNetworkVisualizer class

    // In the NeuralNetworkVisualizer class...

    // In the NeuralNetworkVisualizer class...

    update(activations) {
        if (!activations) return;

        // --- NEW: Define color palettes for themes (neurons) ---
        const themeHues = {
            conscious: {
                positive: 195, // Blue
                negative: 0    // Red
            },
            opponent: {
                positive: 39,  // Orange
                negative: 271  // Purple
            }
        };
        const hues = themeHues[this.currentTheme];

        if (Math.random() < 0.05) {
            this._drawConnections();
        }

        const oldActivations = this.lastActivations;
        this.lastActivations = activations;

        this.layers.forEach((layer, l_idx) => {
            const activationData = activations[layer.dataKey];
            if (!activationData || activationData.length === 0) return;

            let maxAbsVal = 0;
            for (const val of activationData) {
                if (Math.abs(val) > maxAbsVal) {
                    maxAbsVal = Math.abs(val);
                }
            }
            const normalizer = maxAbsVal + 1e-9;

            for (let n_idx = 0; n_idx < layer.count; n_idx++) {
                const dataIndex = Math.floor(n_idx * (activationData.length / layer.count));
                const value = activationData[dataIndex] || 0;
                
                const normalizedValue = value / normalizer;
                const visualIntensity = clamp(Math.abs(normalizedValue), 0, 1);
                const ambient = 0.05;
                const finalIntensity = ambient + (1 - ambient) * visualIntensity;
                
                // --- THEME-AWARE CHANGE ---
                // Use the HUE from the current theme's palette
                const hue = value >= 0 ? hues.positive : hues.negative;
                
                const color = `hsl(${hue}, 100%, ${finalIntensity * 45}%)`;
                const borderColor = `hsl(${hue}, 100%, 70%)`;
                
                const neuronEl = this.neuronElements[l_idx][n_idx];
                neuronEl.style.backgroundColor = color;
                neuronEl.style.borderColor = borderColor;

                if (oldActivations && oldActivations[layer.dataKey]) {
                    const oldValue = oldActivations[layer.dataKey][dataIndex] || 0;
                    const oldNormalizedValue = oldValue / normalizer;
                    if (Math.abs(normalizedValue - oldNormalizedValue) > 0.5) {
                        neuronEl.classList.remove('neuron-flash');
                        void neuronEl.offsetWidth;
                        neuronEl.classList.add('neuron-flash');
                    }
                }
            }
        });
    }

// In the PongGame class...

    toggleChallengeMode() {
        const wasRunning = this.isRunning;
        this.challengeMode = !this.challengeMode;
        const info = document.getElementById('challenge-info');
        const p_label = document.getElementById('player-label');
        const nnTitle = document.getElementById('nn-visualizer-title');

        if (this.challengeMode) {
            this.challengeOpponent = new BareBonesNNAI(this.worldModel, { width: this.width, height: this.height });
            const stats = this.challengeOpponent.getStats();
            
            info.innerHTML = `<div style="color: #ff6b6b;">üèÜ CHALLENGE MODE</div><div>${stats.type} vs Conscious AI</div>`;
            p_label.textContent = "NN Clone Score:";
            if (nnTitle) nnTitle.textContent = "ü§ñ Opponent World Model Activity";
            this.challengeStats.totalGames++;

            // --- THE DEFINITIVE FIX ---
            // Use the direct 'this.app' reference. This CANNOT fail.
            if (this.app && this.app.nnVisualizer) {
                this.app.nnVisualizer.setTheme('opponent');
            }

        } else {
            this.challengeOpponent = null; 
            info.innerHTML = `<div style="color: #4CAF50;">üéÆ NORMAL MODE</div><div>Human vs Conscious AI</div>`;
            p_label.textContent = "Human Score:";
            if (nnTitle) nnTitle.textContent = "üß† World Model Activity";

            // --- THE DEFINITIVE FIX ---
            // Use the direct 'this.app' reference here as well.
            if (this.app && this.app.nnVisualizer) {
                this.app.nnVisualizer.setTheme('conscious');
            }
        }

        this.reset();
        if (wasRunning) {
            this.isRunning = true;
            this.gameStartTime = Date.now();
        }
        return this.challengeMode;
    }
}

        // =======================================================================
// === FINAL REPLACEMENT for UltimateConsciousnessSystem ===
// Integrates the decoupled "brain" (slow loop) and "body" (fast loop)
// into your updated class structure for maximum performance.
// =======================================================================

class UltimateConsciousnessSystem {
    constructor() {
        this.isRunning = false;
        this.step = 0; // Cognitive steps
        this.nnVisualizer = null;
        this.lastGameState = null;
        this.lastResult = null;
        this.chatInitialized = false;
        this.narrationEnabled = true;
        this.performanceStats = { totalTime: 0, calls: 0, maxTime: 0 };
        this.narrationHistory = [];

        // --- State variables for communication between loops ---
        this.nextAIAction = 'IDLE';     // The brain writes here, the body reads from here
        this.aiIntervalId = null;       // To store the ID of the brain loop
        this.lastFrameReward = 0;       // The body writes the reward, the brain reads it

        this.initializeSystem();
        this.setupEventListeners();
    }

    initializeSystem() {
        console.log('üß† Initializing Ultimate Consciousness System...');
        const initialGraph = this.createConsciousnessGraph();
        this.player = new UltimateSCANPlayer(initialGraph);
        this.consciousLM = new ConsciousLanguageModel();

        const gameCanvas = document.getElementById('gameCanvas');
        if (gameCanvas) this.pongGame = new PongGame(gameCanvas, this.player.worldModel, this);

        const vizContainer = document.getElementById('visualization-container');
        if (vizContainer) {
            this.visualizer = new ConsciousnessVisualizer(vizContainer);
            this.visualizer.createOrUpdateGraph(initialGraph, 0.5);
        }
        
        // --- THE DEFINITIVE FIX: CREATE TWO SEPARATE VISUALIZERS ---
        // One for the conscious AI
        this.nnVisualizer = new NeuralNetworkVisualizer('nn-visualization-container', this.player.worldModel);
        this.nnVisualizer.setTheme('conscious'); // Blue/Red theme

        // One for the opponent AI (it shares the same predictive brain)
        this.nnVisualizerOpponent = new NeuralNetworkVisualizer('nn-visualization-container-opponent', this.player.worldModel);
        this.nnVisualizerOpponent.setTheme('opponent'); // Orange/Purple theme

        // Ensure the correct panels are visible by default
        document.getElementById('nn-visualizer-panel-opponent').style.display = 'none';
        document.querySelector('.nn-visualizer-panel').style.display = 'flex'; // The first one

        this.startNarrationSystem();
        console.log('‚úÖ System initialized with language integration');
        this.updateStatus('Offline');
    }
    
    toggleConsciousness() {
        this.isRunning = !this.isRunning;
        const btn = document.getElementById('startStopBtn');

        if (this.isRunning) {
            if (btn) btn.textContent = '‚è∏Ô∏è Pause Consciousness';
            this.updateStatus('Running');
            if (this.pongGame) this.pongGame.start();
            if (this.visualizer) this.visualizer.startAnimation();
            
            // Start the brain loop (slow, expensive decisions)
            this.aiIntervalId = setInterval(() => this.aiCognitiveLoop(), 100);
            // Start the body loop (fast physics & rendering)
            this.gameLoop();
        } else {
            if (btn) btn.textContent = 'üöÄ Awaken Consciousness';
            this.updateStatus('Paused');
            if (this.pongGame) this.pongGame.stop();
            if (this.visualizer) this.visualizer.stopAnimation();
            
            clearInterval(this.aiIntervalId);
            this.aiIntervalId = null;
        }
    }

    async aiCognitiveLoop() {
        if (!this.isRunning) return;

        try {
            const gameState = { 
                ball: { ...this.pongGame.ball }, 
                ai: { ...this.pongGame.ai }, 
                player: { ...this.pongGame.player } 
            };

            // 1. THINK
            const result = await stepTick(this.player, gameState, this.step);

            // Ignore non-finite action values
            if (!['UP','DOWN','IDLE'].includes(result.action)) result.action = 'IDLE';

            this.nextAIAction = result.action || 'IDLE';
            this.lastResult = result;

            // 2. LEARN
            const reward = this.lastFrameReward;
            if (reward !== 0 && this.lastGameState && this.lastResult) {
                const lastStateVec = this.player.gameStateToVec(this.lastGameState);
                const nextStateVec = this.player.gameStateToVec(gameState);
                const lastActionVec = (this.lastResult.action === 'UP') ? [1,0,0] : (this.lastResult.action === 'DOWN') ? [0,1,0] : [0,0,1];
                const qualiaStateQ = this.player.getAggregateQualia(this.lastResult.graph);
                const nextQualiaStateQ = this.player.getAggregateQualia(result.graph);
                
                this.player.worldModel.storeTransition(lastStateVec, lastActionVec, nextStateVec, reward, qualiaStateQ, nextQualiaStateQ);
                this.player.worldModel.trainFromMemory();
            }

            // 3. NARRATE
            if (!this.lastNarrationTime || Date.now() - this.lastNarrationTime > 2000) {
                const sentenceResult = await this.consciousLM.generateActionSentence(result.action, result.consciousness, gameState);
                this.addNarration(sentenceResult.sentence, result.consciousness);
                this.lastNarrationTime = Date.now();
            }

            this.lastGameState = gameState;
            this.step++;
        } catch (error) {
            console.error("CRITICAL ERROR IN AI COGNITIVE LOOP:", error);
            this.toggleConsciousness();
            alert("The AI suffered a critical cognitive failure. Check console.");
        }
    }

    // In the UltimateConsciousnessSystem class...

    // REPLACE the entire 'gameLoop' method in the 'UltimateConsciousnessSystem' class.

    gameLoop() {
        if (!this.isRunning) return;

        // 1. ACT
        this.pongGame.setAIAction(this.nextAIAction, this.lastResult ? this.lastResult.dynamicSpeed : null);

        // 2. UPDATE PHYSICS & GET REWARD / ACTIVATIONS
        const gameUpdateResult = this.pongGame.update();
        
        // --- THE LEARNING FIX ---
        // Check if a point was just scored
        if (gameUpdateResult.reward !== 0) {
            // Store the reward for the conscious AI's next cognitive cycle.
            this.lastFrameReward = gameUpdateResult.reward;

            // If in challenge mode, tell the opponent to learn from the outcome.
            // The opponent's reward is the inverse of the conscious AI's reward.
            if (this.pongGame.challengeMode && this.pongGame.challengeOpponent.learn) {
                const opponentReward = -gameUpdateResult.reward;
                const currentGameState = { ball: { ...this.pongGame.ball }, ai: { ...this.pongGame.ai }, player: { ...this.pongGame.player } };
                this.pongGame.challengeOpponent.learn(opponentReward, currentGameState);
            }
        } else {
             // If no point was scored, there is no reward.
             this.lastFrameReward = 0;
        }
        // --- END OF FIX ---

        // 3. RENDER & VISUALIZE
        const consciousnessValue = this.lastResult ? this.lastResult.consciousness : 0.5;
        this.pongGame.render(consciousnessValue);

        if (this.lastResult && this.lastResult.graph) {
            this.visualizer.createOrUpdateGraph(this.lastResult.graph, consciousnessValue);
            this.updateUIDisplays(this.lastResult);
        }
        
        if (this.pongGame.challengeMode && gameUpdateResult.challengeAiActivations) {
            this.nnVisualizerOpponent.update(gameUpdateResult.challengeAiActivations);
        } else if (this.lastResult && this.lastResult.activations) {
            this.nnVisualizer.update(this.lastResult.activations);
        }

        const timerEl = document.getElementById('game-length');
        if (timerEl && this.pongGame.isRunning && this.pongGame.gameStartTime > 0) {
            const elapsedSeconds = Math.floor((Date.now() - this.pongGame.gameStartTime) / 1000);
            timerEl.textContent = `${elapsedSeconds}s`;
        }

        requestAnimationFrame(() => this.gameLoop());
    }

    startNarrationSystem() {
        this.addNarration("üß† Consciousness system initialized. Language generation ready.", 0.5);
        this.addNarration("üéÆ Game AI will narrate its thoughts and actions in real-time.", 0.5);
        window.addEventListener('resize', () => this.adjustNarrationPanelHeight());
        this.adjustNarrationPanelHeight();
    }

    adjustNarrationPanelHeight() {
        const narrationPanel = document.getElementById('narration-panel');
        const leftPanel = document.querySelector('.consciousness-panel');
        const rightPanel = document.querySelector('.game-container');
        if (!narrationPanel || !leftPanel || !rightPanel) return;

        const leftHeight = leftPanel.offsetHeight;
        const rightHeight = rightPanel.offsetHeight;
        const maxSideHeight = Math.min(leftHeight, rightHeight);
        const header = 60, metrics = 80, padding = 40;
        const maxHeight = Math.min(400, Math.max(200, maxSideHeight - header - metrics - padding));
        narrationPanel.style.maxHeight = `${maxHeight}px`;

        const messages = document.getElementById('ai-narration');
        if (messages) {
            const msgHeight = Math.max(150, maxHeight - header - metrics);
            messages.style.height = `${msgHeight}px`;
            messages.style.maxHeight = `${msgHeight}px`;
        }
    }

    createConsciousnessGraph() {
        const n = 20, eps = 1e-6;
        const W = Array(n).fill().map(() => new Float32Array(n).fill(0));
        const edges = [];

        for (let i = 0; i < n; i++) {
            for (let j = 0; j < n; j++) {
                if (i === j) continue;
                const distance = Math.abs(i - j);
                const localWeight = Math.exp(-distance / 3) * Math.random();
                const globalWeight = Math.random() < 0.05 ? Math.random() * 0.5 : 0;
                const totalWeight = localWeight + globalWeight;
                if (totalWeight > 0.1) { W[i][j] = totalWeight; edges.push([i, j]); }
            }
        }

        for (let i = 0; i < n; i++) {
            let sum = W[i].reduce((a, b) => a + b, 0);
            if (sum < eps) { let t = Math.floor(Math.random() * n); while(t===i) t=Math.floor(Math.random()*n); W[i][t]=0.1; sum=0.1; }
            for (let j = 0; j < n; j++) W[i][j] /= sum;
        }

        const q = Array(n).fill().map(() => { let v; do { v = new Float32Array(8).map(()=>Math.random()-0.5); } while (norm2(v)<eps); return cliffordProject(v); });
        const X = Array(n).fill().map(() => new Float32Array(4).map(() => Math.random()-0.5));

        return { V: n, W, X, q, edges, stalkDims: new Array(n).fill(4),
                 a: new Float32Array(n).fill(1/n),
                 aSchema: new Float32Array(n).fill(1/n),
                 aMeasured: new Float32Array(n).fill(1/n) };
    }

    setupEventListeners() {
        const bind = (id, fn) => { const el = document.getElementById(id); if(el) el.addEventListener('click', fn); };
        bind('startStopBtn', () => this.toggleConsciousness());
        bind('resetBtn', () => this.resetSystem());
        bind('imaginationBtn', () => this.toggleImagination());
        bind('trainGrammarBtn', () => this.trainGameGrammar());
        bind('toggleNarrationBtn', () => this.toggleNarration());
        bind('testImports', () => this.testSystem());
        bind('challengeModeBtn', () => { if(this.pongGame){this.pongGame.toggleChallengeMode();} });
        window.addEventListener('resize', () => { if(this.visualizer) this.visualizer.resize(); this.adjustNarrationPanelHeight(); });
    }

    addNarration(sentence, consciousness) {
        if(!this.narrationEnabled) return;
        const container = document.getElementById('ai-narration');
        if(!container) return;
        const msg = document.createElement('div');
        const time = new Date().toLocaleTimeString();
        msg.innerHTML = `<div style="color:${this.getConsciousnessColor(consciousness)}; font-weight:bold;">üß† AI (C=${consciousness.toFixed(3)}) <span style="color:#888; font-weight:normal;">${time}</span></div>
                         <div style="color:#fff; line-height:1.3;">${sentence}</div>`;
        msg.style.marginBottom='8px';
        msg.style.padding='6px';
        msg.style.borderLeft=`3px solid ${this.getConsciousnessColor(consciousness)}`;
        msg.style.backgroundColor='#2a2a2a';
        container.appendChild(msg);
        container.scrollTop = container.scrollHeight;
        this.narrationHistory.push(sentence);
    }

    getConsciousnessColor(c){ return c>0.8?'#4CAF50':c>0.6?'#FF9800':c>0.4?'#2196F3':'#9E9E9E'; }

    // In the UltimateConsciousnessSystem class, replace the placeholder function with this:

updateUIDisplays(result) {
    // --- Guard Clauses: Exit early if essential data is missing ---
    if (!result || !result.graph) return;

    /**
     * A robust helper to format any value for display, handling Infinity and NaN.
     */
    function formatMetric(value, precision = 3) {
        const num = Number(value);
        if (!isFinite(num)) {
            if (num === Infinity) return "Impermissible";
            if (num === -Infinity) return "-‚àû";
            return "Error (NaN)";
        }
        return num.toFixed(precision);
    }

    // --- 1. Update Core Metrics Panel ---
    const actionEl = document.getElementById('action');
    if (actionEl) {
        const currentAction = result.action || 'IDLE';
        actionEl.textContent = currentAction;
        actionEl.className = 'metric-value';
        actionEl.classList.add(`action-${currentAction.toLowerCase()}`);
    }

    Object.entries({
        'step': this.step,
        'consciousness': formatMetric(result.consciousness, 3),
        'coherence-error': formatMetric(result.coherenceError, 3),
        'loops': (result.graph.syntrices || []).length,
    }).forEach(([id, value]) => {
        const el = document.getElementById(id);
        if (el) el.textContent = value;
    });

    // --- 2. Update Imagination Paths Panel ---
    const imaginationContainer = document.getElementById('imagination-paths');
    const paths = result.imaginationPaths || [];

    if (imaginationContainer && paths.length > 0) {
        imaginationContainer.innerHTML = '';
        paths.forEach(path => {
            const div = document.createElement('div');
            const value = path.value || 0;
            let pathClass = 'path-neutral';
            if (isFinite(value)) {
                if (value > 0.01) pathClass = 'path-good';
                if (value < -0.01) pathClass = 'path-bad';
            } else {
                pathClass = 'path-bad';
            }
            div.className = `imagination-path ${pathClass}`;
            div.textContent = `Action ${path.actionName}: Value ${formatMetric(value, 4)}`;
            imaginationContainer.appendChild(div);
        });
    }

    // --- 3. Update Proof Harness & Custom Metrics Panel ---
    if (this.step % 5 === 0) {
        const proofContainer = document.getElementById('proof-metrics');
        if (proofContainer) {
            proofContainer.innerHTML = '';

            // ====================================================================
            // === DEFINITIVE FIX FOR BINDING QUALITY CALCULATION ===
            // This now uses Cosine Similarity for a more stable and interpretable score (-1 to 1).
            // It measures the alignment between the AI's internal spatial qualia and the external sensory data.
            // ====================================================================
            let total_similarity = 0;
            const V = (this.player && this.player.graph) ? this.player.graph.V : 0;
            if (V > 0) {
                for (let i = 0; i < V; i++) {
                    const q_vec = this.player.graph.q[i];
                    const x_vec = this.player.graph.X[i];
                    if (q_vec && x_vec) {
                        // Extract the spatial components
                        const q_spatial = [q_vec[1], q_vec[2], q_vec[3]]; // e1, e2, e3
                        const x_spatial = [x_vec[0], x_vec[1], x_vec[2]]; // ball.x, ball.y, paddle.y

                        // The q_spatial vector is part of a unit vector, so its norm is <= 1.
                        // We only need to normalize the sensory vector.
                        const x_norm = norm2(x_spatial);
                        if (x_norm > eps) { // Avoid division by zero
                            const similarity = dot(q_spatial, x_spatial) / x_norm;
                            total_similarity += similarity;
                        }
                    }
                }
            }
            const bindingQuality = total_similarity / (V || 1);


            const report = result.proofReport || {};
            const metrics = [
                { name: 'Binding Quality', value: bindingQuality, threshold: 0.1 }, // Adjusted threshold for new metric
                { name: 'Sys Stability', value: result.selfStability || 0, threshold: 0.2 },
                { name: 'Clifford Dagger', value: report.dagger || 0, threshold: 0.8 },
                { name: 'PSD Matrix', value: report.psd || 0, threshold: 0.8 },
                { name: 'Idempotence', value: report.idemp || 0, threshold: 0.8 },
                { name: 'Coalgebra', value: report.coalg || 0, threshold: 0.8 }
            ];

            metrics.forEach(m => {
                const div = document.createElement('div');
                const isPass = isFinite(m.value) && m.value >= m.threshold;
                let valueStr;

                if (!isFinite(m.value)) {
                    valueStr = "Error";
                } else if (m.name === 'Binding Quality' || Math.abs(m.value) > 1) {
                     // Display Binding Quality as a percentage for clarity
                    valueStr = `${(m.value * 100).toFixed(0)}%`;
                }
                else if (Math.abs(m.value * 100) > 1) {
                    valueStr = `${(m.value * 100).toFixed(0)}%`;
                } else {
                    valueStr = m.value.toFixed(4);
                }
                
                div.className = `proof-metric ${isPass ? 'proof-pass' : 'proof-fail'}`;
                div.textContent = `${m.name}: ${valueStr} ${isPass ? '‚úì' : '‚úó'}`;
                proofContainer.appendChild(div);
            });
        }
    }
}
    // In the UltimateConsciousnessSystem class...

    // In the UltimateConsciousnessSystem class...

resetSystem() {
    // Stop all running processes
    this.isRunning = false;
    if (this.aiIntervalId) {
        clearInterval(this.aiIntervalId);
        this.aiIntervalId = null;
    }
    
    // Stop the game and visualization animations
    if (this.pongGame) {
        this.pongGame.stop();
    }
    if (this.visualizer) {
        this.visualizer.stopAnimation();
    }

    this.step = 0;
    this.nextAIAction = 'IDLE';
    this.lastResult = null;
    
    // --- THE DEFINITIVE FIX IS HERE ---
    // Re-initialize all core components from scratch.
    // This creates a new player, a new visualizer, and importantly,
    // a new pongGame instance that is correctly linked to the new components.
    this.initializeSystem();

    // Now, update the UI to reflect the fresh state.
    const startBtn = document.getElementById('startStopBtn');
    if (startBtn) startBtn.textContent = 'üöÄ Awaken Consciousness';
    
    this.updateStatus('Reset');
    
    // Explicitly reset UI text elements to their default state
    const nnTitle = document.getElementById('nn-visualizer-title');
    const challengeInfo = document.getElementById('challenge-info');
    const playerLabel = document.getElementById('player-label');

    if (nnTitle) nnTitle.textContent = "üß† World Model Activity";
    if (playerLabel) playerLabel.textContent = "Human Score:";
    if (challengeInfo) {
        challengeInfo.innerHTML = `<div style="color: #4CAF50;">üéÆ NORMAL MODE</div><div>Human vs Conscious AI</div>`;
    }

    console.log('üîÑ System fully reset to a clean initial state.');
}
    toggleImagination(){ console.log('üîÆ Imagination mode toggled'); }
    trainGameGrammar(){ console.log('üìù Training game grammar (stub)'); }
    toggleNarration(){ this.narrationEnabled=!this.narrationEnabled; }
    testSystem(){ console.log('üîß System test (stub)'); }
    updateStatus(status){ const el=document.getElementById('status'); if(el){ el.textContent=status; el.className=status==='Running'?'status-running':'status-stopped'; } }

    cleanupMemory() {
        if(this.player && this.player.worldModel){
            if(this.player.worldModel.memory.length>1000) this.player.worldModel.memory=this.player.worldModel.memory.slice(-500);
            if(this.player.worldModel.fepHistory.length>100) this.player.worldModel.fepHistory=this.player.worldModel.fepHistory.slice(-50);
        }
        if(this.narrationHistory.length>50) this.narrationHistory=this.narrationHistory.slice(-25);
        if(window.gc) window.gc();
        console.log(`üßπ Memory cleanup completed at cognitive step ${this.step}`);
    }
}
     // ===== INITIALIZE APPLICATION =====

        let app;

        window.addEventListener('load', () => {
            console.log('üöÄ Starting Ultimate Consciousness System...');

            try {
                app = new UltimateConsciousnessSystem();
                window.app = app; // Make globally accessible for Pong game
                console.log('‚úÖ Ultimate Consciousness System ready!');

                // Add welcome message
                setTimeout(() => {
                    console.log('üß† Welcome to the Ultimate SCAN Consciousness System!');
                    console.log('üí° Click "Awaken Consciousness" to begin the journey into artificial consciousness');
                    console.log('üéÆ Play Pong with a conscious AI that narrates its thoughts in real-time');
                    console.log('ÔøΩ Watch the AI learn grammar from its own actions and decisions');
                    console.log('üîÆ Observe real-time 3D visualization of consciousness emergence');
                    console.log('üó£Ô∏è AI continuously generates sentences based on game actions');
                }, 1000);

            } catch (error) {
                console.error('‚ùå System initialization failed:', error);
            }
        });

        console.log('‚úÖ Ultimate SCAN System fully loaded');
    </script>
</body>
</html>
